"""
Main Workflow Module

This module implements the main research workflow using LangGraph. It defines the
state, nodes, and routing logic for a multi-step research process.

Key Components:
- GraphState: Manages the shared state across all nodes.
- Agent Nodes: Each node wraps an agent responsible for a specific task (planning,
  searching, analyzing, synthesizing).
- Routing Logic: Conditional edges that direct the flow of the graph based on
  the current state.
"""

import logging
import uuid
import re
from typing import TypedDict, Annotated, List, Optional, Dict, Any, Sequence
import operator

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from langgraph.graph import StateGraph, END
from langchain.agents import AgentExecutor

from config.settings import settings
from src.agents.agent_architectures import (
    create_research_planner_agent,
    create_arxiv_search_agent,
    create_document_analysis_agent,
    create_synthesis_agent,
)
from src.graph.checkpointer import MongoDBSaver

logger = logging.getLogger(__name__)


class GraphState(TypedDict):
    """
    Represents the state of the research workflow graph. Each attribute is a piece
    of information that can be passed between nodes.

    Attributes:
        messages: The history of messages in the conversation.
        user_query: The original query submitted by the user.
        research_plan: The plan generated by the planner agent.
        arxiv_query_for_searcher: A specific query for ArXiv, extracted from the plan.
        arxiv_search_results_str: Formatted string of search results from ArXiv.
        document_analysis_summary: The comprehensive summary from the document analysis.
        synthesis_output: The final, synthesized response for the user.
        error_message: A message describing an error, if one occurs.
    """
    messages: Annotated[List[BaseMessage], operator.add]
    user_query: str
    research_plan: Optional[str] = None
    arxiv_query_for_searcher: Optional[str] = None
    arxiv_search_results_str: Optional[str] = None
    document_analysis_summary: Optional[str] = None
    synthesis_output: Optional[str] = None
    error_message: Optional[str] = None


# Initialize agents
planner_agent_executor = create_research_planner_agent()
arxiv_search_agent_executor = create_arxiv_search_agent()
doc_analysis_agent_executor = create_document_analysis_agent()
synthesis_agent_executor = create_synthesis_agent()


def _get_agent_output(
    agent_response: Dict[str, Any], agent_name: str
) -> Optional[str]:
    """
    Extracts the primary content from an agent's response.

    This helper function standardizes the process of getting the output string
    from an agent's execution result. It prioritizes the content of the last
    AIMessage, falls back to the 'output' key, and logs warnings if no
    output can be found.

    Args:
        agent_response: The dictionary returned by the agent executor.
        agent_name: The name of the agent, for logging purposes.

    Returns:
        The extracted output string, or None if no output is found.
    """
    if agent_response.get("messages"):
        for msg in reversed(agent_response.get("messages", [])):
            if isinstance(msg, AIMessage) and msg.content:
                logger.debug(f"Extracted output from AIMessage for {agent_name}.")
                return msg.content

    if "output" in agent_response and agent_response["output"]:
        logger.debug(f"Extracted output from 'output' key for {agent_name}.")
        return str(agent_response["output"])

    logger.warning(f"No output found for {agent_name} in messages or 'output' key.")
    return None


def run_agent_node(
    state: GraphState, agent_executor: AgentExecutor, agent_name: str
) -> Dict[str, Any]:
    """
    Runs a specific agent node and handles its execution.

    Args:
        state: The current state of the graph.
        agent_executor: The agent executor to run.
        agent_name: The name of the agent for logging.

    Returns:
        The response from the agent executor.

    Raises:
        Exception: Propagates exceptions from the agent execution.
    """
    try:
        logger.info(f"--- EXECUTING {agent_name.upper()} NODE ---")
        agent_input = {"messages": state["messages"]}
        response = agent_executor.invoke(agent_input)

        # Log the raw output for debugging
        if isinstance(response, dict) and response.get("messages"):
            last_message = response["messages"][-1]
            logger.info(f"{agent_name} output:\n{last_message.content}")
        else:
            logger.info(f"{agent_name} raw response: {response}")

        return response
    except Exception as e:
        logger.error(f"Error in {agent_name}: {e}", exc_info=True)
        raise


def planner_node(state: GraphState) -> Dict[str, Any]:
    """
    Executes the research planner agent to create a research plan.

    This node runs the planner agent, extracts the generated plan, and also
    attempts to extract a specific ArXiv query from the plan.
    """
    logger.info("--- PLANNER NODE ---")
    response = run_agent_node(state, planner_agent_executor, "ResearchPlannerAgent")
    plan = _get_agent_output(response, "ResearchPlannerAgent")

    if not plan:
        logger.error("No plan generated by ResearchPlannerAgent.")
        return {
            "messages": [
                AIMessage(content="Failed to generate a research plan. Please try again.")
            ],
            "error_message": "No plan generated",
        }

    arxiv_query = extract_arxiv_query(plan)

    return {
        "research_plan": plan,
        "arxiv_query_for_searcher": arxiv_query,
        "messages": [AIMessage(content=plan)],
        "error_message": None,
    }


def extract_arxiv_query(plan: str) -> Optional[str]:
    """
    Extracts a specific ArXiv query from the research plan text.

    This function uses a series of regular expressions to find a query
    intended for ArXiv search. It tries to find structured queries first
    before falling back to more general patterns.

    Args:
        plan: The research plan text generated by the planner.

    Returns:
        The extracted ArXiv query as a string, or None if not found.
    """
    if not plan:
        return None

    # A lookbehind `(?<=...)` in Python's `re` module requires the pattern inside
    # to have a fixed string length. The previous implementation used a variable-length
    # lookbehind, causing a `re.error`. This new implementation is more robust and
    # does not use lookbehinds.

    patterns = [
        # Pattern 1: Most specific. Looks for `arxiv: "query"`
        re.compile(r'arxiv\s*:\s*\"([^\"]+)\"', re.IGNORECASE),
        
        # Pattern 2: General fallback for `recherche sur arxiv: "query"`
        re.compile(r'recherche sur arxiv[^:]*:\s*\"([^\"]+)\"', re.IGNORECASE),
        
        # Pattern 3: Looks for a query within a "Search Queries" or "Requêtes de
        # recherche" section, handling markdown lists and optional quotes.
        re.compile(
            r"(?:search queries|requêtes de recherche):.*?(?:-|\*)\s*arxiv\s*:\s*\"?([^\n\"]+)\"?",
            re.IGNORECASE | re.DOTALL
        )
    ]

    for i, pattern in enumerate(patterns, 1):
        match = pattern.search(plan)
        if match:
            # The query is expected to be in the last captured group.
            query = match.groups()[-1].strip()
            if query:
                logger.info(f"Extracted ArXiv query from plan (pattern {i}): '{query}'")
                return query

    logger.warning("Could not extract a specific ArXiv query from the plan.")
    return None


async def arxiv_search_node(state: GraphState) -> Dict[str, Any]:
    """
    Executes the ArXiv search agent based on the research plan.

    This node determines the best query to use (either from the planner or the
    original user query), runs the ArXiv search agent, and formats the results.
    """
    logger.info("--- ARXIV SEARCH NODE ---")
    query_for_search = state.get("arxiv_query_for_searcher") or state.get("user_query")
    if not query_for_search:
        logger.error("No query available for ArXiv search.")
        return {
            "messages": [AIMessage(content="Cannot perform ArXiv search: No query provided.")],
            "error_message": "No query for ArXiv search",
        }

    # The prompt now clearly instructs the agent to use its tools.
    search_prompt = f"""
Based on the user's request, search for relevant scientific papers on ArXiv.

User request: "{query_for_search}"

Your task is to use the `arxiv_search` tool to find the most relevant papers.
Return the search results directly.
"""
    logger.debug(f"ArXiv search prompt: {search_prompt}")

    # The agent is invoked with a focused prompt, not the whole message history.
    agent_input = {"messages": [HumanMessage(content=search_prompt)]}

    try:
        response = await arxiv_search_agent_executor.ainvoke(agent_input)
        logger.debug(f"Raw response from ArxivSearchAgent: {response}")

        # The output extraction is now more robust.
        search_results_content = _extract_tool_or_ai_message_content(response)

        if not search_results_content:
            logger.error("No search results found in ArxivSearchAgent response.")
            return {
                "messages": [AIMessage(content="ArXiv Search: Failed to get search results.")],
                "error_message": "No search results from ArxivSearchAgent",
            }

        formatted_results = format_arxiv_results(search_results_content)
        num_papers = (
            len(formatted_results.split("\n\n---\n\n")) if formatted_results else 0
        )
        logger.info(f"Found {num_papers} relevant papers from ArXiv.")

        return {
            "arxiv_search_results_str": formatted_results,
            "messages": [
                AIMessage(
                    content=f"ArXiv Search: Found {num_papers} relevant papers.\n\n{formatted_results}"
                )
            ],
            "error_message": None,
        }
    except Exception as e:
        logger.error(f"Error in ArxivSearchAgent execution: {e}", exc_info=True)
        return {
            "messages": [AIMessage(content=f"Error during ArXiv search: {e}")],
            "error_message": str(e),
        }


def _extract_tool_or_ai_message_content(response: Dict[str, Any]) -> List[Any]:
    """Extracts content from ToolMessage or AIMessage in the agent response."""
    results = []
    if response.get("messages"):
        for msg in response["messages"]:
            if isinstance(msg, (ToolMessage, AIMessage)) and msg.content:
                logger.debug(f"Found {type(msg).__name__} with content.")
                results.append(msg.content)
    # Fallback to 'output' key.
    if not results and response.get("output"):
        logger.debug("No messages with content, falling back to 'output' key.")
        results.append(response["output"])
    return results


def format_arxiv_results(tool_output: List[Any]) -> str:
    """
    Formats ArXiv search results into a readable string.

    Args:
        tool_output: The raw list of outputs from the search tool.

    Returns:
        A formatted string with each paper's details separated.
    """
    if not isinstance(tool_output, list):
        return str(tool_output)

    formatted_items = []
    for item in tool_output:
        # The tool might return a list of dicts, or a single string/dict.
        if isinstance(item, list):
            for sub_item in item:
                if isinstance(sub_item, dict):
                    formatted_items.append(_format_paper_dict(sub_item))
                else:
                    formatted_items.append(str(sub_item))
        elif isinstance(item, dict):
            formatted_items.append(_format_paper_dict(item))
        else:
            formatted_items.append(str(item))

    return "\n\n---\n\n".join(filter(None, formatted_items))


def _format_paper_dict(paper: Dict[str, Any]) -> str:
    """Formats a single paper dictionary into a string."""
    title = paper.get("title", "N/A")
    summary = paper.get("summary", "N/A").strip()
    authors = ", ".join(paper.get("authors", []))
    pdf_url = paper.get("pdf_url", "N/A")
    return f"Title: {title}\nAuthors: {authors}\nSummary: {summary}\nLink: {pdf_url}"


async def document_analysis_node(state: GraphState) -> Dict[str, Any]:
    """
    Executes the document analysis agent.

    This node is crucial. It takes the search results and instructs an agent
    to perform a deep analysis. The prompt explicitly gives the agent the
    option to use the `document_deep_dive_analysis_tool` for a more thorough
    investigation if the summaries are insufficient.
    """
    logger.info("--- DOCUMENT ANALYSIS NODE ---")
    arxiv_results = state.get("arxiv_search_results_str")
    if not arxiv_results:
        logger.warning("No ArXiv results found for analysis, skipping node.")
        return {
            "messages": [
                AIMessage(content="Document Analysis: No ArXiv results to analyze.")
            ],
            "error_message": "No ArXiv results for analysis",
        }

    # This prompt is significantly improved. It gives clear instructions and context.
    # It empowers the agent to use the deep dive tool if needed.
    analysis_prompt = f"""
**Context:**
You are a research analyst. You have been provided with a list of scientific papers (with summaries and links) from ArXiv. Your goal is to produce a comprehensive analysis of the topic.

**Your Task:**
1.  **Initial Review:** First, review the titles and summaries of the papers provided below to get an overview.
2.  **Deeper Analysis (Optional but Recommended):** The summaries are a good starting point, but may be insufficient for a deep, high-quality analysis. For the most promising papers, you are **strongly encouraged** to use the `document_deep_dive_analysis_tool`. This tool will read the full content of the PDF and provide a detailed analysis.
3.  **Synthesize Findings:** Based on your review of the summaries and any deep dives you perform, synthesize your findings into a comprehensive analysis.

**Input - ArXiv Search Results:**
{arxiv_results}

**Instructions for your final output:**
Structure your analysis to include:
- Key breakthroughs and innovations.
- Emerging trends and new methodologies.
- Practical applications and potential impact.
- Contradictory findings or open questions.
- Challenges and limitations discussed in the papers.
- Suggestions for future research directions.

Begin your analysis now.
"""
    logger.debug("Analysis prompt for DocumentAnalyzerAgent is ready.")

    agent_input = {"messages": [HumanMessage(content=analysis_prompt)]}
    response = run_agent_node(
        agent_input, doc_analysis_agent_executor, "DocumentAnalyzerAgent"
    )

    analysis = _get_agent_output(response, "DocumentAnalyzerAgent")
    if not analysis:
        logger.error("DocumentAnalyzerAgent failed to produce any output.")
        return {
            "messages": [AIMessage(content="Document Analysis: Failed to produce output.")],
            "error_message": "Document analysis failed to produce output",
        }

    logger.info(f"Document Analysis Output:\n{analysis}")
    return {
        "document_analysis_summary": analysis,
        "messages": [AIMessage(content=f"Document Analysis Result:\n\n{analysis}")],
        "error_message": None,
    }


async def synthesis_node(state: GraphState) -> Dict[str, Any]:
    """
    Synthesizes the final report from the collected analysis.

    This final node takes the detailed analysis and formats it into a polished,
    final report for the user.
    """
    logger.info("--- SYNTHESIS NODE ---")
    analysis = state.get("document_analysis_summary")
    if not analysis:
        logger.warning("No document analysis summary found for synthesis.")
        return {
            "messages": [AIMessage(content="Synthesis: No analysis available.")],
            "error_message": "No analysis available for synthesis",
        }

    # The synthesis prompt is now more structured.
    synthesis_prompt = f"""
**Role:** You are a senior research editor.
**Task:** Transform the detailed technical analysis provided below into a clear, well-structured, and insightful final report for a user.

**Input - Detailed Analysis:**
---
{analysis}
---

**Instructions for the Final Report:**
Your final output should be a comprehensive and polished synthesis. Structure your response as follows:

1.  **Executive Summary:** Start with a brief, high-level summary of the most critical findings.
2.  **Key Developments:** Detail the most significant recent developments and breakthroughs identified in the analysis.
3.  **Emerging Trends:** Discuss the key trends, methodologies, and technologies that are gaining traction.
4.  **Applications & Impact:** Explain the real-world applications and potential impact of these advancements.
5.  **Challenges & Future Outlook:** Conclude with the current challenges, limitations, and a forward-looking perspective on future research directions.

Focus on providing actionable insights and clear explanations, avoiding overly technical jargon where possible.
"""
    logger.debug("Synthesis prompt is ready.")

    try:
        response = await synthesis_agent_executor.ainvoke(
            {"messages": [HumanMessage(content=synthesis_prompt)]}
        )
        synthesis_content = _get_agent_output(response, "SynthesisAgent")

        if not synthesis_content:
            logger.error("Synthesis agent failed to produce a valid response.")
            return {
                "messages": [AIMessage(content="Synthesis: Failed to generate a valid synthesis.")],
                "error_message": "Synthesis generation failed",
            }

        logger.info(f"Final Synthesis Output:\n{synthesis_content}")
        return {
            "synthesis_output": synthesis_content,
            "messages": [AIMessage(content=f"Final Synthesis:\n\n{synthesis_content}")],
            "error_message": None,
        }
    except Exception as e:
        logger.error(f"Error in synthesis node: {e}", exc_info=True)
        return {
            "messages": [AIMessage(content=f"Synthesis: Error during execution: {e}")],
            "error_message": str(e),
        }


def router_after_planner(state: GraphState) -> str:
    """Routes the workflow after the planner node."""
    logger.info("--- ROUTER (after Planner) ---")
    if state.get("error_message"):
        logger.error(f"Error detected: {state['error_message']}. Ending workflow.")
        return END
    logger.info("Decision: Proceed to ArXiv Search.")
    return "arxiv_searcher"


def router_after_arxiv_search(state: GraphState) -> str:
    """Routes the workflow after the ArXiv search node."""
    logger.info("--- ROUTER (after ArXiv Search) ---")
    if state.get("error_message"):
        logger.error(f"Error detected: {state['error_message']}. Ending workflow.")
        return END
    logger.info("Decision: Proceed to Document Analysis.")
    return "document_analyzer"


def router_after_document_analysis(state: GraphState) -> str:
    """Routes the workflow after the document analysis node."""
    logger.info("--- ROUTER (after Document Analysis) ---")
    if state.get("error_message"):
        logger.error(f"Error detected: {state['error_message']}. Ending workflow.")
        return END
    logger.info("Decision: Proceed to Synthesis.")
    return "synthesis"


def create_workflow_graph() -> StateGraph:
    """
    Creates and configures the main research workflow graph.

    Returns:
        A compiled StateGraph instance ready for execution.
    """
    workflow = StateGraph(GraphState)

    # Add nodes to the graph
    workflow.add_node("planner", planner_node)
    workflow.add_node("arxiv_searcher", arxiv_search_node)
    workflow.add_node("document_analyzer", document_analysis_node)
    workflow.add_node("synthesis", synthesis_node)

    # Set the entry point
    workflow.set_entry_point("planner")

    # Add conditional edges for routing
    workflow.add_conditional_edges(
        "planner",
        router_after_planner,
        {"arxiv_searcher": "arxiv_searcher", END: END},
    )
    workflow.add_conditional_edges(
        "arxiv_searcher",
        router_after_arxiv_search,
        {"document_analyzer": "document_analyzer", END: END},
    )
    workflow.add_conditional_edges(
        "document_analyzer",
        router_after_document_analysis,
        {"synthesis": "synthesis", END: END},
    )

    # The synthesis node is the final step
    workflow.add_edge("synthesis", END)
    
    # Compile the graph with the checkpointer
    checkpointer = MongoDBSaver(
        collection_name=settings.LANGGRAPH_CHECKPOINTS_COLLECTION
    )
    return workflow.compile(checkpointer=checkpointer)

# Create a single compiled instance of the graph
app = create_workflow_graph()


async def run_workflow(query: str, thread_id: Optional[str] = None) -> Dict[str, Any]:
    """
    Runs the research workflow for a given query.

    Args:
        query: The user's research query.
        thread_id: An optional ID to resume a previous workflow. If not provided,
                   a new one is generated.

    Returns:
        A dictionary containing the final results of the workflow.
    """
    if not thread_id:
        thread_id = str(uuid.uuid4())
    logger.info(f"Starting workflow for query: '{query}' with thread_id: {thread_id}")

    try:
        initial_state = {"messages": [HumanMessage(content=query)], "user_query": query}
        config = {"configurable": {"thread_id": thread_id}}

        final_state = await app.ainvoke(initial_state, config=config)

        synthesis = final_state.get("synthesis_output", "No synthesis available.")
        logger.info("Workflow completed successfully.")
        return {"thread_id": thread_id, "result": final_state, "synthesis": synthesis}

    except Exception as e:
        logger.error(f"Workflow execution failed for thread_id {thread_id}: {e}", exc_info=True)
        return {"thread_id": thread_id, "error": str(e)}


async def main():
    """
    Main function to run a test of the research workflow.
    """
    test_query = "What are the latest developments in explainable AI (XAI)?"
    result = await run_workflow(test_query)

    print("\n--- WORKFLOW EXECUTION FINISHED ---")
    if "error" in result:
        print(f"\nTest failed: {result['error']}")
    else:
        print("\nTest completed successfully!")
        print(f"Thread ID: {result['thread_id']}")
        print("\n--- FINAL SYNTHESIS ---")
        print(result.get("synthesis", "Not available."))
    print("---------------------------------")


if __name__ == "__main__":
    import asyncio
    from config.logging_config import setup_logging

    # Configure logging for rich output
    setup_logging(level="INFO")
    asyncio.run(main())