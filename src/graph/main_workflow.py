# cognitive-swarm-agents/src/graph/main_workflow.py
import logging
import uuid
from typing import TypedDict, Annotated, List, Optional, Dict, Any
import operator 
import datetime 

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.base import BaseCheckpointSaver
from langgraph.prebuilt import ToolNode, tools_condition 

from config.settings import settings
from src.agents.agent_architectures import (
    create_research_planner_agent,
    create_arxiv_search_agent,
    create_document_analysis_agent, # Cette fonction retourne maintenant un agent avec le nouvel outil
    create_synthesis_agent,
    get_llm 
)
from src.agents.tool_definitions import (
    arxiv_search_tool,
    knowledge_base_retrieval_tool,
    document_deep_dive_analysis_tool # <<< MODIFICATION : Importer le nouvel outil
)
from src.graph.checkpointer import MongoDBSaver 

logger = logging.getLogger(__name__)

# --- Définition de l'État du Graphe (inchangé) ---
class GraphState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add] 
    user_query: str
    research_plan: Optional[str] = None
    arxiv_query_for_searcher: Optional[str] = None 
    kb_query_for_analyzer: Optional[str] = None
    arxiv_search_results: Optional[List[Dict[str, Any]]] = None 
    document_analysis_summary: Optional[str] = None 
    synthesis_output: Optional[str] = None
    error_message: Optional[str] = None

# --- Liste des Outils et ToolNode (MODIFIÉ) ---
all_tools = [
    arxiv_search_tool, 
    knowledge_base_retrieval_tool,
    document_deep_dive_analysis_tool # <<< MODIFICATION : Ajout du nouvel outil à la liste
]
tool_node = ToolNode(all_tools)

# --- Initialisation des Agents (inchangé) ---
planner_agent_executor = create_research_planner_agent()
arxiv_search_agent_executor = create_arxiv_search_agent()
# create_document_analysis_agent() va maintenant retourner un agent qui connaît le deep_dive_tool
doc_analysis_agent_executor = create_document_analysis_agent() 
synthesis_agent_executor = create_synthesis_agent()

# --- Nœuds du Graphe (Wrapper pour Agents - inchangés en structure, mais doc_analysis_agent_executor est mis à jour) ---
def run_agent_node(state: GraphState, agent_executor, node_name: str, input_override: Optional[str] = None) -> Dict[str, Any]:
    logger.debug(f"--- EXECUTING AGENT NODE: {node_name} ---")
    current_messages = state["messages"]
    if input_override:
        messages_for_agent = current_messages + [HumanMessage(content=input_override)]
    else:
        messages_for_agent = current_messages

    try:
        response = agent_executor.invoke({"messages": messages_for_agent})
        output_content = str(response.get("output", ""))
        
        # Gestion des tool_calls si présents dans la réponse de l'agent
        agent_tool_calls = response.get("tool_calls") # OpenAI tools agent specific
        if not agent_tool_calls and hasattr(response, 'tool_calls'): # Check attribute if dict key missing
            agent_tool_calls = response.tool_calls

        if agent_tool_calls:
            ai_message_with_tool_calls = AIMessage(content=output_content, tool_calls=agent_tool_calls, name=node_name)
            return {"messages": [ai_message_with_tool_calls]}
        else:
            return {"messages": [AIMessage(content=output_content, name=node_name)]}

    except Exception as e:
        logger.error(f"Error in agent node {node_name}: {e}", exc_info=True)
        error_content = f"Error in {node_name}: {str(e)}"
        return {"messages": [AIMessage(content=error_content, name="error_handler")], "error_message": error_content}

def planner_node(state: GraphState) -> Dict[str, Any]:
    logger.info(">>> Planner Node <<<")
    update = run_agent_node(state, planner_agent_executor, "ResearchPlannerAgent")
    if update.get("messages") and isinstance(update["messages"][-1], AIMessage):
        plan_content = update["messages"][-1].content
        logger.info(f"Research Plan Generated by Planner:\n{plan_content}")
        return {**update, "research_plan": plan_content}
    return update

def arxiv_search_node_wrapper(state: GraphState) -> Dict[str, Any]:
    logger.info(">>> ArXiv Search Node <<<")
    query_for_arxiv = state.get("arxiv_query_for_searcher") or state.get("user_query")
    instruction = f"Based on the research plan, please search ArXiv. Specific query to prioritize: '{query_for_arxiv}'."
    if state.get("research_plan"):
        instruction = f"Research Plan:\n{state['research_plan']}\n\nTask: Execute ArXiv searches as suggested in the plan. Prioritize query: '{query_for_arxiv}' if specified, otherwise use plan context for search terms."
    return run_agent_node(state, arxiv_search_agent_executor, "ArxivSearchAgent", input_override=instruction)

def document_analysis_node_wrapper(state: GraphState) -> Dict[str, Any]:
    logger.info(">>> Document Analysis Node <<<")
    query_for_kb = state.get("kb_query_for_analyzer") or state.get("user_query")
    instruction = f"Analyze documents from the knowledge base related to: '{query_for_kb}'."
    context_from_messages = "\n".join([msg.content for msg in state["messages"] if isinstance(msg, (ToolMessage, AIMessage)) and (msg.name == "ArxivSearchAgent" or (hasattr(msg, 'tool_calls') and not msg.tool_calls))]) # Get content from previous non-tool-calling AI messages or tool messages
    
    if state.get("research_plan"):
        instruction = f"Research Plan:\n{state['research_plan']}\n\n"
    instruction += f"Task: Execute knowledge base searches and analysis as per the plan or query. Prioritize query: '{query_for_kb}' if specified. If a deep, structured analysis of a *single specific document* is required by the plan or query, use the 'document_deep_dive_analysis_tool'. You will need its ID and full content."
    if context_from_messages:
        instruction += f"\n\nConsider also the following context from previous steps (e.g. new ArXiv findings or KB chunks):\n{context_from_messages[:1000]}..."

    update = run_agent_node(state, doc_analysis_agent_executor, "DocumentAnalysisAgent", input_override=instruction)
    
    last_message = update.get("messages", [])[-1] if update.get("messages") else None
    if isinstance(last_message, AIMessage) and not last_message.tool_calls:
        analysis_summary = last_message.content
        # Si c'est le résultat d'un deep_dive_tool, il sera déjà détaillé.
        # Si c'est une analyse plus simple, ce sera le résumé de l'agent.
        logger.info(f"Document Analysis Output (summary or deep dive report): {analysis_summary[:300]}...")
        return {**update, "document_analysis_summary": analysis_summary}
    return update

def synthesis_node_wrapper(state: GraphState) -> Dict[str, Any]:
    logger.info(">>> Synthesis Node <<<")
    update = run_agent_node(state, synthesis_agent_executor, "SynthesisAgent")
    if update.get("messages") and isinstance(update["messages"][-1], AIMessage):
        final_output = update["messages"][-1].content
        return {**update, "synthesis_output": final_output}
    return update

# --- Nœud Routeur (inchangé) ---
def router_after_planner(state: GraphState) -> str:
    logger.info(">>> Router after Planner <<<")
    if state.get("error_message"):
        logger.error(f"Error detected in state: {state['error_message']}. Ending.")
        return END 
    plan = state.get("research_plan", "").lower()
    if "new arxiv search" in plan or "latest papers" in plan or "search arxiv" in plan:
        logger.info("Router decision: Go to ArXiv Search.")
        return "arxiv_searcher"
    else:
        logger.info("Router decision: Go to Document Analysis (Knowledge Base).")
        return "doc_analyzer"

# --- Construction du Graphe (inchangé en structure, mais ToolNode est mis à jour) ---
workflow_v2_1 = StateGraph(GraphState)

workflow_v2_1.add_node("planner", planner_node)
workflow_v2_1.add_node("arxiv_searcher", arxiv_search_node_wrapper)
workflow_v2_1.add_node("doc_analyzer", document_analysis_node_wrapper)
workflow_v2_1.add_node("synthesizer", synthesis_node_wrapper)
workflow_v2_1.add_node("tools_invoker", tool_node) # Ce ToolNode connaît maintenant tous les outils

workflow_v2_1.set_entry_point("planner")

workflow_v2_1.add_conditional_edges(
    "planner",
    router_after_planner,
    {"arxiv_searcher": "arxiv_searcher", "doc_analyzer": "doc_analyzer", END: END}
)
workflow_v2_1.add_conditional_edges(
    "arxiv_searcher",
    tools_condition, 
    {"tools_invoker": "tools_invoker", END: "doc_analyzer"}
)
workflow_v2_1.add_conditional_edges(
    "doc_analyzer",
    tools_condition,
    {"tools_invoker": "tools_invoker", END: "synthesizer"}
)
# Pas d'arête explicite DEPUIS tools_invoker car LangGraph gère le retour à l'agent appelant
# pour que tools_condition soit réévalué sur cet agent.
workflow_v2_1.add_edge("synthesizer", END)

# --- Compilation du Graphe (inchangé) ---
mongo_checkpointer = MongoDBSaver() 
graph_app_v2_1 = workflow_v2_1.compile(checkpointer=mongo_checkpointer)
# graph_app_v2_1 = workflow_v2_1.compile() # Sans checkpointer pour tests rapides


# --- Fonction d'Exécution (inchangée) ---
async def run_cognitive_swarm_v2_1(query: str, thread_id: Optional[str] = None) -> Dict[str, Any]:
    if not thread_id:
        thread_id = "swarm_thread_" + str(uuid.uuid4())
    config = {"configurable": {"thread_id": thread_id}}
    initial_messages: List[BaseMessage] = [HumanMessage(content=query)]
    initial_state: GraphState = {
        "messages": initial_messages, "user_query": query, "research_plan": None,
        "arxiv_query_for_searcher": None, "kb_query_for_analyzer": None,
        "arxiv_search_results": None, "document_analysis_summary": None,
        "synthesis_output": None, "error_message": None,
    }
    logger.info(f"Running Cognitive Swarm V2.1 for query: '{query}' with thread_id: {thread_id}")
    full_final_state = None
    async for event in graph_app_v2_1.astream_events(initial_state, config=config, version="v2"):
        kind = event["event"]
        if kind == "on_chat_model_stream":
            content = event["data"]["chunk"].content
            if content: print(content, end="", flush=True)
        elif kind == "on_tool_start":
            logger.debug(f"Tool Start: {event['name']} with input {event['data'].get('input')}")
            print(f"\n[Tool Start: {event['name']}]", flush=True)
        elif kind == "on_tool_end":
            tool_output = event['data'].get('output')
            logger.debug(f"Tool End: {event['name']} with output: {str(tool_output)[:200]}...")
            if isinstance(tool_output, str) and len(tool_output) < 500:
                 print(f"\n[Tool Output ({event['name']}): {tool_output}]", flush=True)
            else:
                 print(f"\n[Tool Output ({event['name']}): Received (output might be long or complex)]", flush=True)
        elif kind == "on_chain_end" or kind == "on_llm_end":
            node_name = event['name']
            if node_name in ["planner", "arxiv_searcher", "doc_analyzer", "synthesizer"]:
                output_data = event['data'].get('output')
                final_content = None
                if isinstance(output_data, dict): 
                    final_content = output_data.get('output') 
                    if not final_content and 'messages' in output_data and isinstance(output_data['messages'], list) and output_data['messages']:
                        last_msg = output_data['messages'][-1]
                        if hasattr(last_msg, 'content'): final_content = last_msg.content
                elif hasattr(output_data, 'generations'): 
                    try: final_content = output_data.generations[0][0].message.content
                    except: final_content = str(output_data)
                else: final_content = str(output_data)
                if final_content and isinstance(final_content, str):
                    print(f"\nOutput from {node_name}:\n{final_content[:1000]}...\n---", flush=True)
        if event["event"] == "on_graph_end":
            full_final_state = event["data"].get("output")
            logger.info("Graph execution finished (on_graph_end event).")

    if full_final_state:
        logger.info(f"Cognitive Swarm V2.1 finished for thread_id: {thread_id}. Final synthesis: {str(full_final_state.get('synthesis_output'))[:200]}...")
        return full_final_state
    else:
        try:
            last_state_snapshot = await graph_app_v2_1.aget_state(config)
            if last_state_snapshot:
                logger.info(f"Last known state from checkpointer for thread_id {thread_id}: {last_state_snapshot.values}")
                return last_state_snapshot.values 
            else:
                logger.error(f"No state could be retrieved from checkpointer for thread_id {thread_id}.")
                return {"error_message": "Execution completed, but no final state could be retrieved."}
        except Exception as e_chk:
            logger.error(f"Could not retrieve last state for thread_id {thread_id} from checkpointer: {e_chk}", exc_info=True)
            return {"error_message": f"Execution finished but final state could not be determined due to: {str(e_chk)}"}

if __name__ == "__main__":
    import asyncio
    from config.logging_config import setup_logging
    setup_logging(level="DEBUG" if settings.DEBUG else "INFO")

    async def main_test_v2_1():
        logger.info("--- Testing Main Workflow V2.1 (with updated tools) ---")
        if not settings.OPENAI_API_KEY:
             logger.error("OPENAI_API_KEY not found. Workflow test will likely fail.")
             return
        
        # Test avec une requête qui pourrait bénéficier du deep dive tool
        # Le DocumentAnalysisAgent doit être prompté pour utiliser le deep_dive_tool.
        # Son prompt actuel lui dit de l'utiliser si la tâche demande explicitement un "deep dive"
        # ou une "analyse structurée" d'un document unique.
        # Le planner pourrait générer une telle instruction.
        
        # Exemple de requête qui pourrait mener à un deep dive si le planner le demande
        test_query = (
            "I need a deep dive analysis of a key paper on 'sim-to-real transfer in robotics using domain randomization', focusing on its methodology and limitations. "
            "First, find such a key paper if one isn't immediately obvious in the knowledge base."
        )
        
        thread_for_test = "swarm_hybrid_test_" + str(uuid.uuid4())
        logger.info(f"\n--- Running V2.1 for query: '{test_query}' (Thread: {thread_for_test}) ---")
        
        print(f"\n\nStarting Cognitive Swarm for query: \"{test_query}\"\n")
        final_state = await run_cognitive_swarm_v2_1(test_query, thread_id=thread_for_test)
        
        print("\n\n--- Cognitive Swarm V2.1 Execution Finished ---")
        if final_state:
            print("\nFinal Graph State Snapshot:")
            sorted_keys = sorted(final_state.keys())
            for key in sorted_keys:
                value = final_state[key]
                if key == "messages":
                    print(f"  {key} (last {min(5, len(value))} messages):") # Afficher plus de messages
                    for msg in value[-5:]: 
                        msg_type = getattr(msg, 'type', 'UNKNOWN_MSG_TYPE').upper()
                        msg_name = getattr(msg, 'name', None)
                        msg_content_str = str(getattr(msg, 'content', 'N/A'))
                        display_name = f"{msg_type} ({msg_name})" if msg_name else msg_type
                        if hasattr(msg, 'tool_calls') and msg.tool_calls: 
                            print(f"    └─ {display_name}: {msg_content_str[:100]}... [Tool Calls: {len(msg.tool_calls)}]") 
                        elif msg_type == "TOOL": 
                            tool_call_id = getattr(msg, 'tool_call_id', 'N/A')
                            print(f"    └─ {display_name} (ID: {tool_call_id}): {msg_content_str[:150]}...")
                        else:
                            print(f"    └─ {display_name}: {msg_content_str[:150]}...")
                else:
                    print(f"  {key}: {str(value)[:300]}...")
            
            if final_state.get("synthesis_output"):
                print("\n\n====== FINAL SYNTHESIS ======")
                print(final_state["synthesis_output"])
            elif final_state.get("error_message"):
                print(f"\n\n====== EXECUTION ERROR ======")
                print(final_state["error_message"])
            else:
                print("\n\n====== EXECUTION COMPLETED (No explicit synthesis output or error found in final state fields) ======")

        global mongo_checkpointer 
        if 'mongo_checkpointer' in globals() and mongo_checkpointer and hasattr(mongo_checkpointer, 'aclose'):
            await mongo_checkpointer.aclose()
            logger.info("MongoDBSaver client closed via aclose().")

    asyncio.run(main_test_v2_1())