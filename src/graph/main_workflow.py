"""
Main Workflow Module

This module implements the main workflow for the research assistant system using LangGraph.
It defines the state management, node functions, and routing logic for the research process.

Key features:
- State management with GraphState
- Agent node execution and routing
- Tool integration and execution
- Error handling and logging
"""

import logging
import uuid
import re
from typing import TypedDict, Annotated, List, Optional, Dict, Any
import operator
import datetime

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode, tools_condition
from langchain.agents import AgentExecutor

from config.settings import settings
from src.agents.agent_architectures import (
    create_research_planner_agent,
    create_arxiv_search_agent,
    create_document_analysis_agent,
    create_synthesis_agent
)
from src.agents.tool_definitions import (
    arxiv_search_tool,
    knowledge_base_retrieval_tool,
    document_deep_dive_analysis_tool
)
from src.graph.checkpointer import MongoDBSaver

logger = logging.getLogger(__name__)

class GraphState(TypedDict):
    """
    Represents the state of the research workflow graph.
    
    Attributes:
        messages: List of messages in the conversation
        user_query: Original user query
        research_plan: Generated research plan
        arxiv_query_for_searcher: Query for ArXiv search
        kb_query_for_analyzer: Query for knowledge base
        arxiv_search_results_str: Results from ArXiv search
        document_analysis_summary: Summary of document analysis
        synthesis_output: Final synthesis output
        error_message: Any error message
    """
    messages: Annotated[List[BaseMessage], operator.add]
    user_query: str
    research_plan: Optional[str] = None
    arxiv_query_for_searcher: Optional[str] = None
    kb_query_for_analyzer: Optional[str] = None
    arxiv_search_results_str: Optional[str] = None
    document_analysis_summary: Optional[str] = None
    synthesis_output: Optional[str] = None
    error_message: Optional[str] = None

# Initialize tools and agents
all_tools = [
    arxiv_search_tool,
    knowledge_base_retrieval_tool,
    document_deep_dive_analysis_tool
]
tool_node = ToolNode(all_tools)

planner_agent_executor = create_research_planner_agent()
arxiv_search_agent_executor = create_arxiv_search_agent()
doc_analysis_agent_executor = create_document_analysis_agent()
synthesis_agent_executor = create_synthesis_agent()

def run_agent_node(state: GraphState, agent_executor: AgentExecutor, agent_name: str) -> Dict[str, Any]:
    """Run an agent node and return its output."""
    try:
        logger.info(f">>> {agent_name} <<<")
        # Only pass the expected keys to the agent
        agent_input = {
            "messages": state["messages"],
            "agent_scratchpad": state.get("agent_scratchpad", [])
        }
        response = agent_executor.invoke(agent_input)
        
        if response.get("messages"):
            for msg in response["messages"]:
                if isinstance(msg, AIMessage):
                    logger.info(f"{agent_name} Output:\n{msg.content}")
                elif isinstance(msg, HumanMessage):
                    logger.debug(f"Human Input: {msg.content}")
        
        return response
    except Exception as e:
        logger.error(f"Error in {agent_name}: {e}")
        raise

def planner_node(state: GraphState) -> Dict[str, Any]:
    """Execute the research planner node."""
    logger.info(">>> Research Planner Node <<<")
    
    # Run planner agent
    update = run_agent_node(state, planner_agent_executor, "ResearchPlannerAgent")
    
    # Extract plan from the last AIMessage
    plan = ""
    if update.get("messages"):
        for msg in reversed(update.get("messages", [])): # Iterate in reverse to find the last AIMessage
            if isinstance(msg, AIMessage) and msg.content:
                plan = msg.content
                logger.info(f"Research Plan Output:\n{plan}")
                break # Found the last AIMessage with content

    if not plan and "output" in update: # Fallback to "output" key
        plan = str(update["output"])
        logger.info(f"Research Plan Output (from 'output' key):\n{plan}")

    if not plan:
        logger.error("No plan generated by ResearchPlannerAgent")
        return {
            # Still return previous messages if an error occurs, plus the error message
            "messages": state.get("messages", []) + [
                AIMessage(content="Failed to generate a research plan. Please try again.")
            ],
            "error_message": "No plan generated",
            "research_plan": None # Ensure research_plan is None on error
        }
        
    # Extract ArXiv query (if any)
    arxiv_query = extract_arxiv_query(plan)
    
    return {
        "research_plan": plan,
        "arxiv_query_for_searcher": arxiv_query,
        "messages": [AIMessage(content=plan)], # Return only the new plan message
        "error_message": None # Clear any previous error
    }

def extract_arxiv_query(plan: str) -> str:
    """
    Extract ArXiv query from research plan.
    
    Args:
        plan: Research plan text
        
    Returns:
        Extracted ArXiv query or empty string
    """
    if not plan:
        return ""
        
    plan_lines = plan.splitlines()
    in_search_queries_section = False
    extracted_query = ""
    
    for line in plan_lines:
        line_lower = line.lower()
        
        # Check for search queries section
        if "search queries:" in line_lower or "requÃªtes de recherche:" in line_lower:
            in_search_queries_section = True
            continue
            
        # Extract query from search queries section
        if in_search_queries_section and "arxiv" in line_lower:
            match = re.search(r"\"([^\"]+)\"", line)
            if match:
                extracted_query = match.group(1)
                if "arxiv" in extracted_query.lower() or "arxiv" in line_lower.split(extracted_query.lower())[-1]:
                    logger.info(f"Extracted explicit ArXiv query from plan: '{extracted_query}'")
                    break
                else:
                    extracted_query = ""
            else:
                potential_query = line.strip().lstrip('-').strip()
                if "arxiv" in potential_query.lower():
                    extracted_query = potential_query
                    logger.info(f"Extracted ArXiv query (no quotes): '{extracted_query}'")
                    break
                    
        if extracted_query and in_search_queries_section:
            break
            
    # Fallback: Check for ArXiv mention in plan
    if not extracted_query and "arxiv" in plan.lower():
        match = re.search(r"recherche sur arxiv[^:]*:\s*\"([^\"]+)\"", plan, re.IGNORECASE)
        if match:
            extracted_query = match.group(1)
            logger.info(f"Extracted ArXiv query from plan: '{extracted_query}'")
            
    return extracted_query

async def arxiv_search_node_wrapper(state: GraphState) -> Dict[str, Any]:
    """Wrapper for the ArXiv search node."""
    logger.info(">>> ArXiv Search Node <<<")
    
    # Create search prompt from research plan and user query
    # Prefer arxiv_query_for_searcher if available from planner, else fallback to user_query
    query_for_search = state.get("arxiv_query_for_searcher") or state.get("user_query", "")
    if not query_for_search:
        logger.error("No query available for ArXiv search (neither arxiv_query_for_searcher nor user_query is set).")
        return {
            "messages": [AIMessage(content="Cannot perform ArXiv search: No query provided.")],
            "error": "No query for ArXiv search",
            "arxiv_search_results_str": None
        }

    search_prompt = f"Search for papers about: {query_for_search}"
    logger.debug(f"ArXiv search prompt: {search_prompt}")
    
    # Prepare agent input, ensuring messages key is present for run_agent_node
    agent_input_state = state.copy()
    agent_input_state["messages"] = [HumanMessage(content=search_prompt)] # Agent gets focused input
    agent_input_state.pop("agent_scratchpad", None) # Clear scratchpad for this specific call

    try:
        # Run the ArXiv search agent
        logger.info(">>> ArxivSearchAgent <<<")
        # Pass the agent_input_state which has a focused messages list
        update = run_agent_node(agent_input_state, arxiv_search_agent_executor, "ArxivSearchAgent")
        
        logger.debug(f"Raw response from ArxivSearchAgent: {update}")
        
        # Extract search results
        search_results_content = []
        if update.get("messages"):
            for msg in update.get("messages", []):
                if isinstance(msg, ToolMessage):
                    logger.debug(f"Found tool message with content: {msg.content}")
                    search_results_content.append(msg.content)
                elif isinstance(msg, AIMessage) and msg.content: # Could be direct AI response if tool use failed/skipped
                    logger.debug(f"Found AI message with content: {msg.content}")
                    search_results_content.append(msg.content)
        
        if not search_results_content and 'output' in update and update['output']:
            logger.info("No ToolMessage/AIMessage with content found, using 'output' key from agent result.")
            search_results_content = [update['output']]
        
        if not search_results_content:
            logger.error("No search results found in ArxivSearchAgent response")
            return {
                "messages": [AIMessage(content="ArXiv Search: Failed to get search results.")],
                "error": "No search results from ArxivSearchAgent",
                "arxiv_search_results_str": None
            }
        
        formatted_results = format_arxiv_results(search_results_content)
        logger.debug(f"Formatted ArXiv search results: {formatted_results}")
        
        num_papers = len(formatted_results.split("\n\n---\n\n")) if formatted_results else 0
        
        return {
            "arxiv_search_results_str": formatted_results,
            "messages": [
                AIMessage(content=f"ArXiv Search: Found {num_papers} relevant papers.\n\n{formatted_results}")
            ],
            "error_message": None # Clear any previous error
        }
        
    except Exception as e:
        logger.error(f"Error in ArxivSearchAgent execution: {str(e)}", exc_info=True)
        return {
            "messages": [AIMessage(content=f"Error during ArXiv search: {str(e)}")],
            "error_message": str(e),
            "arxiv_search_results_str": None
        }

def format_arxiv_results(tool_output: Any) -> str:
    """
    Format ArXiv search results for analysis.
    
    Args:
        tool_output: Raw tool output
        
    Returns:
        Formatted results string
    """
    if isinstance(tool_output, list) and tool_output:
        formatted_results = []
        for item in tool_output:
            if isinstance(item, dict):
                title = item.get('title', 'N/A')
                summary = item.get('summary', 'N/A')
                authors = ", ".join(item.get('authors', []))
                pdf_url = item.get('pdf_url', '#')
                formatted_results.append(
                    f"Title: {title}\nAuthors: {authors}\nSummary: {summary}\nLink: {pdf_url}"
                )
            else:
                formatted_results.append(str(item))
        return "\n\n---\n\n".join(formatted_results)
    return str(tool_output)

def document_analysis_node_wrapper(state: GraphState) -> Dict[str, Any]:
    """Execute the document analysis node."""
    logger.info(">>> Document Analysis Node <<<")
    
    arxiv_results = state.get("arxiv_search_results_str", "")
    if not arxiv_results:
        logger.warning("No ArXiv results found for analysis")
        # Return a dictionary with only the new error message and relevant state updates
        return {
            "messages": [AIMessage(content="Document Analysis: No ArXiv results available for analysis.")],
            "error_message": "No ArXiv results available for analysis",
            "document_analysis_summary": None # Ensure summary is None on error
        }
    
    analysis_prompt = f"""Based on the following ArXiv search results, provide a comprehensive analysis of the latest advancements in machine learning:

{arxiv_results}

Please structure your analysis to include:
1. Key breakthroughs and innovations
2. Emerging trends and methodologies
3. Practical applications and use cases
4. Challenges and limitations
5. Future directions and opportunities

Focus on providing clear, actionable insights and explanations."""
    logger.debug(f"Analysis prompt for DocumentAnalyzerAgent: {analysis_prompt}")

    # Prepare a focused input for the DocumentAnalyzerAgent
    doc_analysis_agent_input_state = {
        "messages": [HumanMessage(content=analysis_prompt)],
        # agent_scratchpad is not explicitly passed if not needed or handled by run_agent_node's defaults
    }

    update = run_agent_node(
        doc_analysis_agent_input_state, # Pass the focused dict, not the full GraphState
        doc_analysis_agent_executor,
        "DocumentAnalyzerAgent"
    )
    
    logger.debug(f"Raw response from DocumentAnalyzerAgent: {update}")
    
    analysis = ""
    # Try to extract analysis from AIMessage first
    if update.get("messages"):
        for msg in reversed(update.get("messages", [])):
            if isinstance(msg, AIMessage) and msg.content:
                analysis = msg.content
                logger.debug(f"Extracted analysis from AIMessage: {analysis}")
                break
    
    # Fallback to 'output' key if no AIMessage content found
    if not analysis and update.get("output"):
        analysis = str(update["output"])
        logger.debug(f"Extracted analysis from agent 'output' key: {analysis}")

    if not analysis:
        logger.error("No analysis produced by DocumentAnalyzerAgent. Agent response: %s", update)
        return {
            "messages": [AIMessage(content="Document Analysis: Failed to produce output.")],
            "error_message": "Document analysis failed to produce output",
            "document_analysis_summary": None # Ensure summary is None on error
        }
    
    logger.info(f"Document Analysis Output:\n{analysis}")
    
    # Return a dictionary with only the new AIMessage and relevant state updates
    return {
        "document_analysis_summary": analysis,
        "messages": [AIMessage(content=f"Document Analysis Result:\n\n{analysis}")],
        "error_message": None # Clear any previous error
    }

async def synthesis_node(state: GraphState) -> Dict[str, Any]:
    """Synthesize the final output from all collected information."""
    try:
        logger.info(">>> Synthesis Node <<<")
        # Get the document analysis summary
        analysis = state.get("document_analysis_summary", "")
        if not analysis:
            logger.warning("No document analysis summary found for synthesis")
            return {
                "messages": [AIMessage(content="Synthesis: No analysis available to synthesize.")],
                "error_message": "No analysis available for synthesis",
                "synthesis_output": None # Ensure synthesis_output is None
            }

        # Create synthesis prompt
        synthesis_prompt = f"""Based on the following analysis, provide a comprehensive synthesis of the latest advancements in machine learning:

{analysis}

Please structure your response as a clear, well-organized summary that:
1. Highlights the most significant recent developments
2. Identifies key trends and breakthroughs
3. Discusses real-world applications
4. Addresses current challenges and future directions

Focus on providing actionable insights and clear explanations."""

        logger.debug(f"Synthesis prompt: {synthesis_prompt}")

        # Get synthesis from LLM
        synthesis_content = await get_llm_response(synthesis_prompt)
        logger.info(f"Final Synthesis Output:\n{synthesis_content}")
        
        if synthesis_content == "No response generated" or "Error generating response:" in synthesis_content:
             logger.error(f"Synthesis agent failed to produce a valid response: {synthesis_content}")
             return {
                "messages": [AIMessage(content=f"Synthesis: Failed to generate a valid synthesis. Details: {synthesis_content}")],
                "error_message": f"Synthesis generation failed: {synthesis_content}",
                "synthesis_output": None
            }

        return {
            "synthesis_output": synthesis_content,
            "messages": [AIMessage(content=f"Final Synthesis:\n\n{synthesis_content}")],
            "error_message": None # Clear any previous error
        }
        
    except Exception as e:
        logger.error(f"Error in synthesis node: {str(e)}", exc_info=True)
        return {
            "messages": [AIMessage(content=f"Synthesis: Error during synthesis execution: {str(e)}")],
            "error_message": str(e),
            "synthesis_output": None # Ensure synthesis_output is None
        }

def router_after_planner(state: GraphState) -> str:
    """
    Route after planner node execution.
    
    Args:
        state: Current graph state
        
    Returns:
        Next node to execute
    """
    logger.info(">>> Router after Planner <<<")
    
    if state.get("error_message"):
        logger.error(f"Error detected: {state['error_message']}. Ending.")
        return END 
    
    # Always go to ArXiv search for machine learning queries
    logger.info("Router decision: Go to ArXiv Search")
    return "arxiv_searcher"

def router_after_arxiv_search(state: GraphState) -> str:
    """
    Route after ArXiv search node execution.
    
    Args:
        state: Current graph state
        
    Returns:
        Next node to execute
    """
    logger.info(">>> Router after ArXiv Search <<<")
    
    if state.get("error_message"):
        logger.error(f"Error detected: {state['error_message']}. Ending.")
        return END
        
    return "document_analyzer"

def router_after_document_analysis(state: GraphState) -> str:
    """
    Route after document analysis node execution.
    
    Args:
        state: Current graph state
        
    Returns:
        Next node to execute
    """
    logger.info(">>> Router after Document Analysis <<<")
    
    if state.get("error_message"):
        logger.error(f"Error detected: {state['error_message']}. Ending.")
        return END
        
    return "synthesis"

def create_workflow_graph() -> StateGraph:
    """
    Create the workflow graph.
    
    Returns:
        Configured StateGraph instance
    """
    workflow = StateGraph(GraphState)
    
    # Add nodes
    workflow.add_node("planner", planner_node)
    workflow.add_node("arxiv_searcher", arxiv_search_node_wrapper)
    workflow.add_node("document_analyzer", document_analysis_node_wrapper)
    workflow.add_node("synthesis", synthesis_node)
    workflow.add_node("tools", tool_node)
    
    # Add conditional edges
    workflow.add_conditional_edges(
        "planner",
        router_after_planner,
        {
            "arxiv_searcher": "arxiv_searcher",
            "document_analyzer": "document_analyzer",
            END: END
        }
    )
    
    workflow.add_conditional_edges(
        "arxiv_searcher",
        router_after_arxiv_search,
        {
            "document_analyzer": "document_analyzer",
            END: END
        }
    )
    
    workflow.add_conditional_edges(
        "document_analyzer",
        router_after_document_analysis,
        {
            "synthesis": "synthesis",
            END: END
        }
    )
    
    # Add tool edges
    workflow.add_conditional_edges(
        "tools",
        tools_condition,
        {
            "arxiv_searcher": "arxiv_searcher",
            "document_analyzer": "document_analyzer",
            "synthesis": "synthesis",
            END: END
        }
    )
    
    # Set entry point
    workflow.set_entry_point("planner")
    
    return workflow

async def run_makers_v2_1(
    query: str,
    thread_id: Optional[str] = None
) -> Dict[str, Any]:
    """
    Run the research workflow.
    
    Args:
        query: User query
        thread_id: Optional thread ID for state management
        
    Returns:
        Workflow results
    """
    if not thread_id:
        thread_id = str(uuid.uuid4())
        
    # Create workflow graph
    workflow = create_workflow_graph()
    
    # Create checkpointer
    checkpointer = MongoDBSaver(
        collection_name=settings.LANGGRAPH_CHECKPOINTS_COLLECTION
    )
    
    # Compile workflow
    app = workflow.compile(checkpointer=checkpointer)
    
    # Run workflow
    try:
        # Create initial state with configuration
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "user_query": query
        }
        
        # Create configuration for the workflow
        config = {
            "configurable": {
                "thread_id": thread_id,
                "checkpoint_ns": "makers_workflow"
            }
        }
        
        # Run the workflow with the initial state and configuration
        result = await app.ainvoke(initial_state, config=config)
        
        # Extract synthesis from result
        synthesis = result.get("synthesis_output", "No synthesis available")
        
        return {
            "thread_id": thread_id,
            "result": result,
            "synthesis": synthesis
        }
        
    except Exception as e:
        logger.error(f"Error running workflow: {e}", exc_info=True)
        return {
            "thread_id": thread_id,
            "error": str(e)
        }

async def main_test_v2_1():
    """
    Run a test of the workflow.
    """
    test_query = "What are the latest developments in explainable AI?"
    result = await run_makers_v2_1(test_query)
    
    if "error" in result:
        logger.error(f"Test failed: {result['error']}")
    else:
        logger.info("Test completed successfully")
        logger.info(f"Thread ID: {result['thread_id']}")
        logger.info(f"Result: {result['result']}")

async def get_llm_response(prompt: str) -> str:
    """
    Get a response from the LLM for synthesis.
    
    Args:
        prompt: The prompt to send to the LLM
        
    Returns:
        The LLM's response as a string
    """
    try:
        # Use the synthesis agent to get the response
        response = await synthesis_agent_executor.ainvoke({"messages": [HumanMessage(content=prompt)]})
        logger.debug(f"Raw response from synthesis_agent_executor: {response}")
        
        # Try to get content from the last AIMessage
        if response.get("messages") and isinstance(response["messages"][-1], AIMessage):
            synthesis_content = response["messages"][-1].content
            if synthesis_content:
                logger.info(f"Extracted synthesis from AIMessage: {synthesis_content}")
                return synthesis_content
        
        # If not in AIMessage, try the 'output' key
        if response.get("output"):
            synthesis_content = str(response["output"])
            if synthesis_content:
                logger.info(f"Extracted synthesis from 'output' key: {synthesis_content}")
                return synthesis_content
                
        logger.warning(f"No synthesis content found in messages or output. Full response: {response}")
        return "No response generated"
    except Exception as e:
        logger.error(f"Error getting LLM response: {e}")
        return f"Error generating response: {str(e)}"

if __name__ == "__main__":
    import asyncio
    from config.logging_config import setup_logging
    
    setup_logging(level="INFO")
    asyncio.run(main_test_v2_1())