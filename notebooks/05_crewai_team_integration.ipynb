{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14b5a0d",
   "metadata": {},
   "source": [
    "# Notebook 05: Int√©gration et Test d'une √âquipe CrewAI (Document Deep Dive Crew)\n",
    "\n",
    "Ce notebook se concentre sur le test et la d√©monstration de notre √©quipe d'agents CrewAI sp√©cialis√©e dans l'analyse approfondie de documents : la `DocumentAnalysisCrew`. Nous allons instancier cette √©quipe en utilisant le module `src.agents.crewai_teams.document_analysis_crew`, lui soumettre un exemple de document et un focus de recherche, et examiner le rapport d'analyse qu'elle produit.\n",
    "\n",
    "**Pr√©requis :**\n",
    "* Environnement configur√© via `00_setup_environment.ipynb`.\n",
    "* Les biblioth√®ques `crewai` et `langchain-openai` (ou un autre fournisseur LLM configur√©) doivent √™tre install√©es (via `environment.yml` ou `requirements.txt`).\n",
    "* Une cl√© API OpenAI (`OPENAI_API_KEY`) doit √™tre configur√©e dans votre fichier `.env`, car les agents CrewAI l'utiliseront par d√©faut via la fonction `get_llm` de notre projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fa31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json # Pour un affichage lisible\n",
    "\n",
    "# Ajout de la racine du projet au PYTHONPATH\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "    print(f\"Ajout de {project_root} au PYTHONPATH\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "dotenv_path = project_root / \".env\"\n",
    "if dotenv_path.exists():\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "    print(f\"Variables d'environnement charg√©es depuis : {dotenv_path}\")\n",
    "else:\n",
    "    print(f\"ATTENTION: Fichier .env non trouv√© √† {dotenv_path}.\")\n",
    "\n",
    "from config.settings import settings\n",
    "from config.logging_config import setup_logging\n",
    "\n",
    "# Importer la fonction pour ex√©cuter notre √©quipe CrewAI\n",
    "from src.agents.crewai_teams.document_analysis_crew import run_document_deep_dive_crew\n",
    "\n",
    "# Configurer le logging pour le notebook\n",
    "LOG_LEVEL_NOTEBOOK = \"INFO\" # Mettre √† DEBUG pour voir les logs d√©taill√©s de CrewAI\n",
    "setup_logging(level=LOG_LEVEL_NOTEBOOK) \n",
    "logger = logging.getLogger(\"nb_05_crewai_integration\")\n",
    "\n",
    "# --- MODIFI√â : V√©rification des pr√©requis pour le LLM utilis√© par CrewAI (via get_llm) ---\n",
    "active_llm_provider_for_crew = settings.DEFAULT_LLM_MODEL_PROVIDER.lower()\n",
    "logger.info(f\"L'√©quipe CrewAI utilisera le fournisseur LLM configur√© par d√©faut : '{active_llm_provider_for_crew}' (via get_llm).\")\n",
    "\n",
    "if active_llm_provider_for_crew == \"openai\":\n",
    "    if not settings.OPENAI_API_KEY:\n",
    "        logger.error(\"ERREUR : Le fournisseur LLM pour CrewAI est 'openai', mais OPENAI_API_KEY n'est pas configur√©e. L'ex√©cution de l'√©quipe CrewAI √©chouera probablement.\")\n",
    "        print(\"ERREUR: Cl√© API OpenAI manquante. Veuillez la configurer dans votre fichier .env.\")\n",
    "elif active_llm_provider_for_crew == \"huggingface_api\":\n",
    "    if not settings.HUGGINGFACE_API_KEY:\n",
    "        logger.error(\"ERREUR : Le fournisseur LLM pour CrewAI est 'huggingface_api', mais HUGGINGFACE_API_KEY n'est pas configur√©e.\")\n",
    "        print(\"ERREUR: Cl√© API HuggingFace manquante. Veuillez la configurer dans votre fichier .env.\")\n",
    "elif active_llm_provider_for_crew == \"ollama\":\n",
    "    if not settings.OLLAMA_BASE_URL:\n",
    "        logger.error(\"ERREUR : Le fournisseur LLM pour CrewAI est 'ollama', mais OLLAMA_BASE_URL n'est pas configur√©e.\")\n",
    "        print(\"ERREUR: URL de base Ollama manquante. Veuillez la configurer dans votre fichier .env.\")\n",
    "    if not settings.OLLAMA_GENERATIVE_MODEL_NAME: # V√©rifier aussi le nom du mod√®le pour Ollama\n",
    "        logger.error(\"ERREUR : Le fournisseur LLM pour CrewAI est 'ollama', mais OLLAMA_GENERATIVE_MODEL_NAME n'est pas configur√©.\")\n",
    "        print(\"ERREUR: Nom du mod√®le g√©n√©ratif Ollama manquant. Veuillez le configurer dans votre fichier .env ou settings.py.\")\n",
    "# --- FIN MODIFI√â ---\n",
    "\n",
    "# V√©rifier si crewai est install√©\n",
    "try:\n",
    "    import crewai\n",
    "    logger.info(f\"Biblioth√®que CrewAI version {crewai.__version__} import√©e.\")\n",
    "except ImportError:\n",
    "    logger.error(\"La biblioth√®que 'crewai' n'est PAS install√©e. Veuillez l'installer (pip install crewai) et relancer.\")\n",
    "    crewai = None # Pour que les cellules suivantes ne plantent pas si import √©choue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82128400",
   "metadata": {},
   "source": [
    "### 1. Pr√©paration des Donn√©es d'Exemple pour l'Analyse\n",
    "\n",
    "Nous allons d√©finir un exemple de contenu de document, son ID, et un focus de recherche sp√©cifique pour tester notre `DocumentAnalysisCrew`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed249b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_doc_id = \"arxiv_sample_2401.001\"\n",
    "sample_research_focus = \"Identify the core methodology, key results, and explicitly stated limitations regarding sim-to-real transfer techniques.\"\n",
    "\n",
    "sample_doc_content = \"\"\"\n",
    "Abstract: This research presents \"TransferRL\", a novel framework for enhancing sim-to-real transfer in robotic manipulation tasks. \n",
    "By employing adaptive instance normalization in the feature space of a vision-based policy and a curriculum of progressively complex simulated environments, \n",
    "TransferRL significantly reduces the reality gap. We demonstrate its efficacy on a pick-and-place task, achieving an 82% success rate on a physical KUKA LBR iiwa robot after training purely in simulation.\n",
    "\n",
    "Introduction: Sim-to-real transfer is a pivotal challenge in applying deep reinforcement learning (RL) to real-world robotics. \n",
    "While training RL agents in simulation is often faster, safer, and more scalable than on physical systems, policies learned in simulation frequently\n",
    "fail to generalize to the real world due to discrepancies in dynamics, visual appearance, and sensor noise. \n",
    "This paper addresses these challenges with a focus on visual domain adaptation.\n",
    "\n",
    "Methodology: TransferRL consists of two main components. First, an image-to-image translation network based on CycleGAN is used to translate\n",
    "simulated images to a more realistic style, though this is only used for initial policy pre-training. The core of TransferRL is an\n",
    "encoder-decoder policy architecture where the encoder features are modulated by adaptive instance normalization (AdaIN) layers. \n",
    "These AdaIN layers are conditioned on a learned domain embedding, allowing the policy to adapt its visual processing dynamically.\n",
    "The agent is trained using Soft Actor-Critic (SAC) on a curriculum of tasks in a custom OpenAI Gym environment built with PyBullet. \n",
    "The curriculum gradually increases object diversity and complexity of grasp poses. Domain randomization is applied to lighting, textures, and camera positions.\n",
    "\n",
    "Results: On the primary pick-and-place task, TransferRL (82% success on physical robot) outperformed: \n",
    "(a) direct transfer without AdaIN or curriculum (35%), \n",
    "(b) AdaIN without curriculum (65%), and \n",
    "(c) curriculum without AdaIN (58%). \n",
    "The domain embedding was observed to cluster according to different simulation variations, suggesting successful domain identification. \n",
    "Qualitative analysis showed improved handling of novel object textures and lighting in the real world.\n",
    "\n",
    "Limitations: The current implementation of TransferRL requires a small set of real-world images to learn the target domain embedding for AdaIN, making it not entirely \"zero-shot\" sim-to-real. \n",
    "The computational overhead of the AdaIN layers adds a minor latency to the policy execution. \n",
    "The system has only been tested on quasi-static pick-and-place tasks.\n",
    "\n",
    "Conclusion: TransferRL offers an effective method for robust sim-to-real transfer in vision-based robotic manipulation by combining adaptive normalization with a structured training curriculum. Future work will explore fully zero-shot adaptation and application to dynamic tasks.\n",
    "\"\"\"\n",
    "\n",
    "logger.info(f\"Pr√™t √† analyser le document ID: {sample_doc_id}\")\n",
    "logger.info(f\"Focus de la recherche: {sample_research_focus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f211f",
   "metadata": {},
   "source": [
    "### 2. Ex√©cution de l'√âquipe CrewAI `DocumentAnalysisCrew`\n",
    "\n",
    "Nous appelons la fonction `run_document_deep_dive_crew` (d√©finie dans `src/agents/crewai_teams/document_analysis_crew.py`) avec nos donn√©es d'exemple. Cette fonction orchestre l'√©quipe CrewAI pour produire un rapport d'analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report_from_crew = None\n",
    "\n",
    "if crewai and settings.OPENAI_API_KEY:\n",
    "    logger.info(\"Lancement de DocumentAnalysisCrew...\")\n",
    "    print(\"\\nüîÑ Lancement de l'√©quipe CrewAI pour l'analyse du document... Cela peut prendre quelques minutes, surtout avec verbose=2.\\n\")\n",
    "    \n",
    "    try:\n",
    "        final_report_from_crew = run_document_deep_dive_crew(\n",
    "            document_id=sample_doc_id,\n",
    "            document_content=sample_doc_content,\n",
    "            research_focus=sample_research_focus\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\\n--- üìù Rapport d'Analyse Final Compil√© par l'√âquipe CrewAI ---\")\n",
    "        if final_report_from_crew:\n",
    "            try:\n",
    "                from IPython.display import display, Markdown\n",
    "                display(Markdown(final_report_from_crew))\n",
    "            except ImportError:\n",
    "                print(final_report_from_crew)\n",
    "        else:\n",
    "            print(\"L'√©quipe CrewAI n'a pas retourn√© de rapport (v√©rifiez les logs).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'ex√©cution de DocumentAnalysisCrew: {e}\", exc_info=True)\n",
    "        print(f\"ERREUR lors de l'ex√©cution de l'√©quipe CrewAI : {e}\")\n",
    "        final_report_from_crew = f\"Erreur d'ex√©cution : {e}\"\n",
    "else:\n",
    "    if not crewai:\n",
    "        print(\"Biblioth√®que CrewAI non install√©e. Test saut√©.\")\n",
    "    elif not settings.OPENAI_API_KEY: # V√©rification redondante mais bonne pour la clart√© ici\n",
    "        print(\"Cl√© API OpenAI manquante. Test de l'√©quipe CrewAI saut√©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68121d3",
   "metadata": {},
   "source": [
    "### 3. Analyse du Rapport et Discussion\n",
    "\n",
    "* Examinez attentivement le rapport g√©n√©r√© par l'√©quipe CrewAI.\n",
    "* **Structure :** Le `ReportCompilerAgent` a-t-il bien structur√© le rapport en fonction des contributions des autres agents (Extracteur, R√©sumeur, Analyste Critique) ?\n",
    "* **Contenu :**\n",
    "    * Les informations cl√©s extraites par l'`InfoExtractorAgent` (m√©thodologie, r√©sultats, limitations) sont-elles pr√©cises et pertinentes par rapport au `research_focus` ?\n",
    "    * Les r√©sum√©s de sections (si l'`SectionSummarizerAgent` a pu les produire) sont-ils concis et informatifs ?\n",
    "    * L'analyse critique du `CriticalAnalystAgent` (forces, faiblesses, contributions) est-elle judicieuse ?\n",
    "* **Focus de Recherche :** Le rapport final est-il bien ax√© sur le `research_focus` que nous avons sp√©cifi√© ?\n",
    "* **Verbosit√© de CrewAI :** Si vous avez r√©gl√© `verbose=2` dans la d√©finition de la `Crew` dans `document_analysis_crew.py`, vous avez d√ª voir le d√©tail des pens√©es et actions de chaque agent. Cela permet de comprendre leur processus de \"r√©flexion\" et de collaboration.\n",
    "\n",
    "Cette ex√©cution isol√©e nous donne une id√©e de la capacit√© de l'√©quipe CrewAI √† traiter une t√¢che d'analyse de document complexe et sp√©cialis√©e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104bb9de",
   "metadata": {},
   "source": [
    "### 4. Int√©gration Potentielle dans le Workflow LangGraph\n",
    "\n",
    "Rappelons comment cette √©quipe CrewAI pourrait s'int√©grer √† notre syst√®me LangGraph principal :\n",
    "\n",
    "1.  **Wrapper la CrewAI comme un Outil LangChain :**\n",
    "    La fonction `run_document_deep_dive_crew` peut √™tre transform√©e en un outil LangChain personnalis√© √† l'aide du d√©corateur `@tool`.\n",
    "    ```python\n",
    "    # Exemple conceptuel (√† mettre dans tool_definitions.py si on l'int√®gre)\n",
    "    # from langchain_core.tools import tool\n",
    "    # from src.agents.crewai_teams.document_analysis_crew import run_document_deep_dive_crew\n",
    "\n",
    "    # @tool\n",
    "    # def deep_document_analysis_tool(document_id: str, document_content: str, research_focus: str) -> str:\n",
    "    #     \"\"\"\n",
    "    #     Performs an in-depth analysis of a specific document using a specialized team of AI agents (CrewAI).\n",
    "    #     Use this when a detailed, structured report on a single document is needed, focusing on specific aspects.\n",
    "    #     Args:\n",
    "    #         document_id (str): The unique identifier of the document.\n",
    "    #         document_content (str): The full text content of the document to be analyzed.\n",
    "    #         research_focus (str): Specific questions or areas the detailed analysis should concentrate on.\n",
    "    #     Returns:\n",
    "    #         str: A structured analytical report about the document.\n",
    "    #     \"\"\"\n",
    "    #     return run_document_deep_dive_crew(document_id, document_content, research_focus)\n",
    "    ```\n",
    "\n",
    "2.  **Utilisation par un Agent LangGraph :**\n",
    "    L'agent `DocumentAnalysisAgent` (d√©fini dans `agent_architectures.py` pour LangGraph) pourrait se voir attribuer ce nouvel outil.\n",
    "    Son prompt syst√®me serait mis √† jour pour lui indiquer quand il est appropri√© de d√©l√©guer une analyse approfondie √† cet outil plut√¥t que de simplement utiliser le `knowledge_base_retrieval_tool` pour des extraits.\n",
    "\n",
    "3.  **Flux dans LangGraph :**\n",
    "    * Le `ResearchPlannerAgent` identifie un document cl√© et un focus d'analyse.\n",
    "    * Le routeur dirige vers le `DocumentAnalysisAgent` (LangGraph).\n",
    "    * Cet agent, voyant la n√©cessit√© d'une analyse profonde, appelle le `deep_document_analysis_tool`.\n",
    "    * Le `ToolNode` de LangGraph ex√©cute cet outil (qui lance la CrewAI).\n",
    "    * Le rapport de la CrewAI revient comme un `ToolMessage` dans l'√©tat LangGraph.\n",
    "    * L'`DocumentAnalysisAgent` (LangGraph) re√ßoit ce rapport et l'int√®gre potentiellement √† d'autres analyses avant de passer la main au `SynthesisAgent`.\n",
    "\n",
    "Cette approche hybride permet de combiner la flexibilit√© et la gestion d'√©tat de LangGraph pour l'orchestration globale avec la collaboration structur√©e et orient√©e r√¥les de CrewAI pour des t√¢ches sp√©cifiques tr√®s d√©limit√©es."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d1a26",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook a d√©montr√© comment instancier et ex√©cuter notre `DocumentAnalysisCrew` pour effectuer une analyse approfondie d'un document. Nous avons √©galement discut√© des pistes pour int√©grer cette √©quipe CrewAI comme un composant sp√©cialis√© au sein de notre architecture LangGraph principale.\n",
    "\n",
    "L'utilisation de CrewAI pour des sous-t√¢ches complexes peut enrichir les capacit√©s de notre \"Cognitive Swarm\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitive-swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
