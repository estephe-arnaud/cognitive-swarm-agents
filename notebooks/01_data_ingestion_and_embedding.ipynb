{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79506aac",
   "metadata": {},
   "source": [
    "# Notebook 01: Pipeline d'Ingestion et d'Embedding des Données ArXiv\n",
    "\n",
    "Ce notebook démontre le processus complet d'acquisition, de traitement, d'embedding et de stockage des articles scientifiques d'ArXiv dans notre base de données MongoDB.\n",
    "\n",
    "**Prérequis :**\n",
    "* Assurez-vous d'avoir exécuté le notebook `00_setup_environment.ipynb` et que votre environnement est correctement configuré (variables d'environnement chargées, clés API valides, MongoDB accessible).\n",
    "* Les bibliothèques nécessaires doivent être installées via `environment.yml`.\n",
    "\n",
    "**Étapes de ce Notebook :**\n",
    "1.  Configuration initiale (imports, logging, connexion MongoDB).\n",
    "2.  Téléchargement d'articles depuis ArXiv.\n",
    "3.  Parsing des documents PDF et de leurs métadonnées.\n",
    "4.  Prétraitement du texte (nettoyage et chunking).\n",
    "5.  Génération des embeddings pour les chunks.\n",
    "6.  Stockage des chunks et de leurs embeddings dans MongoDB et création des index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65b0c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-02 22:48:12 - nb_01_ingestion_embedding - INFO - Configuration initiale du notebook terminée.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:48:12 - nb_01_ingestion_embedding - INFO - Utilisation de DATA_DIR: /home/facetoface/cognitive-swarm-agents/data\u001b[0m\n",
      "\u001b[34m2025-06-02 22:48:12 - nb_01_ingestion_embedding - INFO - Pour ce notebook, les PDFs ArXiv seront gérés dans : /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/pdfs\u001b[0m\n",
      "\u001b[34m2025-06-02 22:48:12 - nb_01_ingestion_embedding - INFO - Pour ce notebook, les métadonnées ArXiv seront gérées dans : /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/metadata\u001b[0m\n",
      "\u001b[34m2025-06-02 22:48:12 - nb_01_ingestion_embedding - INFO - --- Configuration d'Embedding Active (depuis settings.py et .env) ---\u001b[0m\n",
      "\u001b[34m2025-06-02 22:48:12 - nb_01_ingestion_embedding - INFO - Fournisseur d'embedding par défaut configuré : ollama\u001b[0m\n",
      "\u001b[34m2025-06-02 22:48:12 - nb_01_ingestion_embedding - INFO -   Modèle Ollama Embedding à utiliser : nomic-embed-text\u001b[0m\n",
      "\u001b[34m2025-06-02 22:48:12 - nb_01_ingestion_embedding - INFO -   Dimension Ollama Embedding (configurée) : 768\u001b[0m\n",
      "\u001b[34m2025-06-02 22:48:12 - nb_01_ingestion_embedding - INFO -   URL de base Ollama : http://localhost:11434\u001b[0m\n",
      "\u001b[34m2025-06-02 22:48:12 - nb_01_ingestion_embedding - INFO -   ASSUREZ-VOUS que le modèle 'nomic-embed-text' est disponible sur votre serveur Ollama (ex: via 'ollama pull nomic-embed-text').\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Importer nos modules\n",
    "import logging\n",
    "from typing import List, Optional, Dict, Any\n",
    "from pathlib import Path # Assurez-vous que Path est importé\n",
    "import re # Pour nettoyer le nom du répertoire du corpus\n",
    "\n",
    "from pymongo.errors import ConnectionFailure \n",
    "from config.settings import settings\n",
    "from config.logging_config import setup_logging\n",
    "# Les fonctions attendent maintenant les chemins complets en argument\n",
    "from src.data_processing.arxiv_downloader import download_pipeline as download_arxiv_papers\n",
    "from src.data_processing.document_parser import parse_document_collection \n",
    "# PDF_INPUT_DIR et METADATA_INPUT_DIR ont été supprimés de document_parser.py\n",
    "\n",
    "from src.data_processing.preprocessor import preprocess_parsed_documents, ParsedDocument \n",
    "from src.data_processing.embedder import generate_embeddings_for_chunks \n",
    "from src.vector_store.mongodb_manager import MongoDBManager\n",
    "\n",
    "# Configurer le logging pour le notebook\n",
    "setup_logging(level=\"INFO\") # Mettre à DEBUG pour plus de détails\n",
    "logger = logging.getLogger(\"nb_01_ingestion_embedding\")\n",
    "\n",
    "logger.info(\"Configuration initiale du notebook terminée.\")\n",
    "\n",
    "# --- Définition dynamique des chemins pour ce notebook ---\n",
    "# Utiliser la requête du notebook pour créer un nom de répertoire de corpus unique\n",
    "ARXIV_QUERY_NOTEBOOK = \"explainable artificial intelligence for robotics\" # Gardé pour la requête ArXiv\n",
    "# Fonction simple pour nettoyer la chaîne de requête pour un nom de répertoire\n",
    "def sanitize_for_dir_name(query: str) -> str:\n",
    "    s = query.lower()\n",
    "    s = re.sub(r'[\\s\\W-]+', '_', s)\n",
    "    s = s.strip('_')\n",
    "    return s[:50]\n",
    "\n",
    "# Nom du sous-répertoire de corpus basé sur la requête spécifique à ce notebook\n",
    "corpus_sub_dir_name_nb = sanitize_for_dir_name(ARXIV_QUERY_NOTEBOOK) \n",
    "# Ou utilisez un nom fixe si vous préférez pour les tests du notebook, par ex :\n",
    "# corpus_sub_dir_name_nb = \"notebook_ingestion_test_corpus\"\n",
    "\n",
    "notebook_corpus_base_path = Path(settings.DATA_DIR) / \"corpus\" / corpus_sub_dir_name_nb\n",
    "# Définir les chemins spécifiques pour les PDFs et métadonnées de ce notebook\n",
    "# Ces variables remplaceront les anciennes PDF_INPUT_DIR et METADATA_INPUT_DIR dans ce notebook\n",
    "NB_PDF_OUTPUT_DIR = notebook_corpus_base_path / \"pdfs\"\n",
    "NB_METADATA_OUTPUT_DIR = notebook_corpus_base_path / \"metadata\"\n",
    "\n",
    "# S'assurer que ces répertoires existent pour le notebook\n",
    "NB_PDF_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NB_METADATA_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(f\"Utilisation de DATA_DIR: {settings.DATA_DIR}\")\n",
    "logger.info(f\"Pour ce notebook, les PDFs ArXiv seront gérés dans : {NB_PDF_OUTPUT_DIR}\")\n",
    "logger.info(f\"Pour ce notebook, les métadonnées ArXiv seront gérées dans : {NB_METADATA_OUTPUT_DIR}\")\n",
    "\n",
    "# --- Affichage de la configuration d'embedding active et vérification des prérequis (inchangé) ---\n",
    "logger.info(f\"--- Configuration d'Embedding Active (depuis settings.py et .env) ---\")\n",
    "active_embedding_provider = settings.DEFAULT_EMBEDDING_PROVIDER.lower()\n",
    "logger.info(f\"Fournisseur d'embedding par défaut configuré : {active_embedding_provider}\")\n",
    "\n",
    "if active_embedding_provider == \"openai\":\n",
    "    logger.info(f\"  Modèle OpenAI Embedding à utiliser : {settings.OPENAI_EMBEDDING_MODEL_NAME}\")\n",
    "    logger.info(f\"  Dimension OpenAI Embedding (configurée) : {settings.OPENAI_EMBEDDING_DIMENSION}\")\n",
    "    if not settings.OPENAI_API_KEY:\n",
    "        logger.error(\"ERREUR : Le fournisseur d'embedding est 'openai', mais OPENAI_API_KEY n'est pas configurée dans .env. La génération d'embeddings échouera.\")\n",
    "elif active_embedding_provider == \"huggingface\":\n",
    "    logger.info(f\"  Modèle HuggingFace Embedding à utiliser : {settings.HUGGINGFACE_EMBEDDING_MODEL_NAME}\")\n",
    "    logger.info(f\"  Dimension HuggingFace Embedding (configurée) : {settings.HUGGINGFACE_EMBEDDING_MODEL_DIMENSION}\")\n",
    "elif active_embedding_provider == \"ollama\":\n",
    "    logger.info(f\"  Modèle Ollama Embedding à utiliser : {settings.OLLAMA_EMBEDDING_MODEL_NAME}\")\n",
    "    logger.info(f\"  Dimension Ollama Embedding (configurée) : {settings.OLLAMA_EMBEDDING_MODEL_DIMENSION}\")\n",
    "    logger.info(f\"  URL de base Ollama : {settings.OLLAMA_BASE_URL}\")\n",
    "    if not settings.OLLAMA_BASE_URL:\n",
    "        logger.error(\"ERREUR : Le fournisseur d'embedding est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée. La génération d'embeddings échouera.\")\n",
    "    logger.info(f\"  ASSUREZ-VOUS que le modèle '{settings.OLLAMA_EMBEDDING_MODEL_NAME}' est disponible sur votre serveur Ollama (ex: via 'ollama pull {settings.OLLAMA_EMBEDDING_MODEL_NAME}').\")\n",
    "else:\n",
    "    logger.error(f\"ERREUR : Fournisseur d'embedding inconnu configuré dans settings.py : '{active_embedding_provider}'. La génération d'embeddings échouera.\")\n",
    "# --- Fin de la section sur la configuration d'embedding ---\n",
    "\n",
    "# Paramètres pour cette exécution de notebook (inchangés, mais les chemins de sortie seront NB_PDF_OUTPUT_DIR etc.)\n",
    "# ARXIV_QUERY_NOTEBOOK est défini plus haut\n",
    "MAX_RESULTS_NOTEBOOK = 2 \n",
    "COLLECTION_NAME_NOTEBOOK = \"arxiv_chunks_notebook_test\" \n",
    "VECTOR_INDEX_NAME_NOTEBOOK = \"vector_index_notebook_test\"\n",
    "TEXT_INDEX_NAME_NOTEBOOK = \"text_index_notebook_test\"\n",
    "\n",
    "# La section de nettoyage des répertoires (si décommentée) devra aussi utiliser NB_PDF_OUTPUT_DIR et NB_METADATA_OUTPUT_DIR\n",
    "# import shutil\n",
    "# if NB_PDF_OUTPUT_DIR.exists():\n",
    "#     logger.info(f\"Nettoyage du répertoire PDF: {NB_PDF_OUTPUT_DIR}\")\n",
    "#     shutil.rmtree(NB_PDF_OUTPUT_DIR)\n",
    "# NB_PDF_OUTPUT_DIR.mkdir(parents=True, exist_ok=True) # Recréer après suppression\n",
    "# if NB_METADATA_OUTPUT_DIR.exists():\n",
    "#     logger.info(f\"Nettoyage du répertoire Metadata: {NB_METADATA_OUTPUT_DIR}\")\n",
    "#     shutil.rmtree(NB_METADATA_OUTPUT_DIR)\n",
    "# NB_METADATA_OUTPUT_DIR.mkdir(parents=True, exist_ok=True) # Recréer après suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a39ee30",
   "metadata": {},
   "source": [
    "### Étape 1: Téléchargement d'Articles depuis ArXiv\n",
    "\n",
    "Nous utilisons `arxiv_downloader.download_pipeline` pour rechercher et télécharger quelques articles.\n",
    "Pour ce notebook, nous limitons la recherche à `MAX_RESULTS_NOTEBOOK` articles pour que l'exécution soit rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6b941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-02 22:49:21 - nb_01_ingestion_embedding - INFO - --- Étape 1: Téléchargement d'Articles ArXiv (max: 2) ---\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:21 - src.data_processing.arxiv_downloader - INFO - Searching ArXiv with query='explainable artificial intelligence for robotics', max_results=2, sort_by='submittedDate', sort_order='descending'\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:21 - arxiv - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=explainable+artificial+intelligence+for+robotics&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:24 - arxiv - INFO - Got first page: 100 of 2237800 total results\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:24 - src.data_processing.arxiv_downloader - INFO - Found 2 papers on ArXiv.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:24 - src.data_processing.arxiv_downloader - INFO - Starting download and metadata saving for 2 papers.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:24 - src.data_processing.arxiv_downloader - INFO - Processing paper 1/2: http://arxiv.org/abs/2505.24878v1\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:24 - src.data_processing.arxiv_downloader - INFO - Downloading PDF for paper 2505.24878 ('Open CaptchaWorld: A Comprehensive Web-based Platf...') to /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/pdfs/2505.24878.pdf\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:37 - src.data_processing.arxiv_downloader - INFO - Successfully downloaded /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/pdfs/2505.24878.pdf\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:40 - src.data_processing.arxiv_downloader - INFO - Saving metadata for paper 2505.24878 ('Open CaptchaWorld: A Comprehensive Web-based Platf...') to /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/metadata/2505.24878_metadata.json\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:40 - src.data_processing.arxiv_downloader - INFO - Successfully saved metadata /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/metadata/2505.24878_metadata.json\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:40 - src.data_processing.arxiv_downloader - INFO - Processing paper 2/2: http://arxiv.org/abs/2505.24877v1\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:40 - src.data_processing.arxiv_downloader - INFO - Downloading PDF for paper 2505.24877 ('AdaHuman: Animatable Detailed 3D Human Generation ...') to /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/pdfs/2505.24877.pdf\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:49 - src.data_processing.arxiv_downloader - INFO - Successfully downloaded /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/pdfs/2505.24877.pdf\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:52 - src.data_processing.arxiv_downloader - INFO - Saving metadata for paper 2505.24877 ('AdaHuman: Animatable Detailed 3D Human Generation ...') to /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/metadata/2505.24877_metadata.json\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:52 - src.data_processing.arxiv_downloader - INFO - Successfully saved metadata /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/metadata/2505.24877_metadata.json\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:52 - src.data_processing.arxiv_downloader - INFO - Finished ArXiv download pipeline. Downloaded 2 PDFs and saved 2 metadata files.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:52 - nb_01_ingestion_embedding - INFO - Téléchargement terminé. 2 PDFs et 2 fichiers de métadonnées.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:52 - nb_01_ingestion_embedding - INFO -   PDF téléchargé : /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/pdfs/2505.24878.pdf\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:52 - nb_01_ingestion_embedding - INFO -   PDF téléchargé : /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/pdfs/2505.24877.pdf\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:52 - nb_01_ingestion_embedding - INFO -   Métadonnées sauvegardées : /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/metadata/2505.24878_metadata.json\u001b[0m\n",
      "\u001b[34m2025-06-02 22:49:52 - nb_01_ingestion_embedding - INFO -   Métadonnées sauvegardées : /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/metadata/2505.24877_metadata.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"--- Étape 1: Téléchargement d'Articles ArXiv (max: {MAX_RESULTS_NOTEBOOK}) ---\")\n",
    "\n",
    "# S'assurer que NB_PDF_OUTPUT_DIR et NB_METADATA_OUTPUT_DIR sont bien définis\n",
    "# depuis la première cellule de code de ce notebook.\n",
    "# Si ce n'est pas le cas, vous pouvez les redéfinir ici ou vous assurer que la première cellule a été exécutée.\n",
    "# Exemple (au cas où, à adapter si vous avez utilisé un autre nom pour le corpus du notebook) :\n",
    "# from pathlib import Path\n",
    "# from config.settings import settings\n",
    "# import re\n",
    "# def sanitize_for_dir_name(query: str) -> str:\n",
    "#     s = query.lower()\n",
    "#     s = re.sub(r'[\\s\\W-]+', '_', s)\n",
    "#     s = s.strip('_')\n",
    "#     return s[:50]\n",
    "# corpus_sub_dir_name_nb = sanitize_for_dir_name(ARXIV_QUERY_NOTEBOOK) \n",
    "# notebook_corpus_base_path = Path(settings.DATA_DIR) / \"corpus\" / corpus_sub_dir_name_nb\n",
    "# NB_PDF_OUTPUT_DIR = notebook_corpus_base_path / \"pdfs\"\n",
    "# NB_METADATA_OUTPUT_DIR = notebook_corpus_base_path / \"metadata\"\n",
    "# NB_PDF_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# NB_METADATA_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "downloaded_files_info = download_arxiv_papers(\n",
    "    query=ARXIV_QUERY_NOTEBOOK,\n",
    "    max_results=MAX_RESULTS_NOTEBOOK,\n",
    "    # MODIFICATION : Ajout des arguments requis pour les chemins de sortie\n",
    "    pdf_output_dir=NB_PDF_OUTPUT_DIR,\n",
    "    metadata_output_dir=NB_METADATA_OUTPUT_DIR\n",
    "    # Les arguments sort_by et sort_order utiliseront leurs valeurs par défaut\n",
    "    # définies dans la fonction download_pipeline si non spécifiés ici.\n",
    ")\n",
    "\n",
    "if downloaded_files_info and downloaded_files_info.get('pdfs'):\n",
    "    logger.info(f\"Téléchargement terminé. {len(downloaded_files_info['pdfs'])} PDFs et {len(downloaded_files_info['metadata'])} fichiers de métadonnées.\")\n",
    "    for pdf_path in downloaded_files_info['pdfs'][:2]: # Afficher les 2 premiers\n",
    "        logger.info(f\"  PDF téléchargé : {pdf_path}\")\n",
    "    for meta_path in downloaded_files_info['metadata'][:2]:\n",
    "        logger.info(f\"  Métadonnées sauvegardées : {meta_path}\")\n",
    "else:\n",
    "    logger.warning(\"Aucun fichier PDF n'a été téléchargé. Vérifiez la requête ArXiv ou la connexion.\")\n",
    "    # On pourrait arrêter ici si aucun fichier n'est téléchargé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e64f8",
   "metadata": {},
   "source": [
    "### Étape 2: Parsing des Documents\n",
    "\n",
    "Maintenant, nous utilisons `document_parser.parse_document_collection` pour lire les PDFs téléchargés et leurs fichiers de métadonnées JSON associés. Cela extraira le texte brut et structurera les métadonnées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b6537dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-02 22:50:55 - nb_01_ingestion_embedding - INFO - \n",
      "--- Étape 2: Parsing des Documents ---\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:55 - src.data_processing.document_parser - INFO - Found 2 PDF files in /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/pdfs to parse.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:55 - src.data_processing.document_parser - INFO - Parsing PDF: 2505.24878.pdf\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:55 - src.data_processing.document_parser - INFO - Successfully processed and added document: 2505.24878\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:55 - src.data_processing.document_parser - INFO - Parsing PDF: 2505.24877.pdf\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:56 - src.data_processing.document_parser - INFO - Successfully processed and added document: 2505.24877\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:56 - src.data_processing.document_parser - INFO - Finished parsing collection. Successfully processed 2 documents.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:56 - nb_01_ingestion_embedding - INFO - 2 documents ont été parsés avec succès.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:56 - nb_01_ingestion_embedding - INFO - Exemple de document parsé (ID ArXiv: 2505.24878):\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:56 - nb_01_ingestion_embedding - INFO -   Titre (depuis métadonnées): Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:56 - nb_01_ingestion_embedding - INFO -   Extrait du texte: 'Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents Yaxin Luo∗, Zhaoyi Li∗, Jiacheng Liu, Jiacheng Cui, Xiaohan Zhao, Zhiqiang Shen† 1VILA Lab, MBZ...'\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:56 - nb_01_ingestion_embedding - INFO -   Chemin PDF: /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/pdfs/2505.24878.pdf\u001b[0m\n",
      "\u001b[34m2025-06-02 22:50:56 - nb_01_ingestion_embedding - INFO -   Chemin Métadonnées: /home/facetoface/cognitive-swarm-agents/data/corpus/explainable_artificial_intelligence_for_robotics/metadata/2505.24878_metadata.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"\\n--- Étape 2: Parsing des Documents ---\")\n",
    "\n",
    "# S'assurer que NB_PDF_OUTPUT_DIR et NB_METADATA_OUTPUT_DIR sont bien définis\n",
    "# depuis la première cellule de code de ce notebook.\n",
    "# Ces variables pointent vers les répertoires où download_arxiv_papers\n",
    "# a (ou aurait dû) sauvegarder les fichiers à l'étape précédente.\n",
    "\n",
    "# MODIFICATION : Passer les chemins corrects à parse_document_collection\n",
    "parsed_documents: List[ParsedDocument] = parse_document_collection(\n",
    "    pdf_dir=NB_PDF_OUTPUT_DIR,\n",
    "    metadata_dir=NB_METADATA_OUTPUT_DIR\n",
    ")\n",
    "\n",
    "if parsed_documents:\n",
    "    logger.info(f\"{len(parsed_documents)} documents ont été parsés avec succès.\")\n",
    "    # Afficher un extrait du premier document parsé\n",
    "    if len(parsed_documents) > 0:\n",
    "        doc_example = parsed_documents[0]\n",
    "        logger.info(f\"Exemple de document parsé (ID ArXiv: {doc_example['arxiv_id']}):\")\n",
    "        logger.info(f\"  Titre (depuis métadonnées): {doc_example['metadata'].get('title', 'N/A')}\")\n",
    "        logger.info(f\"  Extrait du texte: '{doc_example['text_content'][:200].replace(chr(10), ' ')}...'\")\n",
    "        logger.info(f\"  Chemin PDF: {doc_example['pdf_path']}\")\n",
    "        logger.info(f\"  Chemin Métadonnées: {doc_example['metadata_path']}\")\n",
    "else:\n",
    "    logger.warning(\"Aucun document n'a été parsé. Vérifiez si des PDFs existent dans le répertoire attendu et si l'étape précédente de téléchargement a réussi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f71ac7d",
   "metadata": {},
   "source": [
    "### Étape 3: Prétraitement du Texte (Nettoyage et Chunking)\n",
    "\n",
    "Les documents parsés sont maintenant nettoyés et découpés en chunks plus petits et gérables en utilisant `preprocessor.preprocess_parsed_documents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0550720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-02 22:51:04 - nb_01_ingestion_embedding - INFO - \n",
      "--- Étape 3: Prétraitement du Texte ---\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:04 - src.data_processing.preprocessor - INFO - Starting preprocessing for 2 parsed documents.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:04 - src.data_processing.preprocessor - INFO - Preprocessing document 1/2: 2505.24878\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:04 - src.data_processing.preprocessor - INFO - Preprocessing document 2/2: 2505.24877\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:04 - src.data_processing.preprocessor - INFO - Finished preprocessing. Generated 43 chunks in total.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:04 - nb_01_ingestion_embedding - INFO - 43 chunks ont été générés après prétraitement.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:04 - nb_01_ingestion_embedding - INFO - Exemple de chunk traité (ID: 2505.24878_chunk_001):\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:04 - nb_01_ingestion_embedding - INFO -   ID ArXiv d'origine: 2505.24878\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:04 - nb_01_ingestion_embedding - INFO -   Titre d'origine: Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:04 - nb_01_ingestion_embedding - INFO -   Extrait du chunk: 'Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents Yaxin Luo∗, Zhaoyi Li∗, Jiacheng Liu, Jiacheng Cui, Xiaohan Zhao, Zhiqiang Shen† 1VILA Lab, MBZ...'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"\\n--- Étape 3: Prétraitement du Texte ---\")\n",
    "\n",
    "if parsed_documents:\n",
    "    processed_chunks = preprocess_parsed_documents(parsed_documents)\n",
    "    if processed_chunks:\n",
    "        logger.info(f\"{len(processed_chunks)} chunks ont été générés après prétraitement.\")\n",
    "        # Afficher un extrait du premier chunk\n",
    "        if len(processed_chunks) > 0:\n",
    "            chunk_example = processed_chunks[0]\n",
    "            logger.info(f\"Exemple de chunk traité (ID: {chunk_example['chunk_id']}):\")\n",
    "            logger.info(f\"  ID ArXiv d'origine: {chunk_example['arxiv_id']}\")\n",
    "            logger.info(f\"  Titre d'origine: {chunk_example['original_document_title']}\")\n",
    "            logger.info(f\"  Extrait du chunk: '{chunk_example['text_chunk'][:200].replace(chr(10), ' ')}...'\")\n",
    "    else:\n",
    "        logger.warning(\"Aucun chunk n'a été généré lors du prétraitement.\")\n",
    "else:\n",
    "    logger.warning(\"Aucun document parsé à prétraiter. Étape de prétraitement sautée.\")\n",
    "    processed_chunks = [] # S'assurer que la variable existe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b24a9",
   "metadata": {},
   "source": [
    "### Étape 4: Génération des Embeddings\n",
    "\n",
    "Chaque chunk de texte est maintenant converti en une représentation vectorielle (embedding) en utilisant `embedder.generate_embeddings_for_chunks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "817ea79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-02 22:51:08 - nb_01_ingestion_embedding - INFO - \n",
      "--- Étape 4: Génération des Embeddings ---\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:08 - nb_01_ingestion_embedding - INFO - Appel de generate_embeddings_for_chunks avec le provider: ollama\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:08 - src.data_processing.embedder - INFO - Starting embedding generation for 43 chunks.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:08 - src.data_processing.embedder - INFO - Initializing embedding client for provider: ollama\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:08 - src.data_processing.embedder - INFO - Using OllamaEmbeddings with model: nomic-embed-text via http://localhost:11434\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:08 - src.data_processing.embedder - INFO - Embedding batch 1/2 (size: 32) using ollama provider.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/facetoface/cognitive-swarm-agents/src/data_processing/embedder.py:51: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  return OllamaEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-02 22:51:09 - src.data_processing.embedder - INFO - Embedding batch 2/2 (size: 11) using ollama provider.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:10 - src.data_processing.embedder - INFO - Finished embedding generation. Successfully structured 43 chunks for DB out of 43.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:10 - nb_01_ingestion_embedding - INFO - 43 chunks ont maintenant des embeddings.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:10 - nb_01_ingestion_embedding - INFO - Exemple de chunk avec embedding (ID: 2505.24878_chunk_001):\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:10 - nb_01_ingestion_embedding - INFO -   Fournisseur d'Embedding Utilisé: ollama\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:10 - nb_01_ingestion_embedding - INFO -   Modèle d'Embedding Utilisé: nomic-embed-text\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:10 - nb_01_ingestion_embedding - INFO -   Dimension Réelle de l'Embedding: 768\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:10 - nb_01_ingestion_embedding - INFO -   Vecteur d'Embedding (5 premières dimensions): [0.1418522745370865, 1.1173579692840576, -2.4316766262054443, -0.11591464281082153, 1.5562331676483154]...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Contenu de la cellule avec l'ID 817ea79a (Étape 4)\n",
    "logger.info(f\"\\n--- Étape 4: Génération des Embeddings ---\")\n",
    "# MODIFIÉ : L'annotation de type pour chunks_with_embeddings\n",
    "chunks_with_embeddings: List[Dict[str, Any]] = [] # Anciennement List[ProcessedChunkWithEmbedding]\n",
    "\n",
    "if processed_chunks:\n",
    "    # Vérification proactive des prérequis pour le fournisseur d'embedding configuré\n",
    "    provider_check_ok = True\n",
    "    active_provider = settings.DEFAULT_EMBEDDING_PROVIDER.lower()\n",
    "    if active_provider == \"openai\" and not settings.OPENAI_API_KEY:\n",
    "        logger.error(\"OpenAI est le fournisseur d'embedding, mais OPENAI_API_KEY n'est pas configurée. Impossible de générer les embeddings.\")\n",
    "        provider_check_ok = False\n",
    "    elif active_provider == \"ollama\":\n",
    "        if not settings.OLLAMA_BASE_URL:\n",
    "            logger.error(\"Ollama est le fournisseur d'embedding, mais OLLAMA_BASE_URL n'est pas configurée.\")\n",
    "            provider_check_ok = False\n",
    "        if not settings.OLLAMA_EMBEDDING_MODEL_NAME:\n",
    "            logger.error(\"Ollama est le fournisseur d'embedding, mais OLLAMA_EMBEDDING_MODEL_NAME n'est pas configuré.\")\n",
    "            provider_check_ok = False\n",
    "    \n",
    "    if provider_check_ok:\n",
    "        logger.info(f\"Appel de generate_embeddings_for_chunks avec le provider: {active_provider}\")\n",
    "        # generate_embeddings_for_chunks retourne maintenant List[Dict[str, Any]]\n",
    "        chunks_with_embeddings = generate_embeddings_for_chunks(processed_chunks)\n",
    "        \n",
    "        if chunks_with_embeddings:\n",
    "            logger.info(f\"{len(chunks_with_embeddings)} chunks ont maintenant des embeddings.\")\n",
    "            if len(chunks_with_embeddings) > 0:\n",
    "                chunk_emb_example = chunks_with_embeddings[0] # C'est maintenant un Dict[str, Any]\n",
    "                logger.info(f\"Exemple de chunk avec embedding (ID: {chunk_emb_example['chunk_id']}):\")\n",
    "                # MODIFIÉ : Accès aux champs via le sous-dictionnaire 'metadata'\n",
    "                logger.info(f\"  Fournisseur d'Embedding Utilisé: {chunk_emb_example['metadata'].get('embedding_provider', 'N/A')}\")\n",
    "                logger.info(f\"  Modèle d'Embedding Utilisé: {chunk_emb_example['metadata'].get('embedding_model', 'N/A')}\")\n",
    "                logger.info(f\"  Dimension Réelle de l'Embedding: {chunk_emb_example['metadata'].get('embedding_dimension', 'N/A')}\") \n",
    "                logger.info(f\"  Vecteur d'Embedding (5 premières dimensions): {chunk_emb_example.get('embedding', [])[:5]}...\") # 'embedding' est toujours au premier niveau\n",
    "        else:\n",
    "            logger.warning(\"Aucun embedding n'a été généré.\")\n",
    "    else:\n",
    "        logger.warning(\"Prérequis non remplis pour le fournisseur d'embedding configuré. Étape d'embedding sautée.\")\n",
    "else:\n",
    "    logger.warning(\"Aucun chunk traité à embedder. Étape d'embedding sautée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1c78c",
   "metadata": {},
   "source": [
    "### Étape 5: Stockage dans MongoDB et Création des Index\n",
    "\n",
    "Enfin, les chunks avec leurs embeddings sont insérés dans une collection MongoDB. Nous créons également les index de recherche vectorielle et textuelle nécessaires pour notre moteur RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecc36835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-02 22:51:14 - nb_01_ingestion_embedding - INFO - \n",
      "--- Étape 5: Stockage MongoDB et Création d'Index ---\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:14 - nb_01_ingestion_embedding - INFO - Initialisation de MongoDBManager pour la collection: arxiv_chunks_notebook_test\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:14 - src.vector_store.mongodb_manager - INFO - MongoDBManager initialized for database: cognitive_swarm_db\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:14 - src.vector_store.mongodb_manager - INFO - Successfully connected to MongoDB database: cognitive_swarm_db\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:14 - nb_01_ingestion_embedding - INFO - Suppression des documents existants dans la collection de test 'arxiv_chunks_notebook_test'...\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:15 - nb_01_ingestion_embedding - INFO - 0 documents supprimés.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:15 - nb_01_ingestion_embedding - INFO - Insertion de 43 chunks dans MongoDB...\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:15 - src.vector_store.mongodb_manager - INFO - Attempting to insert 43 chunks into collection 'arxiv_chunks_notebook_test'.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:16 - src.vector_store.mongodb_manager - INFO - Insertion completed for collection 'arxiv_chunks_notebook_test'. Total documents attempted: 43. Successfully inserted: 43. Duplicates skipped (based on _id=chunk_id): 0.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:16 - nb_01_ingestion_embedding - INFO - Résumé de l'insertion MongoDB: {'inserted_count': 43, 'duplicate_count': 0, 'errors': []}\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:16 - nb_01_ingestion_embedding - INFO - Création/Vérification de l'index vectoriel 'vector_index_notebook_test'. La dimension de l'index sera basée sur le fournisseur d'embedding configuré: 'ollama'.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:17 - src.vector_store.mongodb_manager - INFO - Using effective embedding dimension 768 for index 'vector_index_notebook_test' based on provider 'ollama'.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:17 - src.vector_store.mongodb_manager - INFO - Attempting to create 'vectorSearch' type index 'vector_index_notebook_test' on 'arxiv_chunks_notebook_test' with definition: {'fields': [{'type': 'vector', 'path': 'embedding', 'numDimensions': 768, 'similarity': 'cosine'}, {'type': 'filter', 'path': 'metadata.arxiv_id'}, {'type': 'filter', 'path': 'metadata.original_document_title'}, {'type': 'filter', 'path': 'metadata.primary_category'}, {'type': 'filter', 'path': 'metadata.embedding_provider'}, {'type': 'filter', 'path': 'metadata.embedding_model'}]}\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:17 - src.vector_store.mongodb_manager - INFO - 'vectorSearch' type index 'vector_index_notebook_test' creation initiated on 'arxiv_chunks_notebook_test'. It may take a few minutes to become active.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:17 - nb_01_ingestion_embedding - INFO - Index vectoriel géré avec succès.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:17 - nb_01_ingestion_embedding - INFO - Création/Vérification de l'index textuel 'text_index_notebook_test'...\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:17 - src.vector_store.mongodb_manager - INFO - Attempting to create standard text search index 'text_index_notebook_test' on 'arxiv_chunks_notebook_test' with definition: {'mappings': {'dynamic': False, 'fields': {'text_chunk': {'type': 'string', 'analyzer': 'lucene.standard'}, 'metadata.original_document_title': {'type': 'string', 'analyzer': 'lucene.standard'}}}}\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - src.vector_store.mongodb_manager - INFO - Text search index 'text_index_notebook_test' creation initiated on 'arxiv_chunks_notebook_test'.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO - Index textuel géré avec succès.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO - Exemple de document récupéré de MongoDB (ID: 2505.24878_chunk_001):\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO -   Texte: Open CaptchaWorld: A Comprehensive\n",
      "Web-based Platform for Testing and Benchmarking\n",
      "Multimodal LLM Ag...\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO -   Fournisseur Embedding (depuis metadata): ollama\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO -   Modèle Embedding (depuis metadata): nomic-embed-text\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO -   Dimension Embedding (depuis metadata): 768\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO -   ArXiv ID (depuis metadata): 2505.24878\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO -   Titre Doc (depuis metadata): Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO -   Primary Category (depuis metadata): cs.AI\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO -   Vecteur Embedding (premières dims): [0.1418522745370865, 1.1173579692840576, -2.4316766262054443]...\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - src.vector_store.mongodb_manager - INFO - MongoDB connection closed.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO - Connexion MongoDB fermée.\u001b[0m\n",
      "\u001b[34m2025-06-02 22:51:18 - nb_01_ingestion_embedding - INFO - \n",
      "Pipeline d'Ingestion et d'Embedding terminé pour ce notebook !\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Cellule Étape 5: Stockage MongoDB et Création d'Index (ID: ecc36835)\n",
    "\n",
    "logger.info(f\"\\n--- Étape 5: Stockage MongoDB et Création d'Index ---\")\n",
    "mongo_mgr = None \n",
    "\n",
    "# chunks_with_embeddings est une List[Dict[str, Any]] avec la nouvelle structure\n",
    "if chunks_with_embeddings:\n",
    "    try:\n",
    "        logger.info(f\"Initialisation de MongoDBManager pour la collection: {COLLECTION_NAME_NOTEBOOK}\")\n",
    "        mongo_mgr = MongoDBManager(mongo_uri=settings.MONGODB_URI, db_name=settings.MONGO_DATABASE_NAME)\n",
    "        mongo_mgr.connect()\n",
    "\n",
    "        test_collection = mongo_mgr.get_collection(COLLECTION_NAME_NOTEBOOK)\n",
    "        if test_collection is not None: \n",
    "            logger.info(f\"Suppression des documents existants dans la collection de test '{COLLECTION_NAME_NOTEBOOK}'...\")\n",
    "            delete_result = test_collection.delete_many({})\n",
    "            logger.info(f\"{delete_result.deleted_count} documents supprimés.\")\n",
    "        else:\n",
    "            # Si test_collection est None, cela signifie que mongo_mgr.get_collection a échoué (probablement un problème de connexion)\n",
    "            # Il est préférable de ne pas continuer si la collection n'est pas accessible.\n",
    "            logger.error(f\"Impossible d'obtenir la collection {COLLECTION_NAME_NOTEBOOK}. L'insertion et la création d'index vont échouer. Arrêt.\")\n",
    "            # Vous pourriez vouloir lever une exception ici pour arrêter l'exécution du notebook\n",
    "            raise ConnectionError(f\"Impossible d'obtenir la collection {COLLECTION_NAME_NOTEBOOK} depuis MongoDB.\")\n",
    "\n",
    "\n",
    "        logger.info(f\"Insertion de {len(chunks_with_embeddings)} chunks dans MongoDB...\")\n",
    "        # insert_chunks_with_embeddings attend List[Dict[str, Any]] et mappe chunk_id à _id\n",
    "        insertion_summary = mongo_mgr.insert_chunks_with_embeddings(\n",
    "            chunks_with_embeddings,\n",
    "            collection_name=COLLECTION_NAME_NOTEBOOK\n",
    "        )\n",
    "        logger.info(f\"Résumé de l'insertion MongoDB: {insertion_summary}\")\n",
    "\n",
    "        if insertion_summary.get(\"inserted_count\", 0) > 0:\n",
    "            logger.info(f\"Création/Vérification de l'index vectoriel '{VECTOR_INDEX_NAME_NOTEBOOK}'. La dimension de l'index sera basée sur le fournisseur d'embedding configuré: '{settings.DEFAULT_EMBEDDING_PROVIDER}'.\")\n",
    "            \n",
    "            # MODIFIÉ : Mettre à jour les chemins pour les champs de filtrage vectoriel\n",
    "            # Ces champs sont maintenant attendus à l'intérieur du champ \"metadata\"\n",
    "            vector_filter_fields = [\n",
    "                \"metadata.arxiv_id\", \n",
    "                \"metadata.original_document_title\", \n",
    "                \"metadata.primary_category\", # Assurez-vous que 'primary_category' est bien dans le dict 'metadata' des chunks\n",
    "                \"metadata.embedding_provider\", \n",
    "                \"metadata.embedding_model\"     \n",
    "            ]\n",
    "            # Note: Si 'metadata.primary_category' n'existe pas dans tous les documents, \n",
    "            # l'indexation de ce champ spécifique pourrait ne pas s'appliquer à ces documents, \n",
    "            # mais la création de l'index devrait réussir si le type est bien géré (e.g. stringFacet).\n",
    "\n",
    "            success_vector_idx = mongo_mgr.create_vector_search_index(\n",
    "                collection_name=COLLECTION_NAME_NOTEBOOK,\n",
    "                index_name=VECTOR_INDEX_NAME_NOTEBOOK, # Doit être le nom de l'index de type \"vectorSearch\"\n",
    "                embedding_field=\"embedding\", # Ce champ est au premier niveau\n",
    "                filter_fields=vector_filter_fields # Ces champs sont maintenant préfixés par \"metadata.\"\n",
    "            )\n",
    "            if success_vector_idx:\n",
    "                logger.info(\"Index vectoriel géré avec succès.\")\n",
    "            else:\n",
    "                logger.warning(\"Problème lors de la gestion de l'index vectoriel.\")\n",
    "\n",
    "            logger.info(f\"Création/Vérification de l'index textuel '{TEXT_INDEX_NAME_NOTEBOOK}'...\")\n",
    "            # MODIFIÉ : Mettre à jour les chemins pour les champs de texte additionnels\n",
    "            additional_text_fields_for_index = {\n",
    "                \"metadata.original_document_title\": \"string\", \n",
    "                # Si vous aviez un champ 'title' distinct dans les métadonnées source :\n",
    "                # \"metadata.title\": \"string\", \n",
    "                # Assurez-vous que ces chemins existent réellement dans la structure de vos documents MongoDB\n",
    "            }\n",
    "            success_text_idx = mongo_mgr.create_text_search_index(\n",
    "                collection_name=COLLECTION_NAME_NOTEBOOK,\n",
    "                index_name=TEXT_INDEX_NAME_NOTEBOOK,\n",
    "                text_field=\"text_chunk\", # Ce champ est au premier niveau\n",
    "                additional_text_fields=additional_text_fields_for_index\n",
    "            )\n",
    "            if success_text_idx:\n",
    "                logger.info(\"Index textuel géré avec succès.\")\n",
    "            else:\n",
    "                logger.warning(\"Problème lors de la gestion de l'index textuel.\")\n",
    "            \n",
    "            if test_collection is not None: # Ré-vérifier, même si on a levé une erreur plus tôt\n",
    "                first_chunk_id_val = chunks_with_embeddings[0][\"chunk_id\"]\n",
    "                sample_doc_from_db = test_collection.find_one({\"_id\": first_chunk_id_val})\n",
    "                if sample_doc_from_db:\n",
    "                    logger.info(f\"Exemple de document récupéré de MongoDB (ID: {sample_doc_from_db['_id']}):\")\n",
    "                    logger.info(f\"  Texte: {sample_doc_from_db.get('text_chunk', '')[:100]}...\")\n",
    "                    \n",
    "                    # MODIFIÉ : Accès aux champs via le sous-dictionnaire 'metadata'\n",
    "                    doc_metadata = sample_doc_from_db.get(\"metadata\")\n",
    "                    if isinstance(doc_metadata, dict):\n",
    "                        logger.info(f\"  Fournisseur Embedding (depuis metadata): {doc_metadata.get('embedding_provider')}\")\n",
    "                        logger.info(f\"  Modèle Embedding (depuis metadata): {doc_metadata.get('embedding_model')}\")\n",
    "                        logger.info(f\"  Dimension Embedding (depuis metadata): {doc_metadata.get('embedding_dimension')}\")\n",
    "                        logger.info(f\"  ArXiv ID (depuis metadata): {doc_metadata.get('arxiv_id')}\")\n",
    "                        logger.info(f\"  Titre Doc (depuis metadata): {doc_metadata.get('original_document_title')}\")\n",
    "                        logger.info(f\"  Primary Category (depuis metadata): {doc_metadata.get('primary_category', 'N/A')}\") # Exemple\n",
    "                    else:\n",
    "                        logger.warning(\"  Le champ 'metadata' est manquant ou n'est pas un dictionnaire dans le document récupéré.\")\n",
    "                    \n",
    "                    logger.info(f\"  Vecteur Embedding (premières dims): {str(sample_doc_from_db.get('embedding', [])[:3])[:100]}...\")\n",
    "                else:\n",
    "                    logger.warning(f\"Impossible de récupérer le document d'exemple '{first_chunk_id_val}' depuis MongoDB.\")\n",
    "            # La clause 'else' pour 'test_collection is None' est déjà gérée par le raise ConnectionError plus haut.\n",
    "        else:\n",
    "            logger.warning(\"Aucun document n'a été inséré, la création des index pourrait ne pas être pertinente ou échouer sur une collection vide.\")\n",
    "\n",
    "    except ConnectionFailure as cf: # Spécifique pour les erreurs de connexion attrapées plus tôt\n",
    "        logger.error(f\"Erreur de connexion MongoDB non récupérable : {cf}\", exc_info=True)\n",
    "        # L'exécution s'arrête ici si ConnectionError a été levée plus tôt\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors des opérations MongoDB: {e}\", exc_info=True)\n",
    "    finally:\n",
    "        if mongo_mgr:\n",
    "            mongo_mgr.close()\n",
    "            logger.info(\"Connexion MongoDB fermée.\")\n",
    "else:\n",
    "    logger.warning(\"Aucun chunk avec embedding à stocker. Étape MongoDB sautée.\")\n",
    "\n",
    "logger.info(\"\\nPipeline d'Ingestion et d'Embedding terminé pour ce notebook !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5416e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook a illustré l'ensemble du pipeline d'ingestion :\n",
    "- Téléchargement des données sources (ArXiv).\n",
    "- Parsing pour extraire le texte et les métadonnées.\n",
    "- Prétraitement pour nettoyer et diviser le texte en chunks.\n",
    "- Génération des embeddings pour chaque chunk.\n",
    "- Stockage des données enrichies dans MongoDB et création des index nécessaires pour la recherche.\n",
    "\n",
    "Les données sont maintenant prêtes à être utilisées par le `RetrievalEngine` et les agents du \"Cognitive Swarm\". Vous pouvez explorer la collection MongoDB (`arxiv_chunks_notebook_test` dans la base `cognitive_swarm_db` par défaut) pour voir les documents stockés."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitive-swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
