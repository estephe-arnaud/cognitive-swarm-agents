{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c5cad9a",
   "metadata": {},
   "source": [
    "# Notebook 06: Test Approfondi du Pipeline de Bout en Bout\n",
    "\n",
    "Ce notebook est dédié à un test complet et une analyse détaillée du workflow \"Cognitive Swarm\" sur une requête utilisateur complexe. Nous allons observer les sorties intermédiaires des agents, le flux de décision, et la qualité de la synthèse finale. Nous explorerons également comment inspecter les états sauvegardés par le checkpointer MongoDB.\n",
    "\n",
    "**Prérequis :**\n",
    "* Environnement configuré via `00_setup_environment.ipynb`.\n",
    "* Base de données MongoDB peuplée via `01_data_ingestion_and_embedding.ipynb` ou `scripts/run_ingestion.py`.\n",
    "* Clés API (`OPENAI_API_KEY`, `MONGO_URI`) configurées dans `.env`.\n",
    "* Le `MongoDBSaver` (checkpointer) est activé par défaut dans `src/graph/main_workflow.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a65b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import uuid \n",
    "import pprint # Pour un affichage plus lisible des dictionnaires\n",
    "\n",
    "# Ajout de la racine du projet au PYTHONPATH\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "    print(f\"Ajout de {project_root} au PYTHONPATH\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "dotenv_path = project_root / \".env\"\n",
    "if dotenv_path.exists():\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "    print(f\"Variables d'environnement chargées depuis : {dotenv_path}\")\n",
    "else:\n",
    "    print(f\"ATTENTION: Fichier .env non trouvé à {dotenv_path}.\")\n",
    "\n",
    "from config.settings import settings\n",
    "from config.logging_config import setup_logging\n",
    "\n",
    "from src.graph.main_workflow import run_cognitive_swarm_v2_1, GraphState # GraphState pour type hint\n",
    "from src.graph.checkpointer import MongoDBSaver # Pour inspecter les checkpoints (dans une cellule ultérieure)\n",
    "\n",
    "# Configurer le logging\n",
    "LOG_LEVEL_NOTEBOOK = \"INFO\" # Mettre à DEBUG pour voir TOUS les logs du workflow\n",
    "setup_logging(level=LOG_LEVEL_NOTEBOOK) \n",
    "logger = logging.getLogger(\"nb_06_e2e_test\")\n",
    "\n",
    "# --- MODIFIÉ : Vérification des prérequis pour LLMs et Embeddings utilisés par le workflow ---\n",
    "logger.info(f\"--- Configuration Active pour le Test de Bout en Bout ---\")\n",
    "# Pour les LLMs génératifs utilisés par les agents du workflow\n",
    "active_llm_provider = settings.DEFAULT_LLM_MODEL_PROVIDER.lower()\n",
    "logger.info(f\"Fournisseur LLM génératif principal : '{active_llm_provider}'\")\n",
    "if active_llm_provider == \"openai\" and not settings.OPENAI_API_KEY:\n",
    "    logger.error(f\"ERREUR : Le fournisseur LLM est 'openai', mais OPENAI_API_KEY n'est pas configurée.\")\n",
    "elif active_llm_provider == \"huggingface_api\" and not settings.HUGGINGFACE_API_KEY:\n",
    "    logger.error(f\"ERREUR : Le fournisseur LLM est 'huggingface_api', mais HUGGINGFACE_API_KEY n'est pas configurée.\")\n",
    "elif active_llm_provider == \"ollama\" and not settings.OLLAMA_BASE_URL:\n",
    "    logger.error(f\"ERREUR : Le fournisseur LLM est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée.\")\n",
    "\n",
    "# Pour les embeddings (utilisés par RetrievalEngine via les outils)\n",
    "active_embedding_provider = settings.DEFAULT_EMBEDDING_PROVIDER.lower()\n",
    "logger.info(f\"Fournisseur d'Embedding (pour RAG) : '{active_embedding_provider}'\")\n",
    "if active_embedding_provider == \"openai\" and not settings.OPENAI_API_KEY:\n",
    "    logger.error(f\"ERREUR : Le fournisseur d'embedding est 'openai', mais OPENAI_API_KEY n'est pas configurée.\")\n",
    "elif active_embedding_provider == \"ollama\":\n",
    "    if not settings.OLLAMA_BASE_URL:\n",
    "        logger.error(f\"ERREUR : Le fournisseur d'embedding est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée.\")\n",
    "    if not settings.OLLAMA_EMBEDDING_MODEL_NAME:\n",
    "        logger.error(f\"ERREUR : Le fournisseur d'embedding est 'ollama', mais OLLAMA_EMBEDDING_MODEL_NAME n'est pas configuré.\")\n",
    "\n",
    "\n",
    "# Pour MongoDB (checkpointer et RAG)\n",
    "if not settings.MONGO_URI:\n",
    "    logger.error(\"ERREUR : MONGO_URI non trouvé. Le checkpointer et le RetrievalEngine (RAG) échoueront.\")\n",
    "# --- FIN MODIFIÉ ---\n",
    "\n",
    "# Fonction d'affichage de l'état (se concentre sur la synthèse ou l'erreur, puis état brut)\n",
    "def display_final_synthesis(final_state: dict):\n",
    "    print(\"\\n--- Synthèse Finale Produite (ou Erreur) ---\")\n",
    "    if not final_state:\n",
    "        print(\"Aucun état final retourné.\")\n",
    "        return\n",
    "    \n",
    "    synthesis = final_state.get(\"synthesis_output\")\n",
    "    error_msg = final_state.get(\"error_message\")\n",
    "\n",
    "    if synthesis:\n",
    "        print(synthesis)\n",
    "    elif error_msg:\n",
    "        print(f\"ERREUR DANS LE WORKFLOW : {error_msg}\")\n",
    "    else:\n",
    "        print(\"Aucune synthèse explicite ni message d'erreur trouvé dans les champs dédiés de l'état final.\")\n",
    "        print(\"Affichage de l'état final complet pour débogage :\")\n",
    "        pprint.pprint(final_state) # pprint est importé au début de la cellule\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd0c5ec",
   "metadata": {},
   "source": [
    "### 1. Définition d'une Requête Utilisateur Complexe et Multi-Facettes\n",
    "\n",
    "Nous allons choisir une requête qui nécessite une planification, potentiellement une recherche de nouveaux documents et une analyse de plusieurs aspects avant la synthèse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836af575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de requête complexe :\n",
    "complex_query = (\n",
    "    \"Provide a comprehensive overview of the use of deep reinforcement learning (DRL) for \"\n",
    "    \"autonomous drone navigation in complex, cluttered urban environments. \"\n",
    "    \"The overview should cover: \"\n",
    "    \"1. Key DRL algorithms employed (e.g., PPO, SAC, DDPG variations). \"\n",
    "    \"2. Common simulation environments and sim-to-real transfer challenges specific to this domain. \"\n",
    "    \"3. How sensor fusion (e.g., vision, LiDAR, IMU) is typically handled in DRL policies for drones. \"\n",
    "    \"4. Explicitly search for and include findings from any ArXiv papers published in the last 12-18 months on this topic, \"\n",
    "    \"especially those addressing safety or obstacle avoidance. \"\n",
    "    \"5. Summarize future research directions.\"\n",
    ")\n",
    "\n",
    "logger.info(f\"Requête complexe pour le test de bout en bout : '{complex_query}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f7984",
   "metadata": {},
   "source": [
    "### 2. Exécution du Workflow \"Cognitive Swarm\"\n",
    "\n",
    "Nous lançons le workflow avec cette requête. Le checkpointer MongoDB sauvegardera les états intermédiaires.\n",
    "Nous allons observer les logs (surtout si `LOG_LEVEL_NOTEBOOK` est à `DEBUG` dans la cellule de configuration ou si la fonction `run_cognitive_swarm_v2_1` a sa propre verbosité d'événements activée)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a09d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_thread_id = \"e2e_test_thread_\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Lancement du workflow de bout en bout pour la requête avec thread_id: {e2e_thread_id}\")\n",
    "print(\"Surveillez la console pour les logs détaillés du flux d'agents et des appels d'outils...\")\n",
    "\n",
    "final_state_e2e = None\n",
    "if settings.OPENAI_API_KEY and settings.MONGO_URI:\n",
    "    try:\n",
    "        # La fonction run_cognitive_swarm_v2_1 affiche déjà beaucoup d'informations en streaming\n",
    "        final_state_e2e = asyncio.run(run_cognitive_swarm_v2_1(complex_query, thread_id=e2e_thread_id))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'exécution de asyncio.run(run_cognitive_swarm_v2_1): {e}\", exc_info=True)\n",
    "        print(f\"ERREUR pendant l'exécution du workflow : {e}\")\n",
    "else:\n",
    "    print(\"Clés API OpenAI ou MONGO_URI manquantes. Exécution du workflow annulée.\")\n",
    "\n",
    "# Afficher la synthèse finale (ou l'erreur)\n",
    "if final_state_e2e:\n",
    "    display_final_synthesis(final_state_e2e)\n",
    "else:\n",
    "    print(\"L'exécution du workflow n'a pas retourné d'état final.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee64145",
   "metadata": {},
   "source": [
    "### 3. Analyse Qualitative des Sorties Intermédiaires (si `final_state_e2e` est disponible)\n",
    "\n",
    "Si l'exécution précédente a réussi et retourné `final_state_e2e`, nous pouvons examiner certains des champs clés de cet état pour comprendre le comportement du système."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded95f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if final_state_e2e and not final_state_e2e.get(\"error_message\"):\n",
    "    print(\"\\n--- Analyse des Sorties Intermédiaires Clés ---\")\n",
    "\n",
    "    # 1. Plan de Recherche\n",
    "    research_plan = final_state_e2e.get(\"research_plan\")\n",
    "    if research_plan:\n",
    "        print(\"\\n### Plan de Recherche Généré par ResearchPlannerAgent ###\")\n",
    "        print(research_plan)\n",
    "    else:\n",
    "        print(\"\\nAucun plan de recherche explicite trouvé dans l'état final.\")\n",
    "\n",
    "    # 2. Résultats de Recherche ArXiv (si stockés explicitement)\n",
    "    # Note: Dans main_workflow.py, arxiv_search_results n'est pas explicitement peuplé dans GraphState.\n",
    "    # Les résultats des outils sont dans la liste `messages` (sous forme de ToolMessage).\n",
    "    # On peut parcourir les messages pour trouver les ToolMessage pertinents.\n",
    "    print(\"\\n### Analyse des Messages (pour les résultats d'outils) ###\")\n",
    "    messages = final_state_e2e.get(\"messages\", [])\n",
    "    arxiv_tool_outputs = []\n",
    "    kb_tool_outputs = []\n",
    "\n",
    "    for msg in messages:\n",
    "        if msg.type.upper() == \"TOOL\": # C'est un ToolMessage\n",
    "            # Le nom de l'outil est dans msg.name (si défini par ToolNode, sinon dans le contenu)\n",
    "            # Le contenu du ToolMessage est le résultat de l'outil.\n",
    "            # Pour notre arxiv_search_tool, le résultat est une liste de dictionnaires.\n",
    "            # Pour knowledge_base_retrieval_tool, c'est une liste de dictionnaires (chunks).\n",
    "            \n",
    "            # On pourrait essayer de deviner l'outil par le contenu ou si on avait un `name` plus explicite sur ToolMessage\n",
    "            # Pour l'instant, on va juste afficher les contenus des ToolMessage.\n",
    "            # On pourrait améliorer cela en ayant des noms d'outils clairs sur les ToolMessages\n",
    "            # ou en regardant l'AIMessage précédent qui a fait le tool_call.\n",
    "            \n",
    "            # Simple affichage du contenu du ToolMessage\n",
    "            # On suppose que le contenu est une chaîne ou une liste/dict sérialisable en JSON\n",
    "            try:\n",
    "                tool_content = json.loads(msg.content) if isinstance(msg.content, str) and (msg.content.startswith('[') or msg.content.startswith('{')) else msg.content\n",
    "                # Heuristique pour différencier (très basique)\n",
    "                if isinstance(tool_content, list) and tool_content and \"pdf_url\" in tool_content[0]:\n",
    "                    print(f\"\\n[Résultat d'un Outil ArXiv (probable)] - {len(tool_content)} items:\")\n",
    "                    for item in tool_content[:2]: # Afficher les 2 premiers\n",
    "                        print(f\"  - Titre: {item.get('title', 'N/A')[:70]}..., PDF: {item.get('pdf_url')}\")\n",
    "                    arxiv_tool_outputs.append(tool_content)\n",
    "                elif isinstance(tool_content, list) and tool_content and \"text_chunk\" in tool_content[0]:\n",
    "                    print(f\"\\n[Résultat d'un Outil KB Retrieval (probable)] - {len(tool_content)} chunks:\")\n",
    "                    for item in tool_content[:1]: # Afficher le premier\n",
    "                        print(f\"  - Chunk ID: {item.get('chunk_id', 'N/A')}, Score: {item.get('retrieval_score', 'N/A'):.4f}\")\n",
    "                        print(f\"    Texte: {item.get('text_chunk', '')[:150]}...\")\n",
    "                    kb_tool_outputs.append(tool_content)\n",
    "                # else:\n",
    "                #     print(f\"\\n[Résultat d'Outil (type inconnu ou non structuré)]:\\n{str(msg.content)[:300]}...\")\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                # print(f\"\\n[Résultat d'Outil (chaîne brute)]:\\n{str(msg.content)[:300]}...\")\n",
    "                pass # Silencieux si ce n'est pas du JSON facilement identifiable\n",
    "\n",
    "\n",
    "    # 3. Résumé de l'Analyse de Documents\n",
    "    doc_analysis_summary = final_state_e2e.get(\"document_analysis_summary\")\n",
    "    if doc_analysis_summary:\n",
    "        print(\"\\n### Résumé de l'Analyse de Documents (par DocumentAnalysisAgent) ###\")\n",
    "        print(doc_analysis_summary)\n",
    "    else:\n",
    "        print(\"\\nAucun résumé d'analyse de document explicite trouvé dans l'état final (peut être intégré dans la synthèse ou les messages).\")\n",
    "    \n",
    "    print(\"\\n--- Fin de l'Analyse des Sorties Intermédiaires ---\")\n",
    "\n",
    "elif final_state_e2e and final_state_e2e.get(\"error_message\"):\n",
    "    print(f\"L'exécution du workflow a produit une erreur, analyse des sorties intermédiaires impossible de cette manière.\")\n",
    "else:\n",
    "    print(\"État final non disponible, impossible d'analyser les sorties intermédiaires.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5b268",
   "metadata": {},
   "source": [
    "### 4. Inspection des Checkpoints dans MongoDB\n",
    "\n",
    "Si le `MongoDBSaver` est actif (ce qui est le cas par défaut dans notre `main_workflow.py`), nous pouvons interroger MongoDB pour voir les états sauvegardés pour le `thread_id` de cette exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4dfff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def inspect_checkpoints(thread_id: str):\n",
    "    logger.info(f\"\\n--- Inspection des Checkpoints pour Thread ID: {thread_id} ---\")\n",
    "    if not settings.MONGO_URI:\n",
    "        logger.error(\"MONGO_URI non configuré. Impossible d'inspecter les checkpoints.\")\n",
    "        return\n",
    "\n",
    "    checkpointer = None # Pour le bloc finally\n",
    "    try:\n",
    "        # Utiliser la collection configurée dans settings pour les checkpoints LangGraph\n",
    "        checkpointer = MongoDBSaver(\n",
    "            collection_name=settings.LANGGRAPH_CHECKPOINTS_COLLECTION\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Récupération des checkpoints pour thread_id='{thread_id}'...\")\n",
    "        \n",
    "        # Lister tous les checkpoints pour ce thread_id\n",
    "        config_for_list = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        checkpoints_history = []\n",
    "        async for checkpoint_tuple in checkpointer.alist(config=config_for_list):\n",
    "            checkpoints_history.append(checkpoint_tuple)\n",
    "        \n",
    "        if not checkpoints_history:\n",
    "            print(f\"Aucun checkpoint trouvé pour le thread_id: {thread_id}\")\n",
    "            return\n",
    "\n",
    "        print(f\"Trouvé {len(checkpoints_history)} checkpoints pour le thread_id: {thread_id} (du plus récent au plus ancien):\")\n",
    "        \n",
    "        for i, cp_tuple in enumerate(checkpoints_history[:3]): # Afficher les 3 plus récents\n",
    "            print(f\"\\nCheckpoint #{i+1} (ts: {cp_tuple.checkpoint['id']}):\")\n",
    "            print(f\"  Metadata: {cp_tuple.metadata}\")\n",
    "            print(f\"  Parent ts: {cp_tuple.parent_config['configurable'].get('thread_ts') if cp_tuple.parent_config else 'None'}\")\n",
    "            \n",
    "            # Afficher le dernier message dans ce checkpoint pour avoir une idée de l'étape\n",
    "            messages_in_checkpoint = cp_tuple.checkpoint.get(\"channel_values\", {}).get(\"messages\", [])\n",
    "            if messages_in_checkpoint:\n",
    "                last_msg_in_cp = messages_in_checkpoint[-1]\n",
    "                msg_type = getattr(last_msg_in_cp, 'type', 'UNKNOWN').upper()\n",
    "                msg_name = getattr(last_msg_in_cp, 'name', '')\n",
    "                msg_content = str(getattr(last_msg_in_cp, 'content', ''))\n",
    "                print(f\"  Dernier message dans ce checkpoint: [{msg_type}{' ('+msg_name+')' if msg_name else ''}]: {msg_content[:100]}...\")\n",
    "            else:\n",
    "                print(\"  Aucun message dans channel_values pour ce checkpoint.\")\n",
    "        \n",
    "        if len(checkpoints_history) > 3:\n",
    "            print(f\"\\n... et {len(checkpoints_history) - 3} checkpoint(s) plus ancien(s).\")\n",
    "\n",
    "        # Récupérer un checkpoint spécifique (le plus récent par exemple)\n",
    "        # latest_checkpoint_config = {\"configurable\": {\"thread_id\": thread_id, \"thread_ts\": checkpoints_history[0].checkpoint['id']}}\n",
    "        # specific_checkpoint_tuple = await checkpointer.aget_tuple(latest_checkpoint_config)\n",
    "        # if specific_checkpoint_tuple:\n",
    "        #     print(\"\\nDétail du checkpoint le plus récent:\")\n",
    "        #     pprint.pprint(specific_checkpoint_tuple.checkpoint)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'inspection des checkpoints: {e}\", exc_info=True)\n",
    "        print(f\"Erreur lors de l'inspection des checkpoints: {e}\")\n",
    "    finally:\n",
    "        if checkpointer and hasattr(checkpointer, 'aclose'): # MongoDBSaver a une méthode aclose\n",
    "             await checkpointer.aclose()\n",
    "\n",
    "\n",
    "if final_state_e2e: # Seulement si l'exécution précédente a défini un thread_id\n",
    "    asyncio.run(inspect_checkpoints(e2e_thread_id))\n",
    "else:\n",
    "    logger.warning(\"e2e_thread_id non défini ou exécution précédente échouée. Test d'inspection des checkpoints sauté.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074122d4",
   "metadata": {},
   "source": [
    "### 5. Discussion et Analyse Qualitative de la Synthèse Finale\n",
    "\n",
    "Revenons à la synthèse finale produite à l'étape 2 (stockée dans `final_state_e2e['synthesis_output']`).\n",
    "* La synthèse répond-elle de manière complète et précise à la requête complexe initiale ?\n",
    "* Les différents aspects de la requête (algorithmes DRL, environnements de simulation, défis sim-to-real, fusion de capteurs, résultats récents d'ArXiv, directions futures) sont-ils couverts ?\n",
    "* L'information est-elle bien structurée et cohérente ?\n",
    "* Y a-t-il des signes d'hallucination ou des informations manquantes cruciales (en supposant que le corpus contient les informations nécessaires) ?\n",
    "\n",
    "Cette analyse qualitative est subjective mais essentielle pour comprendre les forces et faiblesses actuelles du système. Elle peut guider les améliorations des prompts des agents, de la logique de routage, ou des stratégies RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed1bb2e",
   "metadata": {},
   "source": [
    "## Conclusion de ce Test de Bout en Bout\n",
    "\n",
    "Ce notebook a permis d'exécuter le \"Cognitive Swarm\" sur une requête complexe, d'examiner certaines sorties intermédiaires et la synthèse finale, et de voir comment les checkpoints sont gérés.\n",
    "\n",
    "Ce type de test approfondi est utile pour :\n",
    "- Identifier les goulots d'étranglement ou les points faibles dans le flux des agents.\n",
    "- Évaluer qualitativement la performance globale.\n",
    "- Déboguer des comportements inattendus.\n",
    "- Générer des exemples concrets pour l'évaluation quantitative (par exemple, des paires `(requête, contexte, synthèse)` pour `SynthesisEvaluator`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitive-swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
