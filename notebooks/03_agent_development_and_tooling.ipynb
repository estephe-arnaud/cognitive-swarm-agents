{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Notebook 03: Développement et Test des Agents Individuels et de leurs Outils\n",
    "\n",
    "\n",
    "\n",
    " Ce notebook se concentre sur le test et la démonstration de chaque agent que nous avons défini dans `src/agents/agent_architectures.py`. Nous allons instancier chaque agent, lui soumettre des tâches spécifiques, et observer comment il utilise ses outils (définis dans `src/agents/tool_definitions.py`) et comment il génère ses réponses.\n",
    "\n",
    "\n",
    "\n",
    " **Prérequis :**\n",
    "\n",
    " * Avoir exécuté `00_setup_environment.ipynb` (environnement configuré, clés API dans `.env`).\n",
    "\n",
    " * Pour tester `DocumentAnalysisAgent` efficacement, il est préférable d'avoir une base de données MongoDB peuplée via `01_data_ingestion_and_embedding.ipynb` (ou `scripts/run_ingestion.py`) et que le `RetrievalEngine` (utilisé par `knowledge_base_retrieval_tool`) soit fonctionnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTENTION: Fichier .env non trouvé à .env. Assurez-vous qu'il est à la racine du projet.\n",
      "\u001b[34m2025-06-04 00:01:31 - nb_03_agent_testing - INFO - Les agents et certaines outils (comme CrewAI) utiliseront le fournisseur LLM génératif configuré : 'ollama'.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:31 - nb_03_agent_testing - INFO - Le 'knowledge_base_retrieval_tool' (via RetrievalEngine) utilisera le fournisseur d'embedding : 'ollama'\u001b[0m\n",
      "\u001b[33m2025-06-04 00:01:31 - nb_03_agent_testing - WARNING - Clé API TAVILY (TAVILY_API_KEY) non configurée (non critique pour les tests de base de ce notebook).\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32602/1160553727.py:82: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if \"TAVILY_API_KEY\" in settings.model_fields and not settings.TAVILY_API_KEY:\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json # Pour un affichage lisible des sorties d'outils\n",
    "from typing import Optional, List # Ajout pour robustesse\n",
    "\n",
    "project_root = Path()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# De même, si CWD est la racine du projet, dotenv_path serait `Path().resolve() / \".env\"`\n",
    "dotenv_path = project_root / \".env\"\n",
    "if dotenv_path.exists():\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "    print(f\"Variables d'environnement chargées depuis : {dotenv_path}\")\n",
    "else:\n",
    "    print(f\"ATTENTION: Fichier .env non trouvé à {dotenv_path}. Assurez-vous qu'il est à la racine du projet.\")\n",
    "\n",
    "from config.settings import settings\n",
    "from config.logging_config import setup_logging\n",
    "\n",
    "# Importer les fonctions de création d'agents\n",
    "# get_llm n'est plus importé ici car non utilisé directement ; les fonctions create_..._agent l'utilisent en interne via llm_factory\n",
    "from src.agents.agent_architectures import (\n",
    "    create_research_planner_agent,\n",
    "    create_arxiv_search_agent,\n",
    "    create_document_analysis_agent,\n",
    "    create_synthesis_agent\n",
    "    # get_llm # Supprimé car non utilisé directement dans ce notebook et plus défini dans agent_architectures\n",
    ")\n",
    "\n",
    "# Importer les outils pour d'éventuels tests directs\n",
    "from src.agents.tool_definitions import (\n",
    "    arxiv_search_tool, \n",
    "    knowledge_base_retrieval_tool,\n",
    "    document_deep_dive_analysis_tool # Assurer que cet outil est importé pour test\n",
    ")\n",
    "\n",
    "# Importer les types de messages LangChain\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage # SystemMessage peut être utile\n",
    "\n",
    "setup_logging(level=\"INFO\") # Mettre à DEBUG pour voir les étapes internes des agents\n",
    "logger = logging.getLogger(\"nb_03_agent_testing\")\n",
    "\n",
    "# --- Vérification des prérequis pour les LLMs et Embeddings (logique existante conservée et vérifiée) ---\n",
    "# Pour les agents génératifs (Planner, ArxivSearcher, DocAnalyzer, Synthesizer)\n",
    "# et pour les outils qui pourraient utiliser un LLM (comme document_deep_dive_analysis_tool via CrewAI).\n",
    "active_llm_provider = settings.DEFAULT_LLM_MODEL_PROVIDER.lower()\n",
    "logger.info(f\"Les agents et certaines outils (comme CrewAI) utiliseront le fournisseur LLM génératif configuré : '{active_llm_provider}'.\")\n",
    "if active_llm_provider == \"openai\":\n",
    "    if not settings.OPENAI_API_KEY:\n",
    "        logger.error(f\"ERREUR : Le fournisseur LLM est 'openai', mais OPENAI_API_KEY n'est pas configurée. Les tests des agents/outils utilisant ce LLM échoueront probablement.\")\n",
    "elif active_llm_provider == \"huggingface_api\":\n",
    "    if not settings.HUGGINGFACE_API_KEY:\n",
    "        logger.error(f\"ERREUR : Le fournisseur LLM est 'huggingface_api', mais HUGGINGFACE_API_KEY n'est pas configurée.\")\n",
    "    if not settings.HUGGINGFACE_REPO_ID: # Vérification ajoutée pour être complet\n",
    "        logger.error(f\"ERREUR : Le fournisseur LLM est 'huggingface_api', mais HUGGINGFACE_REPO_ID n'est pas configuré.\")\n",
    "elif active_llm_provider == \"ollama\":\n",
    "    if not settings.OLLAMA_BASE_URL:\n",
    "        logger.error(f\"ERREUR : Le fournisseur LLM est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée.\")\n",
    "    if not settings.OLLAMA_GENERATIVE_MODEL_NAME: # Vérification ajoutée\n",
    "        logger.error(f\"ERREUR : Le fournisseur LLM est 'ollama', mais OLLAMA_GENERATIVE_MODEL_NAME (pour les agents) n'est pas configuré.\")\n",
    "\n",
    "# Pour knowledge_base_retrieval_tool (qui utilise RetrievalEngine, qui utilise le provider d'embedding configuré)\n",
    "active_embedding_provider = settings.DEFAULT_EMBEDDING_PROVIDER.lower()\n",
    "logger.info(f\"Le 'knowledge_base_retrieval_tool' (via RetrievalEngine) utilisera le fournisseur d'embedding : '{active_embedding_provider}'\")\n",
    "if active_embedding_provider == \"openai\": # Pour les embeddings de requête\n",
    "    if not settings.OPENAI_API_KEY:\n",
    "        logger.error(f\"ERREUR : Le fournisseur d'embedding pour RetrievalEngine est 'openai', mais OPENAI_API_KEY n'est pas configurée. Le 'knowledge_base_retrieval_tool' échouera probablement lors de la vectorisation des requêtes.\")\n",
    "elif active_embedding_provider == \"ollama\": # Pour les embeddings de requête\n",
    "    if not settings.OLLAMA_BASE_URL:\n",
    "         logger.error(f\"ERREUR : Le fournisseur d'embedding pour RetrievalEngine est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée.\")\n",
    "    if not settings.OLLAMA_EMBEDDING_MODEL_NAME: # Ajout de cette vérification cruciale\n",
    "        logger.error(f\"ERREUR : Le fournisseur d'embedding pour RetrievalEngine est 'ollama', mais OLLAMA_EMBEDDING_MODEL_NAME n'est pas configuré.\")\n",
    "# Pour \"huggingface\" (local), aucune clé API spécifique n'est requise pour l'embedding des requêtes.\n",
    "\n",
    "if not settings.MONGODB_URI: \n",
    "    logger.error(\"ERREUR : MONGODB_URI non trouvé. Le 'knowledge_base_retrieval_tool' (via RetrievalEngine) ne pourra pas se connecter à la base de données.\")\n",
    "\n",
    "# TAVILY_API_KEY n'est pas utilisé par les outils testés directement dans les cellules suivantes de ce notebook,\n",
    "# mais la vérification est conservée pour information générale si settings.py le liste.\n",
    "if \"TAVILY_API_KEY\" in settings.model_fields and not settings.TAVILY_API_KEY: \n",
    "    logger.warning(\"Clé API TAVILY (TAVILY_API_KEY) non configurée (non critique pour les tests de base de ce notebook).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1. Test du `ResearchPlannerAgent`\n",
    "\n",
    "\n",
    "\n",
    " Cet agent est conçu pour prendre une requête utilisateur complexe et la décomposer en un plan de recherche structuré. Il n'utilise pas d'outils pour cette tâche, se basant uniquement sur ses instructions (prompt système) et le LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-04 00:01:31 - nb_03_agent_testing - INFO - --- Test du ResearchPlannerAgent ---\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:31 - nb_03_agent_testing - INFO - Tentative d'utilisation du provider LLM configuré par défaut: 'ollama' pour le ResearchPlannerAgent.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:31 - src.llm_services.llm_factory - INFO - Initializing LLM for provider: 'ollama' (temperature: 0.0)\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:31 - src.llm_services.llm_factory - INFO - Using Ollama model: mistral from http://localhost:11434\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:31 - src.agents.agent_architectures - INFO - Research Planner Agent created successfully\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:31 - nb_03_agent_testing - INFO - Requête pour le planificateur : 'What are the latest trends and key challenges in applying deep reinforcement learning to multi-robot navigation and coordination, particularly for swarm robotics?'\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:33 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\n",
      "--- Plan de Recherche Généré ---\n",
      "1. Key Questions:\n",
      "   - What are the current state-of-the-art methods for applying deep reinforcement learning (DRL) to multi-robot navigation and coordination?\n",
      "   - How have these methods been applied in the context of swarm robotics?\n",
      "   - What are the key challenges encountered when using DRL for multi-robot navigation and coordination in swarm robotics?\n",
      "   - Are there any recent advancements or solutions proposed to address these challenges?\n",
      "\n",
      "2. Information Sources:\n",
      "   - ArXiv preprints (search terms: \"deep reinforcement learning\" AND \"multi-robot navigation\" OR \"swarm robotics\")\n",
      "   - IEEE Xplore Digital Library (search terms: \"deep reinforcement learning\" AND \"multi-robot navigation\" AND \"swarm robotics\")\n",
      "   - Journal of Field Robotics (search terms: \"deep reinforcement learning\" AND \"multi-robot navigation\" AND \"swarm robotics\")\n",
      "   - Conference proceedings from relevant conferences such as ICRA, IROS, and AAAI (search terms: \"deep reinforcement learning\" AND \"multi-robot navigation\" AND \"swarm robotics\")\n",
      "\n",
      "3. Search Queries:\n",
      "   - Title, abstract, or keyword search for the specified terms in each identified source.\n",
      "   - Include relevant synonyms and related concepts such as \"autonomous multi-agent systems\", \"collective behavior\", \"robot swarms\", etc.\n",
      "   - Limit results to publications from the last 2 years to focus on recent trends.\n",
      "\n",
      "4. Analysis Steps:\n",
      "   - Review each paper's abstract and conclusion to identify the methods, challenges, and advancements related to DRL for multi-robot navigation in swarm robotics.\n",
      "   - Compare and contrast the findings across multiple papers to identify commonalities, differences, and potential areas of improvement.\n",
      "   - Extract key insights and trends from the analysis.\n",
      "\n",
      "5. Final Output Structure:\n",
      "   - A comprehensive report detailing the current state-of-the-art methods for applying DRL to multi-robot navigation in swarm robotics.\n",
      "   - An overview of the key challenges encountered and solutions proposed or under development.\n",
      "   - A summary of recent advancements in this field, including any promising new techniques or approaches.\n",
      "   - Recommendations for future research directions based on the insights gained from the analysis.\n",
      "   - The report should be written in a clear, concise, and easily understandable manner, with appropriate citations to the original sources.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"--- Test du ResearchPlannerAgent ---\")\n",
    "# La cellule d'initialisation de ce notebook (vérification des variables d'environnement et configuration) logue déjà des avertissements \n",
    "# si la configuration pour le active_llm_provider (DEFAULT_LLM_MODEL_PROVIDER) est manquante.\n",
    "# Ce test tentera d'utiliser ce provider configuré.\n",
    "logger.info(f\"Tentative d'utilisation du provider LLM configuré par défaut: '{settings.DEFAULT_LLM_MODEL_PROVIDER}' pour le ResearchPlannerAgent.\")\n",
    "\n",
    "try:\n",
    "    # create_research_planner_agent() appelle get_llm() qui utilise \n",
    "    # settings.DEFAULT_LLM_MODEL_PROVIDER et gère la configuration.\n",
    "    # Une ValueError sera levée par get_llm si la configuration est incorrecte pour le provider choisi.\n",
    "    planner_agent_executor = create_research_planner_agent() \n",
    "    \n",
    "    # Requête utilisateur d'exemple (inchangée)\n",
    "    user_query_plan = \"What are the latest trends and key challenges in applying deep reinforcement learning to multi-robot navigation and coordination, particularly for swarm robotics?\"\n",
    "    logger.info(f\"Requête pour le planificateur : '{user_query_plan}'\")\n",
    "    \n",
    "    # Invocation de l'agent\n",
    "    response_planner = planner_agent_executor.invoke({\n",
    "        \"messages\": [HumanMessage(content=user_query_plan)]\n",
    "    })\n",
    "    research_plan = response_planner.get(\"output\")\n",
    "    \n",
    "    print(\"\\n--- Plan de Recherche Généré ---\")\n",
    "    if research_plan:\n",
    "        print(research_plan)\n",
    "    else:\n",
    "        print(\"L'agent planificateur n'a pas retourné de plan (vérifiez les logs).\")\n",
    "        # Afficher la réponse complète peut aider au débogage si 'output' est vide mais la réponse existe\n",
    "        print(f\"Réponse complète de l'agent (si output est vide) : {response_planner}\")\n",
    "            \n",
    "except ValueError as ve:\n",
    "    # Attrape spécifiquement les erreurs de configuration de get_llm()\n",
    "    logger.error(f\"Erreur de configuration LLM pour le ResearchPlannerAgent (provider: {settings.DEFAULT_LLM_MODEL_PROVIDER}): {ve}\", exc_info=True)\n",
    "    print(f\"ERREUR de configuration pour ResearchPlannerAgent : Le provider LLM '{settings.DEFAULT_LLM_MODEL_PROVIDER}' n'est pas correctement configuré (ex: clé API ou URL manquante). Détails : {ve}\")\n",
    "except Exception as e:\n",
    "    # Attrape les autres erreurs pendant l'invocation de l'agent\n",
    "    logger.error(f\"Erreur lors de l'invocation du ResearchPlannerAgent: {e}\", exc_info=True)\n",
    "    print(f\"Erreur inattendue lors du test du ResearchPlannerAgent: {e}\")\n",
    "\n",
    "# L'ancien bloc 'else' qui vérifiait settings.OPENAI_API_KEY est supprimé,\n",
    "# car la logique try/except ci-dessus est plus générale et correcte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2. Test du `ArxivSearchAgent` (avec `arxiv_search_tool`)\n",
    "\n",
    "\n",
    "\n",
    " Cet agent est spécialisé dans la recherche d'articles sur ArXiv. Il utilise `arxiv_search_tool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-04 00:01:42 - nb_03_agent_testing - INFO - \n",
      "--- Test du ArxivSearchAgent ---\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:42 - nb_03_agent_testing - INFO - Tentative d'utilisation du provider LLM configuré par défaut: 'ollama' pour l'ArxivSearchAgent.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:42 - src.llm_services.llm_factory - INFO - Initializing LLM for provider: 'ollama' (temperature: 0.0)\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:42 - src.llm_services.llm_factory - INFO - Using Ollama model: mistral from http://localhost:11434\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:42 - src.agents.agent_architectures - INFO - ArXiv Search Agent created with tools: ['arxiv_search_tool']\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:42 - nb_03_agent_testing - INFO - Tâche pour l'agent de recherche ArXiv : 'Find 2 recent papers (last 6 months) on 'explainable reinforcement learning in robotics' sorted by submission date.'\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:43 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\n",
      "--- Résultats de la Recherche ArXiv (via Agent) ---\n",
      "Impossible de parser la sortie comme JSON. Sortie brute :\n",
      "1. Title: \"Explainable Reinforcement Learning for Robot Manipulation with Visual Attention\"\n",
      "   Authors: [Jonathan Tremblay, David Held, Sergey Levine]\n",
      "   Summary: This paper proposes a method to explain the decisions made by an agent in reinforcement learning (RL) tasks. The approach uses visual attention mechanisms to highlight important regions of the environment that influence the agent's actions.\n",
      "   PDF URL: https://arxiv.org/pdf/2103.04867.pdf\n",
      "   Published Date: March 15, 2021\n",
      "\n",
      "2. Title: \"Explainable Reinforcement Learning for Robotics: A Survey\"\n",
      "   Authors: [Mohammadreza Mousavizadeh, Mohammad Hossein Mousavi, Ali Alipour]\n",
      "   Summary: This survey paper provides an overview of explainable reinforcement learning (XRL) in robotics. It discusses various XRL methods and their applications, as well as the challenges and future directions for research in this field.\n",
      "   PDF URL: https://arxiv.org/pdf/2103.04867.pdf\n",
      "   Published Date: March 15, 2021\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"\\n--- Test du ArxivSearchAgent ---\")\n",
    "logger.info(f\"Tentative d'utilisation du provider LLM configuré par défaut: '{settings.DEFAULT_LLM_MODEL_PROVIDER}' pour l'ArxivSearchAgent.\")\n",
    "\n",
    "try:\n",
    "    # create_arxiv_search_agent() appelle get_llm() qui utilise settings.DEFAULT_LLM_MODEL_PROVIDER\n",
    "    arxiv_agent_executor = create_arxiv_search_agent()\n",
    "    \n",
    "    search_task = \"Find 2 recent papers (last 6 months) on 'explainable reinforcement learning in robotics' sorted by submission date.\"\n",
    "    logger.info(f\"Tâche pour l'agent de recherche ArXiv : '{search_task}'\")\n",
    "    \n",
    "    response_arxiv_search = arxiv_agent_executor.invoke({\n",
    "        \"messages\": [HumanMessage(content=search_task)]\n",
    "    })\n",
    "    \n",
    "    arxiv_results_output = response_arxiv_search.get(\"output\")\n",
    "    \n",
    "    print(\"\\n--- Résultats de la Recherche ArXiv (via Agent) ---\")\n",
    "    if arxiv_results_output:\n",
    "        # La sortie de arxiv_search_tool est une liste de dictionnaires (ou un dict d'erreur)\n",
    "        # Essayons de l'afficher de manière lisible\n",
    "        try:\n",
    "            # Si la sortie est une chaîne JSON, la parser. Sinon, l'afficher telle quelle.\n",
    "            # L'outil retourne une liste de dicts, mais l'agent LLM pourrait la wrapper en chaîne.\n",
    "            if isinstance(arxiv_results_output, str):\n",
    "                try:\n",
    "                    # Remplacer les apostrophes simples par des guillemets doubles pour une meilleure compatibilité JSON\n",
    "                    # Attention: ceci est une heuristique et pourrait ne pas marcher pour tous les cas.\n",
    "                    # Une meilleure solution serait que l'agent retourne directement un objet JSON valide ou un type de données structuré.\n",
    "                    corrected_json_string = arxiv_results_output.replace(\"'\", \"\\\"\") \n",
    "                    # Gérer les booléens Python True/False qui ne sont pas valides en JSON (true/false)\n",
    "                    corrected_json_string = corrected_json_string.replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "                    # Gérer None qui n'est pas valide en JSON (null)\n",
    "                    corrected_json_string = corrected_json_string.replace(\"None\", \"null\")\n",
    "\n",
    "                    parsed_output = json.loads(corrected_json_string)\n",
    "                    print(json.dumps(parsed_output, indent=2, ensure_ascii=False))\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Impossible de parser la sortie comme JSON. Sortie brute :\\n{arxiv_results_output}\")\n",
    "            elif isinstance(arxiv_results_output, list) or isinstance(arxiv_results_output, dict): # Si c'est déjà un objet Python\n",
    "                print(json.dumps(arxiv_results_output, indent=2, ensure_ascii=False))\n",
    "            else: # Autre type, afficher directement\n",
    "                 print(arxiv_results_output)\n",
    "        except Exception as e_print:\n",
    "            print(f\"Erreur lors de l'affichage formaté des résultats : {e_print}\")\n",
    "            print(\"Sortie brute de l'agent :\")\n",
    "            print(arxiv_results_output)\n",
    "    else:\n",
    "        print(\"L'agent de recherche ArXiv n'a pas retourné de sortie (vérifiez les logs).\")\n",
    "        print(f\"Réponse complète de l'agent (si output est vide) : {response_arxiv_search}\")\n",
    "\n",
    "    # Affichage des étapes intermédiaires (si disponibles et utiles)\n",
    "    if \"intermediate_steps\" in response_arxiv_search and response_arxiv_search[\"intermediate_steps\"]:\n",
    "        print(\"\\nÉtapes intermédiaires de l'agent ArXiv:\")\n",
    "        for step in response_arxiv_search[\"intermediate_steps\"]:\n",
    "            # La structure de 'step' peut varier selon le type d'agent (AgentAction vs ToolCall)\n",
    "            if hasattr(step[0], 'tool') and hasattr(step[0], 'tool_input'): # Pour AgentAction\n",
    "                tool_call_info = f\"Outil: {step[0].tool}, Input: {step[0].tool_input}\"\n",
    "            elif isinstance(step[0], dict) and 'tool' in step[0] and 'tool_input' in step[0]: # Autre format possible\n",
    "                tool_call_info = f\"Outil: {step[0]['tool']}, Input: {step[0]['tool_input']}\"\n",
    "            else: # Fallback\n",
    "                tool_call_info = str(step[0])\n",
    "\n",
    "            tool_result = step[1]\n",
    "            print(f\"  Appel Outil: {tool_call_info}\")\n",
    "            print(f\"  Résultat Outil (extrait): {str(tool_result)[:300]}...\")\n",
    "            \n",
    "except ValueError as ve:\n",
    "    logger.error(f\"Erreur de configuration LLM pour l'ArxivSearchAgent (provider: {settings.DEFAULT_LLM_MODEL_PROVIDER}): {ve}\", exc_info=True)\n",
    "    print(f\"ERREUR de configuration pour ArxivSearchAgent : Le provider LLM '{settings.DEFAULT_LLM_MODEL_PROVIDER}' n'est pas correctement configuré. Détails : {ve}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erreur lors de l'invocation de l'ArxivSearchAgent: {e}\", exc_info=True)\n",
    "    print(f\"Erreur inattendue lors du test de l'ArxivSearchAgent: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2b. Test Direct de `arxiv_search_tool` (Optionnel)\n",
    "\n",
    "\n",
    "\n",
    " Pour mieux comprendre ce que l'outil `arxiv_search_tool` retourne, nous pouvons l'appeler directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-04 00:01:47 - nb_03_agent_testing - INFO - \n",
      "--- Test Direct de arxiv_search_tool ---\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:47 - src.agents.tool_definitions - INFO - Executing arxiv_search_tool: query='transformer models for robot control', max_results=1\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:47 - arxiv - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=transformer+models+for+robot+control&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:54 - arxiv - INFO - Got first page: 100 of 2388784 total results\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:54 - src.agents.tool_definitions - INFO - Found 1 papers\u001b[0m\n",
      "\n",
      "Résultats Directs de arxiv_search_tool:\n",
      "[\n",
      "  {\n",
      "    \"entry_id\": \"http://arxiv.org/abs/2505.24878v1\",\n",
      "    \"title\": \"Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents\",\n",
      "    \"authors\": [\n",
      "      \"Yaxin Luo\",\n",
      "      \"Zhaoyi Li\",\n",
      "      \"Jiacheng Liu\",\n",
      "      \"Jiacheng Cui\",\n",
      "      \"Xiaohan Zhao\",\n",
      "      \"Zhiqiang Shen\"\n",
      "    ],\n",
      "    \"summary\": \"CAPTCHAs have been a critical bottleneck for deploying web agents in real-world applications, often blocking them from completing end-to-end automation tasks. While modern multimodal LLM agents have demonstrated impressive performance in static perception tasks, their ability to handle interactive, multi-step reasoning challenges like CAPTCHAs is largely untested. To address this gap, we introduce Open CaptchaWorld, the first web-based benchmark and platform specifically designed to evaluate the visual reasoning and interaction capabilities of MLLM-powered agents through diverse and dynamic CAPTCHA puzzles. Our benchmark spans 20 modern CAPTCHA types, totaling 225 CAPTCHAs, annotated with a new metric we propose: CAPTCHA Reasoning Depth, which quantifies the number of cognitive and motor steps required to solve each puzzle. Experimental results show that humans consistently achieve near-perfect scores, state-of-the-art MLLM agents struggle significantly, with success rates at most 40.0% by Browser-Use Openai-o3, far below human-level performance, 93.3%. This highlights Open CaptchaWorld as a vital benchmark for diagnosing the limits of current multimodal agents and guiding the development of more robust multimodal reasoning systems. Code and Data are available at this https URL.\",\n",
      "    \"published_date\": \"2025-05-30T17:59:55+00:00\",\n",
      "    \"pdf_url\": \"http://arxiv.org/pdf/2505.24878v1\",\n",
      "    \"primary_category\": \"cs.AI\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"\\n--- Test Direct de arxiv_search_tool ---\")\n",
    "try:\n",
    "    direct_tool_results = arxiv_search_tool.invoke({\n",
    "        \"query\": \"transformer models for robot control\", \n",
    "        \"max_results\": 1,\n",
    "        \"sort_by\": \"submittedDate\"\n",
    "    })\n",
    "    print(\"\\nRésultats Directs de arxiv_search_tool:\")\n",
    "    # Ajout de ensure_ascii=False pour un meilleur affichage des caractères spéciaux\n",
    "    print(json.dumps(direct_tool_results, indent=2, ensure_ascii=False))\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erreur lors de l'appel direct à arxiv_search_tool: {e}\", exc_info=True)\n",
    "    print(f\"Erreur lors de l'appel direct à arxiv_search_tool: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3. Test du `DocumentAnalysisAgent` (avec `knowledge_base_retrieval_tool`)\n",
    "\n",
    "\n",
    "\n",
    " Cet agent analyse les documents récupérés de notre base de connaissances (MongoDB). Son bon fonctionnement dépend de la présence de données pertinentes dans la collection (par exemple, la collection de test MongoDB comme 'arxiv_chunks_notebook_test' ou 'arxiv_chunks_notebook_test_<provider>', peuplée via le notebook 01) et de la fonctionnalité du `RetrievalEngine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-04 00:01:54 - nb_03_agent_testing - INFO - \n",
      "--- Test du DocumentAnalysisAgent ---\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:54 - nb_03_agent_testing - INFO - Tentative d'utilisation du provider LLM configuré par défaut: 'ollama' pour le DocumentAnalysisAgent.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:54 - nb_03_agent_testing - INFO - Ce test dépend aussi du provider d'embedding configuré: 'ollama' (pour knowledge_base_retrieval_tool via RetrievalEngine) et de MongoDB.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:54 - src.llm_services.llm_factory - INFO - Initializing LLM for provider: 'ollama' (temperature: 0.0)\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:54 - src.llm_services.llm_factory - INFO - Using Ollama model: mistral from http://localhost:11434\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:54 - src.agents.agent_architectures - INFO - Document Analysis Agent created with tools: ['knowledge_base_retrieval_tool', 'document_deep_dive_analysis_tool']\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:54 - nb_03_agent_testing - INFO - Tâche pour l'agent d'analyse de documents : 'Based on the knowledge base, what are some common techniques for achieving explainability in RL agents used in robotics? Cite any relevant ArXiv IDs if found.'\u001b[0m\n",
      "\u001b[34m2025-06-04 00:01:55 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\n",
      "--- Résultats de l'Analyse de Documents (via Agent) ---\n",
      " To answer your question, I will use the `knowledge_base_retrieval_tool` to find relevant information about explainable reinforcement learning (RL) techniques in robotics.\n",
      "\n",
      "Here are some common techniques for achieving explainability in RL agents used in robotics:\n",
      "\n",
      "1. Interpretable Models: Using models that are inherently interpretable, such as decision trees or rule-based systems, can help provide insights into the agent's decision-making process (e.g., '1602.08403', '1707.06887').\n",
      "\n",
      "2. Visual Explanations: Generating visualizations of the environment or the agent's actions to help explain its decisions, such as heatmaps or saliency maps (e.g., '1805.09439', '1906.06476').\n",
      "\n",
      "3. Counterfactual Explanations: Providing explanations for why a specific action was taken and how the outcome would have been different if another action had been chosen (e.g., '1802.05383', '1906.04762').\n",
      "\n",
      "4. Model-Based Methods: Using model-based RL methods that explicitly learn a model of the environment, which can be analyzed to understand the agent's behavior (e.g., '1606.02438', '1905.07755').\n",
      "\n",
      "5. Post-hoc Analysis: Analyzing the learned policy or value function after training to gain insights into the agent's decision-making process (e.g., '1802.06755', '1903.04074').\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"\\n--- Test du DocumentAnalysisAgent ---\")\n",
    "logger.info(f\"Tentative d'utilisation du provider LLM configuré par défaut: '{settings.DEFAULT_LLM_MODEL_PROVIDER}' pour le DocumentAnalysisAgent.\")\n",
    "logger.info(f\"Ce test dépend aussi du provider d'embedding configuré: '{settings.DEFAULT_EMBEDDING_PROVIDER}' (pour knowledge_base_retrieval_tool via RetrievalEngine) et de MongoDB.\")\n",
    "\n",
    "# La connexion à MongoDB est essentielle pour les outils de cet agent.\n",
    "if not settings.MONGODB_URI:\n",
    "    logger.error(\"MONGODB_URI non configuré. Test du DocumentAnalysisAgent sauté car ses outils (knowledge_base_retrieval_tool) en dépendent crucialement.\")\n",
    "    print(\"ERREUR: MONGODB_URI non configuré dans .env. Le DocumentAnalysisAgent ne peut pas être testé correctement sans accès à la base de données.\")\n",
    "else:\n",
    "    try:\n",
    "        # La création de l'agent peut échouer si get_llm() (appelé en interne) échoue \n",
    "        # en raison d'une configuration manquante pour le DEFAULT_LLM_MODEL_PROVIDER.\n",
    "        # De même, RetrievalEngine (utilisé par knowledge_base_retrieval_tool) peut échouer à l'init\n",
    "        # si DEFAULT_EMBEDDING_PROVIDER est mal configuré.\n",
    "        doc_analysis_agent_executor = create_document_analysis_agent()\n",
    "        \n",
    "        # Tâche d'analyse exemple.\n",
    "        # Le DocumentAnalysisAgent est maintenant équipé du document_deep_dive_analysis_tool.\n",
    "        # Son prompt système (DOCUMENT_ANALYSIS_SYSTEM_PROMPT_V2) le guide sur quand utiliser quel outil.\n",
    "        # Voici une tâche qui devrait utiliser knowledge_base_retrieval_tool :\n",
    "        analysis_task = \"Based on the knowledge base, what are some common techniques for achieving explainability in RL agents used in robotics? Cite any relevant ArXiv IDs if found.\"\n",
    "        \n",
    "        # Pour tester le document_deep_dive_analysis_tool, la tâche devrait être formulée différemment,\n",
    "        # par exemple, en demandant explicitement une \"deep dive\" sur un document spécifique.\n",
    "        # Exemple :\n",
    "        # analysis_task = \"Perform a detailed, structured deep dive analysis on document 'XXXX.YYYYY' (you will need to fetch its content first if not provided) focusing on its methodology and limitations for sim-to-real transfer.\"\n",
    "        # Pour un tel test, assurez-vous que le document 'XXXX.YYYYY' existe ou que l'agent peut le récupérer.\n",
    "        \n",
    "        logger.info(f\"Tâche pour l'agent d'analyse de documents : '{analysis_task}'\")\n",
    "        \n",
    "        response_doc_analysis = doc_analysis_agent_executor.invoke({\n",
    "            \"messages\": [HumanMessage(content=analysis_task)]\n",
    "        })\n",
    "        analysis_output = response_doc_analysis.get(\"output\")\n",
    "        \n",
    "        print(\"\\n--- Résultats de l'Analyse de Documents (via Agent) ---\")\n",
    "        if analysis_output:\n",
    "            # La sortie peut être une simple chaîne ou un rapport structuré (ex: de CrewAI via le deep_dive_tool)\n",
    "            if isinstance(analysis_output, str) and analysis_output.lower().startswith(\"error:\"):\n",
    "                print(f\"L'agent ou un outil a retourné une ERREUR gérée : {analysis_output}\")\n",
    "            else:\n",
    "                # Tenter d'afficher en Markdown si la sortie est un rapport formaté (souvent le cas pour CrewAI)\n",
    "                # ou en JSON si c'est une structure de données, sinon en texte brut.\n",
    "                if isinstance(analysis_output, str) and (\"\\n## \" in analysis_output or \"\\n### \" in analysis_output or \"```\" in analysis_output) : # Heuristique pour Markdown\n",
    "                    try:\n",
    "                        from IPython.display import display, Markdown\n",
    "                        print(\"Affichage de la sortie comme Markdown:\")\n",
    "                        display(Markdown(analysis_output))\n",
    "                    except ImportError:\n",
    "                        print(analysis_output) # Fallback\n",
    "                elif isinstance(analysis_output, str) and analysis_output.strip().startswith((\"{\", \"[\")): # Heuristique pour JSON\n",
    "                    try:\n",
    "                        parsed_json = json.loads(analysis_output)\n",
    "                        print(\"Sortie formatée comme JSON:\")\n",
    "                        print(json.dumps(parsed_json, indent=2, ensure_ascii=False))\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(analysis_output) # Fallback\n",
    "                else: # Si c'est déjà un dict/list ou une chaîne simple\n",
    "                    if isinstance(analysis_output, (dict, list)):\n",
    "                        print(json.dumps(analysis_output, indent=2, ensure_ascii=False))\n",
    "                    else:\n",
    "                        print(analysis_output)\n",
    "        else:\n",
    "            print(\"L'agent d'analyse de documents n'a pas retourné de sortie ('output' est vide/None).\")\n",
    "            print(f\"Réponse complète de l'agent (pour débogage) : {response_doc_analysis}\")\n",
    "\n",
    "        # Affichage des étapes intermédiaires\n",
    "        if \"intermediate_steps\" in response_doc_analysis and response_doc_analysis[\"intermediate_steps\"]:\n",
    "            print(\"\\nÉtapes intermédiaires de l'agent d'Analyse:\")\n",
    "            for step in response_doc_analysis[\"intermediate_steps\"]:\n",
    "                tool_call_info = \"N/A\"\n",
    "                # La structure de step[0] (l'action) peut varier.\n",
    "                action_part = step[0]\n",
    "                if hasattr(action_part, 'tool') and hasattr(action_part, 'tool_input'): # AgentAction\n",
    "                    tool_call_info = f\"Outil: {action_part.tool}, Input: {action_part.tool_input}\"\n",
    "                elif isinstance(action_part, list) and action_part and isinstance(action_part[0], dict) and 'tool_name' in action_part[0]: # Possible format pour tool_calls multiples\n",
    "                     tool_call_info = f\"Outil(s): {', '.join([tc.get('tool_name', 'unknown') for tc in action_part])}\"\n",
    "                elif isinstance(action_part, dict) and 'tool' in action_part and 'tool_input' in action_part: # Autre format possible\n",
    "                     tool_call_info = f\"Outil: {action_part['tool']}, Input: {action_part['tool_input']}\"\n",
    "                else: # Fallback\n",
    "                    tool_call_info = str(action_part)\n",
    "\n",
    "                tool_result = step[1] # Observation\n",
    "                print(f\"  Appel Outil/Action: {tool_call_info}\")\n",
    "                print(f\"  Résultat Outil (extrait): {str(tool_result)[:300]}...\")\n",
    "                \n",
    "    except ValueError as ve:\n",
    "        logger.error(f\"Erreur de configuration ou de valeur lors de la création/invocation du DocumentAnalysisAgent. Vérifiez les configurations pour le provider LLM '{settings.DEFAULT_LLM_MODEL_PROVIDER}' et le provider d'embedding '{settings.DEFAULT_EMBEDDING_PROVIDER}'. Détails: {ve}\", exc_info=True)\n",
    "        print(f\"ERREUR (DocumentAnalysisAgent): Problème de configuration LLM ou Embedding. Provider LLM: '{settings.DEFAULT_LLM_MODEL_PROVIDER}', Provider Embedding: '{settings.DEFAULT_EMBEDDING_PROVIDER}'. Détails: {ve}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'invocation du DocumentAnalysisAgent: {e}\", exc_info=True)\n",
    "        print(f\"Erreur inattendue lors du test du DocumentAnalysisAgent: {e}. Assurez-vous que RetrievalEngine peut s'initialiser, que MongoDB est accessible et peuplé, et que les configurations LLM/Embedding sont correctes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 4. Test du `SynthesisAgent`\n",
    "\n",
    "\n",
    "\n",
    " Cet agent prend des informations analysées (que nous allons simuler ici) et produit une synthèse structurée. Il n'utilise pas d'outils de récupération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-04 00:02:02 - nb_03_agent_testing - INFO - \n",
      "--- Test du SynthesisAgent ---\u001b[0m\n",
      "\u001b[34m2025-06-04 00:02:02 - nb_03_agent_testing - INFO - Tentative d'utilisation du provider LLM configuré par défaut: 'ollama' pour le SynthesisAgent.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:02:02 - src.llm_services.llm_factory - INFO - Initializing LLM for provider: 'ollama' (temperature: 0.5)\u001b[0m\n",
      "\u001b[34m2025-06-04 00:02:02 - src.llm_services.llm_factory - INFO - Using Ollama model: mistral from http://localhost:11434\u001b[0m\n",
      "\u001b[34m2025-06-04 00:02:02 - src.agents.agent_architectures - INFO - Synthesis Agent created successfully\u001b[0m\n",
      "\u001b[34m2025-06-04 00:02:02 - nb_03_agent_testing - INFO - Tâche pour l'agent de synthèse (basée sur un contexte simulé).\u001b[0m\n",
      "\u001b[34m2025-06-04 00:02:02 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\n",
      "--- Sortie de Synthèse (via Agent) ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       " Title: Key Considerations for Sim-to-Real Transfer in Robotic Reinforcement Learning\n",
       "\n",
       "   Summary:\n",
       "\n",
       "   In the context of sim-to-real transfer in robotic reinforcement learning, several key considerations have been identified through analysis of relevant research findings and documents.\n",
       "\n",
       "   1. Domain Randomization Issues: Sim-to-real transfer often encounters challenges related to domain randomization. Techniques such as domain adaptation and system identification are critical in addressing these issues (ArXiv ID 123.4567).\n",
       "\n",
       "   2. Accurate Modeling of Physical Parameters: Modeling physical parameters like friction and sensor noise accurately is a significant hurdle due to their complexity and variability in real-world scenarios (ArXiv ID 123.4567).\n",
       "\n",
       "   3. Utilization of Realistic Simulators and Noise Addition during Training: Employing realistic simulators and adding noise during the training phase can enhance the transfer performance, particularly for vision-based policies, as photorealistic rendering aids in this regard (ArXiv ID 789.0123).\n",
       "\n",
       "   4. Policy Distillation: Distilling policies from an ensemble of simulation-trained agents has shown promise in improving sim-to-real transfer (ArXiv ID 789.0123).\n",
       "\n",
       "   5. Review of State-of-the-Art Methods: A comprehensive review of the latest methods in sim-to-real transfer for robotics highlights the importance of robust learning algorithms and accurate dynamics modeling (ArXiv:2401.0001).\n",
       "\n",
       "   Contradictions/Gaps: No contradictions or gaps were found within the provided information. However, it is essential to note that the effectiveness of these considerations may vary depending on the specific application and robot design in question."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.info(\"\\n--- Test du SynthesisAgent ---\")\n",
    "# create_synthesis_agent() dans agent_architectures.py appelle get_llm() \n",
    "# avec SYNTHESIS_LLM_TEMPERATURE depuis llm_factory.py.\n",
    "# Il utilisera le settings.DEFAULT_LLM_MODEL_PROVIDER.\n",
    "logger.info(f\"Tentative d'utilisation du provider LLM configuré par défaut: '{settings.DEFAULT_LLM_MODEL_PROVIDER}' pour le SynthesisAgent.\")\n",
    "\n",
    "try:\n",
    "    # La création de l'agent peut échouer si get_llm() (appelé en interne) échoue \n",
    "    # en raison d'une configuration manquante pour le DEFAULT_LLM_MODEL_PROVIDER.\n",
    "    synthesis_agent_executor = create_synthesis_agent()\n",
    "    \n",
    "    # Préparer un contexte simulé (inchangé par rapport à la version originale de la cellule)\n",
    "    simulated_context_for_synthesis = \"\"\"\n",
    "    User Query: What are key considerations for sim-to-real transfer in robotic reinforcement learning?\n",
    "\n",
    "    Information from Document Analysis:\n",
    "    - Chunk from ArXiv ID 123.4567: Sim-to-real transfer often suffers from domain randomization issues. Techniques like domain adaptation and system identification are crucial. Physical parameters like friction and sensor noise are hard to model accurately.\n",
    "    - Chunk from ArXiv ID 789.0123: Using realistic simulators and adding noise during training can improve transfer. Photorealistic rendering helps vision-based policies. Policy distillation from an ensemble of simulation-trained agents is a promising approach.\n",
    "    - ArXiv Search found paper 'Recent Advances in Sim-to-Real for Robotics' (ArXiv:2401.0001), summary: This paper reviews state-of-the-art methods, highlighting the importance of robust learning algorithms and accurate dynamics modeling.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Le message pour l'agent de synthèse inclut maintenant le contexte directement.\n",
    "    # Le prompt de l'agent de synthèse (SYNTHESIS_AGENT_SYSTEM_PROMPT) lui indique de travailler\n",
    "    # avec les informations fournies dans les messages.\n",
    "    synthesis_task_message = HumanMessage(\n",
    "        content=f\"Based on the provided information below, write a concise summary report on the key considerations for sim-to-real transfer in robotic reinforcement learning. The report should be well-structured and directly address the initial user query mentioned in the context.\\n\\nProvided Information:\\n{simulated_context_for_synthesis}\"\n",
    "    )\n",
    "    logger.info(\"Tâche pour l'agent de synthèse (basée sur un contexte simulé).\")\n",
    "\n",
    "    response_synthesis = synthesis_agent_executor.invoke({\n",
    "        \"messages\": [synthesis_task_message] # L'historique des messages peut aussi être passé si pertinent\n",
    "    })\n",
    "    synthesized_output = response_synthesis.get(\"output\")\n",
    "    \n",
    "    print(\"\\n--- Sortie de Synthèse (via Agent) ---\")\n",
    "    if synthesized_output:\n",
    "        # Le SynthesisAgent est censé produire du texte formaté (potentiellement Markdown).\n",
    "        if isinstance(synthesized_output, str) and (synthesized_output.lower().startswith(\"error:\") or \"erreur\" in synthesized_output.lower()):\n",
    "             print(f\"L'agent de synthèse semble avoir rencontré une difficulté : {synthesized_output}\")\n",
    "        else:\n",
    "            try:\n",
    "                from IPython.display import display, Markdown\n",
    "                display(Markdown(str(synthesized_output)))\n",
    "            except ImportError:\n",
    "                print(str(synthesized_output))\n",
    "    else:\n",
    "        print(\"L'agent de synthèse n'a pas retourné de sortie ('output' est vide/None).\")\n",
    "        print(f\"Réponse complète de l'agent (pour débogage) : {response_synthesis}\")\n",
    "            \n",
    "except ValueError as ve:\n",
    "    logger.error(f\"Erreur de configuration LLM pour le SynthesisAgent (provider: {settings.DEFAULT_LLM_MODEL_PROVIDER}): {ve}\", exc_info=True)\n",
    "    print(f\"ERREUR de configuration pour SynthesisAgent : Le provider LLM '{settings.DEFAULT_LLM_MODEL_PROVIDER}' n'est pas correctement configuré. Détails : {ve}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erreur lors de l'invocation du SynthesisAgent: {e}\", exc_info=True)\n",
    "    print(f\"Erreur inattendue lors du test du SynthesisAgent: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Conclusion des Tests d'Agents Individuels\n",
    "\n",
    "\n",
    "\n",
    " Ce notebook a permis de tester chaque agent de manière isolée pour vérifier son comportement de base et son interaction avec les outils.\n",
    "\n",
    " Ces tests unitaires sont importants avant d'orchestrer ces agents dans un workflow LangGraph plus complexe (ce que nous ferons dans le notebook suivant)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
