{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee6638b",
   "metadata": {},
   "source": [
    "# Notebook 02: Exploration des Stratégies RAG\n",
    "\n",
    "Ce notebook se concentre sur l'exploration des capacités de notre `RetrievalEngine` pour récupérer des informations pertinentes à partir de la base de connaissances MongoDB que nous avons peuplée. Nous allons tester la recherche vectorielle simple et la recherche avec filtres de métadonnées.\n",
    "\n",
    "**Prérequis :**\n",
    "* Avoir exécuté le notebook `00_setup_environment.ipynb` pour configurer l'environnement et les variables d'environnement (fichier `.env`).\n",
    "* Avoir exécuté le notebook `01_data_ingestion_and_embedding.ipynb` (ou le script `scripts/run_ingestion.py`) pour peupler MongoDB. La collection de chunks (par exemple, `arxiv_chunks_notebook_test` ou celle par défaut utilisée lors de l'ingestion) doit contenir des embeddings générés par le fournisseur configuré via `DEFAULT_EMBEDDING_PROVIDER` dans vos paramètres (par exemple, Hugging Face, Ollama, ou OpenAI).\n",
    "* **Configuration pour l'Embedding des Requêtes :** Ce notebook utilise `RetrievalEngine`, qui vectorise les requêtes de recherche en utilisant le fournisseur d'embedding défini par la variable `DEFAULT_EMBEDDING_PROVIDER` dans vos configurations (`.env` ou `config/settings.py`).\n",
    "    * Si `DEFAULT_EMBEDDING_PROVIDER` est `\"openai\"` : assurez-vous que `OPENAI_API_KEY` est configurée dans votre fichier `.env`.\n",
    "    * Si `DEFAULT_EMBEDDING_PROVIDER` est `\"huggingface\"` (utilisant des modèles Sentence Transformers locaux) : aucune clé API spécifique n'est généralement requise pour l'embedding des requêtes.\n",
    "    * Si `DEFAULT_EMBEDDING_PROVIDER` est `\"ollama\"` : assurez-vous que `OLLAMA_BASE_URL` est correctement configuré dans `.env` et que le modèle d'embedding spécifié (par exemple, `OLLAMA_EMBEDDING_MODEL_NAME`) est disponible et servi par votre instance Ollama.\n",
    "* Votre instance MongoDB doit être accessible via le `MONGODB_URI` configuré dans votre fichier `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a6ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables d'environnement chargées depuis : .env\n",
      "\u001b[34m2025-06-03 10:03:15 - nb_02_rag_exploration - INFO - Ce notebook utilisera le fournisseur d'embedding configuré : 'ollama' pour RetrievalEngine.\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:15 - nb_02_rag_exploration - INFO - Ce notebook utilisera la collection MongoDB: 'arxiv_chunks_notebook_test'\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:15 - nb_02_rag_exploration - INFO - Index vectoriel supposé: 'vector_index_notebook_test'\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:15 - nb_02_rag_exploration - INFO - Index textuel supposé (pour hybride): 'text_index_notebook_test'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json # Pour afficher les métadonnées de manière lisible\n",
    "from typing import Optional, List # 'List' était déjà là, 'Optional' est bon à avoir.\n",
    "\n",
    "project_root = Path()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# De même, si CWD est la racine du projet, dotenv_path serait `Path().resolve() / \".env\"`\n",
    "dotenv_path = project_root / \".env\"\n",
    "if dotenv_path.exists():\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "    print(f\"Variables d'environnement chargées depuis : {dotenv_path}\")\n",
    "else:\n",
    "    print(f\"ATTENTION: Fichier .env non trouvé à {dotenv_path}. Assurez-vous qu'il est à la racine du projet.\")\n",
    "\n",
    "from config.settings import settings\n",
    "from config.logging_config import setup_logging\n",
    "from src.rag.retrieval_engine import RetrievalEngine, RetrievedNode\n",
    "from src.vector_store.mongodb_manager import MongoDBManager \n",
    "\n",
    "setup_logging(level=\"INFO\") \n",
    "logger = logging.getLogger(\"nb_02_rag_exploration\")\n",
    "\n",
    "# --- Vérification des prérequis pour l'embedding (logique existante conservée) ---\n",
    "active_embedding_provider = settings.DEFAULT_EMBEDDING_PROVIDER.lower()\n",
    "logger.info(f\"Ce notebook utilisera le fournisseur d'embedding configuré : '{active_embedding_provider}' pour RetrievalEngine.\")\n",
    "\n",
    "if active_embedding_provider == \"openai\":\n",
    "    if not settings.OPENAI_API_KEY:\n",
    "        logger.error(\"ERREUR : Le fournisseur d'embedding est 'openai', mais OPENAI_API_KEY n'est pas configurée. RetrievalEngine (pour l'embedding des requêtes) échouera.\")\n",
    "elif active_embedding_provider == \"ollama\":\n",
    "    if not settings.OLLAMA_BASE_URL:\n",
    "        logger.error(\"ERREUR : Le fournisseur d'embedding est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée. RetrievalEngine échouera.\")\n",
    "    if not settings.OLLAMA_EMBEDDING_MODEL_NAME: # Vérification déjà présente\n",
    "         logger.error(\"ERREUR : Le fournisseur d'embedding est 'ollama', mais OLLAMA_EMBEDDING_MODEL_NAME n'est pas configuré.\")\n",
    "# Pour \"huggingface\", aucune clé API n'est généralement requise pour les modèles SentenceTransformers locaux.\n",
    "\n",
    "if not settings.MONGODB_URI:\n",
    "    logger.error(\"ERREUR : MONGODB_URI non trouvé. Le RetrievalEngine ne pourra pas se connecter à la base de données.\")\n",
    "\n",
    "# --- Configuration des noms de Collection et d'Index MongoDB ---\n",
    "# MODIFIÉ : Pour utiliser explicitement les noms de la collection de test du notebook 01\n",
    "# si l'objectif est de tester sur ces données spécifiques.\n",
    "# Sinon, pour tester sur la collection principale, utilisez MongoDBManager.DEFAULT_CHUNK_COLLECTION_NAME, etc.\n",
    "# Le notebook 01 définit localement :\n",
    "# COLLECTION_NAME_NOTEBOOK = \"arxiv_chunks_notebook_test\"\n",
    "# VECTOR_INDEX_NAME_NOTEBOOK = \"vector_index_notebook_test\"\n",
    "# TEXT_INDEX_NAME_NOTEBOOK = \"text_index_notebook_test\"\n",
    "\n",
    "COLLECTION_NAME_FOR_RAG_TEST = \"arxiv_chunks_notebook_test\"\n",
    "VECTOR_INDEX_NAME_FOR_RAG_TEST = \"vector_index_notebook_test\"\n",
    "TEXT_INDEX_NAME_FOR_RAG_TEST = \"text_index_notebook_test\" \n",
    "\n",
    "# Alternative, si vous voulez toujours un fallback vers les valeurs par défaut principales\n",
    "# et que vous définissiez `settings.COLLECTION_NAME_NOTEBOOK_TEST` dans `config/settings.py`:\n",
    "# COLLECTION_NAME_FOR_RAG_TEST = getattr(settings, 'COLLECTION_NAME_NOTEBOOK_TEST', MongoDBManager.DEFAULT_CHUNK_COLLECTION_NAME)\n",
    "# VECTOR_INDEX_NAME_FOR_RAG_TEST = getattr(settings, 'VECTOR_INDEX_NAME_NOTEBOOK_TEST', MongoDBManager.DEFAULT_VECTOR_INDEX_NAME)\n",
    "# TEXT_INDEX_NAME_FOR_RAG_TEST = getattr(settings, 'TEXT_INDEX_NAME_NOTEBOOK_TEST', MongoDBManager.DEFAULT_TEXT_INDEX_NAME)\n",
    "\n",
    "\n",
    "logger.info(f\"Ce notebook utilisera la collection MongoDB: '{COLLECTION_NAME_FOR_RAG_TEST}'\")\n",
    "logger.info(f\"Index vectoriel supposé: '{VECTOR_INDEX_NAME_FOR_RAG_TEST}'\")\n",
    "logger.info(f\"Index textuel supposé (pour hybride): '{TEXT_INDEX_NAME_FOR_RAG_TEST}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e2df5",
   "metadata": {},
   "source": [
    "### Initialisation du `RetrievalEngine`\n",
    "\n",
    "Nous allons d'abord créer une instance de notre `RetrievalEngine`. Il se connectera à MongoDB et chargera l'index vectoriel existant. Assurez-vous que la collection et l'index spécifiés existent et contiennent des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62be24a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-03 10:03:15 - src.rag.retrieval_engine - INFO - Configuring LlamaIndex global embed_model for provider: ollama\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:15 - src.rag.retrieval_engine - INFO - LlamaIndex embed_model configured for Ollama: model='nomic-embed-text', base_url='http://localhost:11434'\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:16 - src.rag.retrieval_engine - INFO - MongoDBAtlasVectorSearch store configured for collection 'arxiv_chunks_notebook_test'.\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:17 - src.rag.retrieval_engine - INFO - VectorStoreIndex loaded from MongoDB store.\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:17 - src.rag.retrieval_engine - INFO - Default retriever configured.\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:17 - src.rag.retrieval_engine - INFO - RetrievalEngine initialized with LlamaIndex components.\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:17 - nb_02_rag_exploration - INFO - RetrievalEngine initialisé avec succès.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "retrieval_engine_instance: Optional[RetrievalEngine] = None\n",
    "try:\n",
    "    retrieval_engine_instance = RetrievalEngine(\n",
    "        collection_name=COLLECTION_NAME_FOR_RAG_TEST,\n",
    "        vector_index_name=VECTOR_INDEX_NAME_FOR_RAG_TEST\n",
    "        # text_key et embedding_field sont pris par défaut par RetrievalEngine ou settings\n",
    "    )\n",
    "    logger.info(\"RetrievalEngine initialisé avec succès.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erreur lors de l'initialisation du RetrievalEngine: {e}\", exc_info=True)\n",
    "    print(f\"ERREUR: Impossible d'initialiser RetrievalEngine. Vérifiez les logs et la configuration (API Keys, MongoDB URI, nom de la collection/index).\")\n",
    "\n",
    "# Petite fonction pour afficher les résultats de manière lisible\n",
    "def print_retrieved_nodes(nodes: List[RetrievedNode], query: str):\n",
    "    print(f\"\\n--- Résultats de la recherche pour la requête : '{query}' ---\")\n",
    "    if not nodes:\n",
    "        print(\"Aucun document pertinent trouvé.\")\n",
    "        return\n",
    "    for i, node in enumerate(nodes):\n",
    "        print(f\"\\nRésultat # {i+1}:\")\n",
    "        print(f\"  Score        : {node.score:.4f}\" if node.score is not None else \"  Score        : N/A\")\n",
    "        print(f\"  Chunk ID     : {node.metadata.get('chunk_id', 'N/A')}\")\n",
    "        print(f\"  ArXiv ID     : {node.metadata.get('arxiv_id', 'N/A')}\")\n",
    "        print(f\"  Titre Doc    : {node.metadata.get('original_document_title', 'N/A')}\")\n",
    "        # Afficher d'autres métadonnées si elles sont intéressantes\n",
    "        # print(f\"  Autres Meta  : {json.dumps({k: v for k, v in node.metadata.items() if k not in ['chunk_id', 'arxiv_id', 'original_document_title']}, indent=2)}\")\n",
    "        print(f\"  Texte        : {node.text[:300].replace(chr(10), ' ')}...\") # Extrait du texte\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ccf1b",
   "metadata": {},
   "source": [
    "### Définition des Requêtes d'Exemple\n",
    "\n",
    "Définissons quelques requêtes pertinentes pour notre corpus (supposé être sur \"Reinforcement Learning for Robotics\" ou \"Explainable AI for Robotics\" si vous avez utilisé la query du notebook 01). Adaptez ces requêtes si votre corpus est différent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197b44f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-03 10:03:17 - nb_02_rag_exploration - INFO - Requête de test sélectionnée : 'What are the main challenges in applying reinforcement learning to robotic manipulation?'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sample_queries = [\n",
    "    \"What are the main challenges in applying reinforcement learning to robotic manipulation?\",\n",
    "    \"Explainable AI techniques for robot decision making.\",\n",
    "    \"How can sim-to-real transfer be improved for RL agents in robotics?\",\n",
    "    \"Common algorithms for path planning in multi-robot systems using RL.\"\n",
    "]\n",
    "# Choisir une requête pour les tests\n",
    "test_query = sample_queries[0] \n",
    "logger.info(f\"Requête de test sélectionnée : '{test_query}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168d0f1",
   "metadata": {},
   "source": [
    "### Stratégie 1: Recherche Vectorielle Simple\n",
    "\n",
    "Nous utilisons la méthode `retrieve_simple_vector_search` de notre `RetrievalEngine` pour effectuer une recherche basée sur la similarité sémantique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e200be72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-03 10:03:17 - nb_02_rag_exploration - INFO - \n",
      "Exécution de la recherche vectorielle simple pour : 'What are the main challenges in applying reinforcement learning to robotic manipulation?'\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:17 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:17 - src.rag.retrieval_engine - INFO - Retrieved 3 nodes for query: 'What are the main challenges in applying reinforce...' with top_k=3 and filters=None\u001b[0m\n",
      "\n",
      "--- Résultats de la recherche pour la requête : 'What are the main challenges in applying reinforcement learning to robotic manipulation?' ---\n",
      "\n",
      "Résultat # 1:\n",
      "  Score        : 0.7929\n",
      "  Chunk ID     : 2505.24878_chunk_015\n",
      "  ArXiv ID     : 2505.24878\n",
      "  Titre Doc    : Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents\n",
      "  Texte        : , Yi Dong, Jieyu Zhang, Jan Kautz, Bryan Catanzaro, Andrew Tao, Qingyun Wu, Zhiding Yu, and Guilin Liu. Nemotron-research-tool-n1: Tool-using language models with reinforced reasoning. arXiv preprint arXiv:2505.00024, 2025. [50] Xu Zhong, Jianbin Tang, and Antonio Jimeno-Yepes. PubLayNet: Largest da...\n",
      "\n",
      "Résultat # 2:\n",
      "  Score        : 0.7925\n",
      "  Chunk ID     : 2505.24878_chunk_013\n",
      "  ArXiv ID     : 2505.24878\n",
      "  Titre Doc    : Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents\n",
      "  Texte        : ] Magnus Müller and Gregor Žuniˇc. Browser use: Enable ai to control your browser, 2024. URL https://github.com/browser-use/browser-use. [25] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, et al. Webgpt: Browserassisted question-answering with human feedback. arXiv preprint arX...\n",
      "\n",
      "Résultat # 3:\n",
      "  Score        : 0.7877\n",
      "  Chunk ID     : 2505.24878_chunk_002\n",
      "  ArXiv ID     : 2505.24878\n",
      "  Titre Doc    : Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents\n",
      "  Texte        : CAPTCHAv2 [30]) treats them as static perception tasks solvable by CNNs or object detectors, ignoring the sequential planning and interface state dynamics. This leaves a crucial evaluation gap: no benchmark tests whether MLLM agents can handle CAPTCHAs in a closed-loop, interactive setting that mimi...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if retrieval_engine_instance:\n",
    "    logger.info(f\"\\nExécution de la recherche vectorielle simple pour : '{test_query}'\")\n",
    "    simple_search_results = retrieval_engine_instance.retrieve_simple_vector_search(\n",
    "        query_text=test_query,\n",
    "        top_k=3 \n",
    "    )\n",
    "    print_retrieved_nodes(simple_search_results, test_query)\n",
    "else:\n",
    "    logger.warning(\"RetrievalEngine non initialisé. Test de recherche vectorielle simple sauté.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77964080",
   "metadata": {},
   "source": [
    "### Stratégie 2: Recherche Vectorielle avec Filtres de Métadonnées\n",
    "\n",
    "LlamaIndex et MongoDB Atlas Vector Search permettent de filtrer les résultats en fonction des métadonnées associées aux chunks. Notre `RetrievalEngine` expose cette fonctionnalité.\n",
    "\n",
    "Supposons que nous voulons rechercher des informations sur notre `test_query`, mais uniquement dans des documents avec un `arxiv_id` spécifique ou une catégorie principale particulière.\n",
    "\n",
    "**Note:** Pour que ce test soit significatif, vous devez connaître des `arxiv_id` ou des catégories présentes dans votre base de données (celles de la collection `{COLLECTION_NAME_FOR_RAG_TEST}`). Vous pouvez les trouver en explorant les résultats de la recherche simple ci-dessus ou directement dans MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea35d2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-03 10:03:17 - nb_02_rag_exploration - INFO - Utilisation de l'arxiv_id '2505.24878' pour le test de filtre (provenant du premier résultat de la recherche précédente).\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:17 - nb_02_rag_exploration - INFO - \n",
      "Recherche vectorielle pour 'What are the main challenges in applying reinforcement learning to robotic manipulation?' AVEC filtre sur arxiv_id='2505.24878'\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:17 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:17 - src.rag.retrieval_engine - INFO - Retrieved 2 nodes for query: 'What are the main challenges in applying reinforce...' with top_k=2 and filters=[{'key': 'arxiv_id', 'value': '2505.24878'}]\u001b[0m\n",
      "\n",
      "--- Résultats de la recherche pour la requête : 'What are the main challenges in applying reinforcement learning to robotic manipulation? (filtré par arxiv_id: 2505.24878)' ---\n",
      "\n",
      "Résultat # 1:\n",
      "  Score        : 0.7929\n",
      "  Chunk ID     : 2505.24878_chunk_015\n",
      "  ArXiv ID     : 2505.24878\n",
      "  Titre Doc    : Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents\n",
      "  Texte        : , Yi Dong, Jieyu Zhang, Jan Kautz, Bryan Catanzaro, Andrew Tao, Qingyun Wu, Zhiding Yu, and Guilin Liu. Nemotron-research-tool-n1: Tool-using language models with reinforced reasoning. arXiv preprint arXiv:2505.00024, 2025. [50] Xu Zhong, Jianbin Tang, and Antonio Jimeno-Yepes. PubLayNet: Largest da...\n",
      "\n",
      "Résultat # 2:\n",
      "  Score        : 0.7925\n",
      "  Chunk ID     : 2505.24878_chunk_013\n",
      "  ArXiv ID     : 2505.24878\n",
      "  Titre Doc    : Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents\n",
      "  Texte        : ] Magnus Müller and Gregor Žuniˇc. Browser use: Enable ai to control your browser, 2024. URL https://github.com/browser-use/browser-use. [25] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, et al. Webgpt: Browserassisted question-answering with human feedback. arXiv preprint arX...\n",
      "--------------------------------------------------\n",
      "\u001b[34m2025-06-03 10:03:17 - nb_02_rag_exploration - INFO - \n",
      "Recherche vectorielle pour 'What are the main challenges in applying reinforcement learning to robotic manipulation?' AVEC filtre sur primary_category='cs.RO'\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:17 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-03 10:03:17 - src.rag.retrieval_engine - INFO - Retrieved 0 nodes for query: 'What are the main challenges in applying reinforce...' with top_k=2 and filters=[{'key': 'metadata.primary_category', 'value': 'cs.RO'}]\u001b[0m\n",
      "\n",
      "--- Résultats de la recherche pour la requête : 'What are the main challenges in applying reinforcement learning to robotic manipulation? (filtré par catégorie: cs.RO)' ---\n",
      "Aucun document pertinent trouvé.\n"
     ]
    }
   ],
   "source": [
    "if retrieval_engine_instance:\n",
    "    # Exemple 1: Filtrer par un arxiv_id spécifique\n",
    "    # Remplacez 'example_arxiv_id_123' par un ID ArXiv réel de votre base de données\n",
    "    # Vous pouvez obtenir un ID à partir des résultats de la recherche simple précédente.\n",
    "    target_arxiv_id = None\n",
    "    if simple_search_results and simple_search_results[0].metadata.get(\"arxiv_id\"):\n",
    "        target_arxiv_id = simple_search_results[0].metadata.get(\"arxiv_id\")\n",
    "        logger.info(f\"Utilisation de l'arxiv_id '{target_arxiv_id}' pour le test de filtre (provenant du premier résultat de la recherche précédente).\")\n",
    "    else:\n",
    "        # Mettez un ID connu de votre base de données si la recherche précédente n'a rien donné\n",
    "        logger.warning(\"Aucun arxiv_id récupéré de la recherche précédente. Le filtre par ID pourrait ne pas fonctionner sans un ID valide.\")\n",
    "        # target_arxiv_id = \"your_known_arxiv_id_here\" # Décommentez et remplacez\n",
    "\n",
    "    if target_arxiv_id:\n",
    "        logger.info(f\"\\nRecherche vectorielle pour '{test_query}' AVEC filtre sur arxiv_id='{target_arxiv_id}'\")\n",
    "        filtered_results_by_id = retrieval_engine_instance.retrieve_simple_vector_search(\n",
    "            query_text=test_query,\n",
    "            top_k=2,\n",
    "            metadata_filters=[{\"key\": \"arxiv_id\", \"value\": target_arxiv_id}] # Clé telle que stockée dans MongoDB\n",
    "        )\n",
    "        print_retrieved_nodes(filtered_results_by_id, f\"{test_query} (filtré par arxiv_id: {target_arxiv_id})\")\n",
    "    else:\n",
    "        logger.info(\"Saut du test de filtre par arxiv_id car target_arxiv_id n'est pas défini.\")\n",
    "\n",
    "    # Exemple 2: Filtrer par catégorie principale (si stockée et indexée)\n",
    "    # Supposons que votre index vectoriel a été créé avec \"metadata.primary_category\" comme champ de filtre.\n",
    "    # Et que vos documents MongoDB ont un champ `metadata: { \"primary_category\": \"cs.RO\", ... }`\n",
    "    # Notre `MongoDBManager` a été configuré pour créer un filtre sur \"metadata.primary_category\".\n",
    "    # Et `RetrievalEngine` doit passer la clé de filtre correctement (LlamaIndex gère les chemins de points).\n",
    "    target_category = \"cs.RO\" # Exemple: Robotics\n",
    "    logger.info(f\"\\nRecherche vectorielle pour '{test_query}' AVEC filtre sur primary_category='{target_category}'\")\n",
    "    # La clé de filtre pour LlamaIndex doit correspondre au chemin exact dans le document MongoDB\n",
    "    # Si dans MongoDB c'est {\"metadata\": {\"primary_category\": \"cs.RO\"}}, la clé est \"metadata.primary_category\"\n",
    "    # Si c'est {\"primary_category\": \"cs.RO\"} au premier niveau, la clé est \"primary_category\"\n",
    "    # Nos chunks stockent `metadata` comme un dict imbriqué, donc \"metadata.primary_category\" est correct.\n",
    "    filtered_results_by_category = retrieval_engine_instance.retrieve_simple_vector_search(\n",
    "        query_text=test_query,\n",
    "        top_k=2,\n",
    "        metadata_filters=[{\"key\": \"metadata.primary_category\", \"value\": target_category}]\n",
    "    )\n",
    "    print_retrieved_nodes(filtered_results_by_category, f\"{test_query} (filtré par catégorie: {target_category})\")\n",
    "\n",
    "else:\n",
    "    logger.warning(\"RetrievalEngine non initialisé. Tests de recherche avec filtres sautés.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c41b8",
   "metadata": {},
   "source": [
    "### Stratégie 3: Recherche Hybride (Vectorielle + Textuelle) - Discussion\n",
    "\n",
    "Notre `MongoDBManager` a la capacité de créer à la fois des index vectoriels et des index de recherche textuelle (Atlas Search). LlamaIndex, via `MongoDBAtlasVectorSearch`, peut également être configuré pour utiliser ces deux types d'index pour effectuer une recherche hybride.\n",
    "\n",
    "**Configuration pour la Recherche Hybride avec LlamaIndex:**\n",
    "1.  **Index MongoDB :** Assurez-vous que vous avez :\n",
    "    * Un index de recherche vectorielle (par exemple, `default_vector_index`) sur le champ d'embedding.\n",
    "    * Un index de recherche textuelle Atlas Search (par exemple, `default_text_index`) sur les champs textuels pertinents (comme `text_chunk`, `original_document_title`).\n",
    "    Ces index sont créés par notre `MongoDBManager` si vous exécutez `run_ingestion.py`.\n",
    "\n",
    "2.  **`MongoDBAtlasVectorSearch` de LlamaIndex :** Lors de son initialisation, vous pouvez spécifier le `fulltext_index_name`.\n",
    "    ```python\n",
    "    # Exemple d'initialisation (pas exécuté ici, juste pour illustration)\n",
    "    # vector_store_for_hybrid = MongoDBAtlasVectorSearch(\n",
    "    #     uri=settings.MONGODB_URI,\n",
    "    #     db_name=settings.MONGO_DATABASE_NAME,\n",
    "    #     collection_name=COLLECTION_NAME_FOR_RAG_TEST,\n",
    "    #     index_name=VECTOR_INDEX_NAME_FOR_RAG_TEST, # Index vectoriel\n",
    "    #     fulltext_index_name=TEXT_INDEX_NAME_FOR_RAG_TEST, # Index textuel !\n",
    "    #     embedding_key=\"embedding\",\n",
    "    #     text_key=\"text_chunk\"\n",
    "    # )\n",
    "    # index_for_hybrid = VectorStoreIndex.from_vector_store(vector_store_for_hybrid)\n",
    "    ```\n",
    "\n",
    "3.  **Récupérateur LlamaIndex :** Vous pouvez ensuite obtenir un récupérateur ou un moteur de requête en mode hybride.\n",
    "    ```python\n",
    "    # Exemple de récupérateur hybride (pas exécuté ici)\n",
    "    # hybrid_retriever = index_for_hybrid.as_retriever(\n",
    "    #     vector_store_query_mode=\"hybrid\",\n",
    "    #     similarity_top_k=3, # Nombre de résultats de la recherche vectorielle\n",
    "    #     fulltext_top_n=3,   # Nombre de résultats de la recherche textuelle\n",
    "    #     alpha=0.5           # Pondération (0.0 = textuel seul, 1.0 = vectoriel seul)\n",
    "    # )\n",
    "    # results = hybrid_retriever.retrieve(\"ma requête\")\n",
    "    \n",
    "    # Ou avec un QueryEngine :\n",
    "    # query_engine_hybrid = index_for_hybrid.as_query_engine(\n",
    "    #     vector_store_query_mode=\"hybrid\", \n",
    "    #     similarity_top_k=3, \n",
    "    #     alpha=0.5\n",
    "    # )\n",
    "    # response = query_engine_hybrid.query(\"ma requête\")\n",
    "    ```\n",
    "\n",
    "Notre classe `RetrievalEngine` actuelle ne possède pas de méthode dédiée `retrieve_hybrid_search`, mais elle pourrait être étendue pour en inclure une en utilisant la configuration ci-dessus. Pour l'instant, si les deux index existent dans MongoDB, la base est là pour l'implémenter.\n",
    "\n",
    "Le notebook `GenAI-Showcase/notebooks/rag/retrieval_strategies_mongodb_llamaindex.ipynb` fourni en référence montre en détail comment utiliser ces modes avec LlamaIndex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb7e36",
   "metadata": {},
   "source": [
    "### Futures Explorations : Stratégies RAG Avancées\n",
    "\n",
    "LlamaIndex offre de nombreuses autres stratégies RAG avancées qui pourraient être explorées dans des notebooks ultérieurs ou intégrées dans notre `RetrievalEngine` :\n",
    "* **Parent Document Retriever** : Récupère des chunks plus petits mais retourne les documents parents plus larges pour un meilleur contexte.\n",
    "* **HyDE (Hypothetical Document Embeddings)** : Génère un document hypothétique en réponse à la requête, embedde ce document, puis utilise cet embedding pour la recherche.\n",
    "* **Self-Querying Retriever** : Utilise un LLM pour convertir une requête en langage naturel en une requête structurée qui inclut des filtres de métadonnées.\n",
    "* **Et bien d'autres...**\n",
    "\n",
    "Ces techniques peuvent améliorer significativement la pertinence et la qualité des informations fournies aux agents LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e611383d",
   "metadata": {},
   "source": [
    "## Conclusion de l'Exploration RAG\n",
    "\n",
    "Ce notebook a démontré comment utiliser notre `RetrievalEngine` pour effectuer des recherches vectorielles simples et des recherches avec filtres de métadonnées. Nous avons également discuté de la manière dont la recherche hybride et d'autres stratégies RAG avancées pourraient être mises en œuvre avec LlamaIndex et notre backend MongoDB.\n",
    "\n",
    "Les prochaines étapes pourraient impliquer l'enrichissement du `RetrievalEngine` avec ces stratégies plus avancées ou l'utilisation de ce moteur de récupération par nos agents LangGraph."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
