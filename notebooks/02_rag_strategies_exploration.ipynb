{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee6638b",
   "metadata": {},
   "source": [
    "# Notebook 02: Exploration des Stratégies de Récupération (RAG)\n",
    "\n",
    "Ce notebook explore les capacités de notre `RetrievalEngine` (moteur de récupération) pour extraire des informations pertinentes à partir de la base de connaissances MongoDB que nous avons constituée. Nous allons tester différentes stratégies, notamment :\n",
    "*   Recherche vectorielle simple (basée sur la similarité sémantique).\n",
    "*   Recherche vectorielle avec filtres sur les métadonnées.\n",
    "*   (Optionnel, si implémenté dans `RetrievalEngine`) Recherche hybride combinant recherche vectorielle et recherche textuelle par mots-clés.\n",
    "\n",
    "**Prérequis :**\n",
    "\n",
    "1.  **Environnement Configuré** : Avoir exécuté le notebook `00_setup_environment.ipynb` et s'assurer que le fichier `.env` à la racine du projet est correctement rempli (clés API, `MONGODB_URI`, `OLLAMA_BASE_URL` si applicable, etc.).\n",
    "2.  **Base de Données Populée** : Avoir exécuté le notebook `01_data_ingestion_and_embedding.ipynb` (ou le script `scripts/run_ingestion.py`). Une collection MongoDB (par exemple, `arxiv_chunks_notebook_test_ollama` ou le nom que vous avez utilisé) doit exister et contenir des documents \"chunkés\" avec leurs embeddings.\n",
    "3.  **Configuration de l'Embedding pour les Requêtes** :\n",
    "    *   Le `RetrievalEngine` vectorise les requêtes de recherche en utilisant le fournisseur d'embedding défini par `DEFAULT_EMBEDDING_PROVIDER` dans `config/settings.py` (influencé par `.env`).\n",
    "    *   **Si `DEFAULT_EMBEDDING_PROVIDER=\"ollama\"`** (par défaut) :\n",
    "        *   Assurez-vous que `OLLAMA_BASE_URL` est correct dans `.env`.\n",
    "        *   Le modèle d'embedding spécifié par `OLLAMA_EMBEDDING_MODEL_NAME` (ex: `nomic-embed-text`) doit être disponible sur votre instance Ollama (`ollama pull nomic-embed-text`).\n",
    "    *   **Si `DEFAULT_EMBEDDING_PROVIDER=\"openai\"`** :\n",
    "        *   `OPENAI_API_KEY` doit être configurée dans `.env`.\n",
    "    *   **Si `DEFAULT_EMBEDDING_PROVIDER=\"huggingface\"`** :\n",
    "        *   Aucune clé API spécifique n'est généralement requise pour les modèles Sentence Transformers locaux utilisés via LangChain/LlamaIndex.\n",
    "4.  **Instance MongoDB Accessible** : Votre serveur MongoDB (local ou Atlas) doit être en cours d'exécution et accessible via le `MONGODB_URI` de votre fichier `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998a6ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables d'environnement chargées depuis : /home/facetoface/makers/.env\n",
      "\u001b[34m2025-06-03 23:28:46 - nb_02_rag_exploration - INFO - --- Initialisation du Notebook 02: Exploration des Stratégies RAG ---\u001b[0m\n",
      "\u001b[34m2025-06-03 23:28:46 - nb_02_rag_exploration - INFO - Ce notebook utilisera le fournisseur d'embedding configuré : 'ollama' pour RetrievalEngine.\u001b[0m\n",
      "\u001b[34m2025-06-03 23:28:46 - nb_02_rag_exploration - INFO -   Pour Ollama, assurez-vous que le serveur est accessible à http://localhost:11434 et que le modèle 'nomic-embed-text' est disponible.\u001b[0m\n",
      "\u001b[34m2025-06-03 23:28:46 - nb_02_rag_exploration - INFO - Vérification initiale des configurations (clés API, URI) : OK.\u001b[0m\n",
      "\u001b[34m2025-06-03 23:28:46 - nb_02_rag_exploration - INFO - Le RetrievalEngine ciblera la collection MongoDB : 'arxiv_chunks_notebook_test_ollama'\u001b[0m\n",
      "\u001b[34m2025-06-03 23:28:46 - nb_02_rag_exploration - INFO - Index vectoriel à utiliser : 'vector_index_notebook_test'\u001b[0m\n",
      "\u001b[34m2025-06-03 23:28:46 - nb_02_rag_exploration - INFO - Index textuel (pour recherche hybride si applicable) : 'text_index_notebook_test'\u001b[0m\n",
      "\u001b[34m2025-06-03 23:28:46 - nb_02_rag_exploration - INFO - Configuration initiale du notebook terminée.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- Imports Standards et de Configuration ---\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json # Pour un affichage formaté des métadonnées\n",
    "from typing import Optional, List, Dict, Any # Ajout de Dict et Any pour type hinting\n",
    "\n",
    "# --- Configuration du Projet et Logging ---\n",
    "# Assurer que la racine du projet est dans sys.path pour les imports de src/ et config/\n",
    "project_root_path = Path.cwd().parent \n",
    "if str(project_root_path) not in sys.path:\n",
    "    sys.path.append(str(project_root_path))\n",
    "    print(f\"Ajout de {project_root_path} à sys.path\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "dotenv_path = project_root_path / \".env\"\n",
    "if dotenv_path.exists():\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "    print(f\"Variables d'environnement chargées depuis : {dotenv_path}\")\n",
    "else:\n",
    "    print(f\"ATTENTION: Fichier .env non trouvé à {dotenv_path}. Assurez-vous qu'il est à la racine du projet (makers/).\")\n",
    "    print(\"Les configurations (clés API, URI MongoDB, etc.) pourraient être manquantes.\")\n",
    "\n",
    "from config.settings import settings\n",
    "from config.logging_config import setup_logging\n",
    "# Import du RetrievalEngine et de la structure de données RetrievedNode\n",
    "from src.rag.retrieval_engine import RetrievalEngine, RetrievedNode \n",
    "# MongoDBManager pourrait être utile pour des vérifications directes (optionnel ici)\n",
    "# from src.vector_store.mongodb_manager import MongoDBManager \n",
    "\n",
    "# --- Configuration du Logging pour ce Notebook ---\n",
    "setup_logging(level=\"INFO\") # Changer à \"DEBUG\" pour des logs plus détaillés de RetrievalEngine\n",
    "logger = logging.getLogger(\"nb_02_rag_exploration\")\n",
    "\n",
    "logger.info(\"--- Initialisation du Notebook 02: Exploration des Stratégies RAG ---\")\n",
    "\n",
    "# --- Vérification des Prérequis pour l'Embedding et MongoDB (Crucial pour RetrievalEngine) ---\n",
    "active_embedding_provider = settings.DEFAULT_EMBEDDING_PROVIDER.lower()\n",
    "logger.info(f\"Ce notebook utilisera le fournisseur d'embedding configuré : '{active_embedding_provider}' pour RetrievalEngine.\")\n",
    "\n",
    "error_messages = []\n",
    "if active_embedding_provider == \"openai\":\n",
    "    if not settings.OPENAI_API_KEY:\n",
    "        error_messages.append(\"ERREUR : DEFAULT_EMBEDDING_PROVIDER='openai', mais OPENAI_API_KEY manque dans .env.\")\n",
    "elif active_embedding_provider == \"ollama\":\n",
    "    if not settings.OLLAMA_BASE_URL:\n",
    "        error_messages.append(\"ERREUR : DEFAULT_EMBEDDING_PROVIDER='ollama', mais OLLAMA_BASE_URL manque dans .env.\")\n",
    "    if not settings.OLLAMA_EMBEDDING_MODEL_NAME:\n",
    "         error_messages.append(\"ERREUR : DEFAULT_EMBEDDING_PROVIDER='ollama', mais OLLAMA_EMBEDDING_MODEL_NAME manque dans .env/settings.\")\n",
    "    logger.info(f\"  Pour Ollama, assurez-vous que le serveur est accessible à {settings.OLLAMA_BASE_URL} et que le modèle '{settings.OLLAMA_EMBEDDING_MODEL_NAME}' est disponible.\")\n",
    "# Pas de vérification de clé pour \"huggingface\" (Sentence Transformers locaux)\n",
    "\n",
    "if not settings.MONGODB_URI:\n",
    "    error_messages.append(\"ERREUR CRITIQUE : MONGODB_URI non trouvé dans .env. RetrievalEngine ne pourra pas se connecter.\")\n",
    "\n",
    "if error_messages:\n",
    "    for err in error_messages:\n",
    "        logger.error(err)\n",
    "    logger.error(\"Veuillez corriger les erreurs de configuration ci-dessus avant de continuer.\")\n",
    "    # Vous pourriez vouloir arrêter l'exécution ici si des erreurs critiques sont détectées.\n",
    "    # raise RuntimeError(\"Configuration incomplète pour RetrievalEngine. Voir logs.\")\n",
    "else:\n",
    "    logger.info(\"Vérification initiale des configurations (clés API, URI) : OK.\")\n",
    "\n",
    "\n",
    "# --- Configuration des Noms de Collection et d'Index MongoDB pour ce Test ---\n",
    "# Par défaut, utiliser la collection et les index créés par le notebook 01.\n",
    "# Si le notebook 01 a utilisé un nom de collection dépendant du provider, assurez-vous que c'est le même ici.\n",
    "# Exemple de nom de collection du notebook 01 : \"arxiv_chunks_notebook_test_ollama\"\n",
    "COLLECTION_NAME_FOR_RAG_TEST = f\"arxiv_chunks_notebook_test_{active_embedding_provider}\"\n",
    "VECTOR_INDEX_NAME_FOR_RAG_TEST = \"vector_index_notebook_test\" # Doit correspondre à ce qui a été créé dans le notebook 01\n",
    "TEXT_INDEX_NAME_FOR_RAG_TEST = \"text_index_notebook_test\" # Doit correspondre\n",
    "\n",
    "# Alternative: Utiliser les noms par défaut du MongoDBManager si vous avez ingéré des données avec run_ingestion.py\n",
    "# from src.vector_store.mongodb_manager import MongoDBManager # Déjà importé plus haut si besoin\n",
    "# COLLECTION_NAME_FOR_RAG_TEST = MongoDBManager.DEFAULT_CHUNK_COLLECTION_NAME\n",
    "# VECTOR_INDEX_NAME_FOR_RAG_TEST = MongoDBManager.DEFAULT_VECTOR_INDEX_NAME\n",
    "# TEXT_INDEX_NAME_FOR_RAG_TEST = MongoDBManager.DEFAULT_TEXT_INDEX_NAME\n",
    "\n",
    "logger.info(f\"Le RetrievalEngine ciblera la collection MongoDB : '{COLLECTION_NAME_FOR_RAG_TEST}'\")\n",
    "logger.info(f\"Index vectoriel à utiliser : '{VECTOR_INDEX_NAME_FOR_RAG_TEST}'\")\n",
    "logger.info(f\"Index textuel (pour recherche hybride si applicable) : '{TEXT_INDEX_NAME_FOR_RAG_TEST}'\")\n",
    "\n",
    "logger.info(\"Configuration initiale du notebook terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e2df5",
   "metadata": {},
   "source": [
    "### Initialisation du `RetrievalEngine`\n",
    "\n",
    "Nous allons maintenant créer une instance de notre `RetrievalEngine`. \n",
    "Lors de son initialisation, le `RetrievalEngine` (basé sur LlamaIndex) :\n",
    "1.  Configure le modèle d'embedding global en fonction du `DEFAULT_EMBEDDING_PROVIDER`.\n",
    "2.  Se connecte à MongoDB en utilisant le `MONGODB_URI`.\n",
    "3.  Initialise un `MongoDBAtlasVectorSearch` (ou un store vectoriel LlamaIndex équivalent) pointant vers la collection et l'index vectoriel spécifiés.\n",
    "4.  Charge l'index vectoriel (`VectorStoreIndex`) à partir de ce store.\n",
    "5.  Configure un \"retriever\" par défaut à partir de cet index.\n",
    "\n",
    "Assurez-vous que la collection (`COLLECTION_NAME_FOR_RAG_TEST`) et l'index vectoriel (`VECTOR_INDEX_NAME_FOR_RAG_TEST`) existent et contiennent des données avec des embeddings correspondant au fournisseur configuré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62be24a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-03 23:29:08 - nb_02_rag_exploration - INFO - Tentative d'initialisation du RetrievalEngine...\u001b[0m\n",
      "\u001b[34m2025-06-03 23:29:08 - src.rag.retrieval_engine - INFO - Configuring LlamaIndex embed_model for provider: ollama\u001b[0m\n",
      "\u001b[34m2025-06-03 23:29:08 - src.rag.retrieval_engine - INFO - Configured Ollama embedding model: nomic-embed-text\u001b[0m\n",
      "\u001b[34m2025-06-03 23:29:09 - src.rag.retrieval_engine - INFO - Configured MongoDB vector store for collection: arxiv_chunks_notebook_test_ollama\u001b[0m\n",
      "\u001b[34m2025-06-03 23:29:09 - src.rag.retrieval_engine - INFO - Initialized vector store index and retriever\u001b[0m\n",
      "\u001b[34m2025-06-03 23:29:09 - src.rag.retrieval_engine - INFO - RetrievalEngine initialized with LlamaIndex components\u001b[0m\n",
      "\u001b[34m2025-06-03 23:29:09 - nb_02_rag_exploration - INFO - RetrievalEngine initialisé avec succès.\u001b[0m\n",
      "\u001b[34m2025-06-03 23:29:09 - nb_02_rag_exploration - INFO - L'instance RetrievalEngine est prête à être utilisée.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialiser la variable pour l'instance du RetrievalEngine\n",
    "retrieval_engine_instance: Optional[RetrievalEngine] = None\n",
    "\n",
    "# S'assurer que les erreurs de configuration précédentes n'empêchent pas une tentative d'initialisation\n",
    "# (le code précédent logue des erreurs mais n'arrête pas forcément l'exécution)\n",
    "if error_messages: # error_messages défini dans la cellule précédente\n",
    "    logger.error(\"Initialisation du RetrievalEngine annulée en raison d'erreurs de configuration détectées précédemment.\")\n",
    "else:\n",
    "    logger.info(f\"Tentative d'initialisation du RetrievalEngine...\")\n",
    "    try:\n",
    "        retrieval_engine_instance = RetrievalEngine(\n",
    "            collection_name=COLLECTION_NAME_FOR_RAG_TEST,\n",
    "            vector_index_name=VECTOR_INDEX_NAME_FOR_RAG_TEST\n",
    "            # text_search_index_name peut être ajouté si le moteur le gère pour l'hybride\n",
    "            # text_key et embedding_key sont généralement pris par défaut par RetrievalEngine (via settings ou LlamaIndex defaults)\n",
    "        )\n",
    "        logger.info(\"RetrievalEngine initialisé avec succès.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ERREUR CRITIQUE lors de l'initialisation du RetrievalEngine: {e}\", exc_info=True)\n",
    "        logger.error(\"Causes possibles :\")\n",
    "        logger.error(\"  - URI MongoDB incorrect ou serveur inaccessible.\")\n",
    "        logger.error(f\"  - Collection '{COLLECTION_NAME_FOR_RAG_TEST}' ou index vectoriel '{VECTOR_INDEX_NAME_FOR_RAG_TEST}' non trouvés ou mal configurés.\")\n",
    "        logger.error(\"  - Problème avec le fournisseur d'embedding (ex: clé API OpenAI manquante, serveur Ollama inaccessible, modèle Ollama non trouvé).\")\n",
    "        logger.error(\"  - Incohérence entre les embeddings dans la DB et le modèle d'embedding actuel.\")\n",
    "        retrieval_engine_instance = None # S'assurer qu'il est None en cas d'échec\n",
    "\n",
    "# --- Fonction d'Aide pour Afficher les Résultats de Récupération ---\n",
    "def display_retrieved_nodes(\n",
    "    retrieved_nodes: Optional[List[RetrievedNode]], \n",
    "    query_text: str,\n",
    "    search_type: str = \"Vector Search\"\n",
    ") -> None:\n",
    "    \"\"\"Affiche les nœuds récupérés de manière formatée.\"\"\"\n",
    "    print(f\"\\n--- Résultats pour la Requête ({search_type}) : \\\"{query_text}\\\" ---\")\n",
    "    if not retrieved_nodes:\n",
    "        print(\"Aucun document pertinent n'a été trouvé pour cette requête.\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        return\n",
    "\n",
    "    for i, node in enumerate(retrieved_nodes):\n",
    "        print(f\"\\nRésultat # {i + 1}:\")\n",
    "        print(f\"  Score de Similarité : {node.score:.4f}\" if node.score is not None else \"  Score de Similarité : N/A\")\n",
    "        \n",
    "        # Accès sécurisé aux métadonnées\n",
    "        metadata = node.metadata if node.metadata else {}\n",
    "        print(f\"  ID du Chunk         : {metadata.get('chunk_id', 'N/A')}\") # Si 'chunk_id' est dans les métadonnées\n",
    "        print(f\"  ID ArXiv (source)   : {metadata.get('arxiv_id', 'N/A')}\")\n",
    "        print(f\"  Titre du Document   : {metadata.get('original_document_title', 'N/A')}\")\n",
    "        # Afficher d'autres métadonnées si elles existent et sont pertinentes\n",
    "        # Par exemple, l'année de publication si ajoutée\n",
    "        # published_year = metadata.get('published_year', metadata.get('published', {}).get('$date', '')[:4] if isinstance(metadata.get('published'), dict) else metadata.get('published', '')[:4])\n",
    "        # print(f\"  Année Publication   : {published_year if published_year else 'N/A'}\")\n",
    "\n",
    "        # Afficher un extrait du texte du chunk\n",
    "        text_excerpt = node.text[:350].replace('\\n', ' ') + \"...\" if node.text else \"N/A\"\n",
    "        print(f\"  Extrait du Texte    : {text_excerpt}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "# Test rapide pour voir si l'instance est créée\n",
    "if retrieval_engine_instance:\n",
    "    logger.info(\"L'instance RetrievalEngine est prête à être utilisée.\")\n",
    "else:\n",
    "    logger.error(\"L'instance RetrievalEngine n'a pas pu être créée. Les étapes suivantes échoueront.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ccf1b",
   "metadata": {},
   "source": [
    "### Définition des Requêtes d'Exemple\n",
    "\n",
    "Pour tester notre moteur de récupération, nous avons besoin de quelques requêtes. \n",
    "Ces requêtes devraient être pertinentes par rapport au contenu du corpus que vous avez ingéré. \n",
    "Si vous avez utilisé la requête `ARXIV_QUERY_NOTEBOOK = \"explainable artificial intelligence for robotics\"` du notebook 01, les exemples ci-dessous devraient être adaptés. Sinon, modifiez-les en fonction de votre corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197b44f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-03 23:29:26 - nb_02_rag_exploration - INFO - Requête de test sélectionnée pour les exemples suivants : \"What are the main challenges in applying reinforcement learning to robotic manipulation?\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Liste de requêtes d'exemple pour tester le RAG\n",
    "sample_queries_for_rag: List[str] = [\n",
    "    \"What are the main challenges in applying reinforcement learning to robotic manipulation?\",\n",
    "    \"Techniques for explainable AI (XAI) in robot decision-making processes.\",\n",
    "    \"How can sim-to-real transfer be improved for reinforcement learning agents in robotics?\",\n",
    "    \"Common algorithms for path planning in multi-robot systems using RL.\",\n",
    "    \"What are the ethical considerations for autonomous robots using advanced AI?\",\n",
    "    \"How is Large Language Models (LLMs) applied to robotics?\" # Ajout d'une requête plus générale\n",
    "]\n",
    "\n",
    "# Sélectionner une requête pour les tests initiaux\n",
    "# Vous pouvez changer l'index pour tester différentes requêtes\n",
    "selected_test_query: str = sample_queries_for_rag[0] \n",
    "\n",
    "logger.info(f\"Requête de test sélectionnée pour les exemples suivants : \\\"{selected_test_query}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168d0f1",
   "metadata": {},
   "source": [
    "### Stratégie 1: Recherche Vectorielle Simple\n",
    "\n",
    "Cette première stratégie est la forme la plus basique de RAG :\n",
    "1.  La requête de l'utilisateur (`selected_test_query`) est convertie en un vecteur d'embedding en utilisant le même modèle d'embedding que celui utilisé pour les chunks stockés.\n",
    "2.  Ce vecteur de requête est ensuite comparé aux vecteurs d'embedding des chunks dans MongoDB pour trouver les plus similaires (distance cosinus généralement).\n",
    "3.  Les chunks les plus similaires sont retournés.\n",
    "\n",
    "Nous utilisons la méthode `retrieve_simple_vector_search` (ou un nom similaire, ex: `retrieve`) de notre `RetrievalEngine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e200be72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-03 23:30:51 - nb_02_rag_exploration - INFO - \n",
      "--- Début Stratégie 1: Recherche Vectorielle Simple ---\u001b[0m\n",
      "\u001b[34m2025-06-03 23:30:51 - nb_02_rag_exploration - INFO - Exécution de la recherche vectorielle simple pour la requête : \"What are the main challenges in applying reinforcement learning to robotic manipulation?\"\u001b[0m\n",
      "\u001b[34m2025-06-03 23:30:51 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/embeddings \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-03 23:30:52 - src.rag.retrieval_engine - INFO - Retrieved 0 nodes for query: 'What are the main challenges in applying reinforce...'\u001b[0m\n",
      "\n",
      "--- Résultats pour la Requête (Recherche Vectorielle Simple) : \"What are the main challenges in applying reinforcement learning to robotic manipulation?\" ---\n",
      "Aucun document pertinent n'a été trouvé pour cette requête.\n",
      "--------------------------------------------------\n",
      "\u001b[34m2025-06-03 23:30:52 - nb_02_rag_exploration - INFO - --- Fin Stratégie 1 ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"\\n--- Début Stratégie 1: Recherche Vectorielle Simple ---\")\n",
    "logger.info(f\"Exécution de la recherche vectorielle simple pour la requête : \\\"{selected_test_query}\\\"\")\n",
    "\n",
    "retrieved_nodes_simple_search: Optional[List[RetrievedNode]] = None\n",
    "\n",
    "if retrieval_engine_instance:\n",
    "    try:\n",
    "        # CORRECTION: Utiliser le nom de méthode correct 'retrieve_simple_vector_search'\n",
    "        retrieved_nodes_simple_search = retrieval_engine_instance.retrieve_simple_vector_search(\n",
    "            query_text=selected_test_query,\n",
    "            top_k=3 # Demander les 3 résultats les plus pertinents\n",
    "            # metadata_filters est optionnel et non utilisé pour cette recherche simple\n",
    "        )\n",
    "        \n",
    "        # Afficher les résultats en utilisant notre fonction d'aide\n",
    "        display_retrieved_nodes(\n",
    "            retrieved_nodes_simple_search, \n",
    "            selected_test_query, \n",
    "            search_type=\"Recherche Vectorielle Simple\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de la recherche vectorielle simple : {e}\", exc_info=True)\n",
    "        print(f\"Une erreur est survenue. Assurez-vous que le RetrievalEngine est initialisé et que la base de données est accessible et peuplée.\")\n",
    "else:\n",
    "    logger.error(\"RetrievalEngine non initialisé. Impossible d'exécuter la recherche.\")\n",
    "\n",
    "logger.info(f\"--- Fin Stratégie 1 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77964080",
   "metadata": {},
   "source": [
    "### Stratégie 2: Recherche Vectorielle avec Filtres de Métadonnées\n",
    "\n",
    "Souvent, une simple recherche vectorielle sémantique n'est pas suffisante. Nous pouvons vouloir affiner les résultats en ne considérant que les chunks qui correspondent à certains critères de métadonnées. Par exemple, récupérer des documents :\n",
    "*   Publiés une année spécifique.\n",
    "*   Appartenant à une catégorie ArXiv principale particulière.\n",
    "*   Provenant d'un article (ArXiv ID) spécifique.\n",
    "\n",
    "Le `RetrievalEngine` (via la méthode `retrieve_simple_vector_search` ou une méthode dédiée si elle existe) devrait permettre de passer de tels filtres. La structure des filtres attendus par LlamaIndex est généralement une liste de dictionnaires ou d'objets `ExactMatchFilter`.\n",
    "\n",
    "Pour cet exemple, nous allons essayer de filtrer par `arxiv_id` (pour simuler la recherche de chunks d'un document spécifique) et potentiellement par `primary_category`. Assurez-vous que les valeurs de filtre que vous utilisez existent réellement dans les métadonnées de votre corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea35d2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-03 23:31:52 - nb_02_rag_exploration - INFO - \n",
      "--- Début Stratégie 2: Recherche Vectorielle avec Filtres de Métadonnées ---\u001b[0m\n",
      "\u001b[34m2025-06-03 23:31:52 - nb_02_rag_exploration - INFO - Requête pour la recherche filtrée : \"What are the main challenges in applying reinforcement learning to robotic manipulation?\"\u001b[0m\n",
      "\u001b[33m2025-06-03 23:31:52 - nb_02_rag_exploration - WARNING - Impossible de déterminer un target_arxiv_id à partir des résultats précédents pour le filtre. Utilisation d'une valeur par défaut ou test désactivé.\u001b[0m\n",
      "\u001b[33m2025-06-03 23:31:52 - nb_02_rag_exploration - WARNING - Aucun target_arxiv_id n'a été défini pour le filtre. La recherche filtrée par ArXiv ID est sautée.\u001b[0m\n",
      "\u001b[34m2025-06-03 23:31:52 - nb_02_rag_exploration - INFO - --- Fin Stratégie 2 ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"\\n--- Début Stratégie 2: Recherche Vectorielle avec Filtres de Métadonnées ---\")\n",
    "\n",
    "# Choisir une requête pour ce test (peut être la même que précédemment ou une autre)\n",
    "query_for_filtered_search = selected_test_query # Ou sample_queries_for_rag[1] par exemple\n",
    "logger.info(f\"Requête pour la recherche filtrée : \\\"{query_for_filtered_search}\\\"\")\n",
    "\n",
    "# Définition des filtres de métadonnées\n",
    "# Le format attendu par retrieve_simple_vector_search est List[Dict[str, Any]]\n",
    "# où chaque dict est comme {\"key\": \"metadata_field_name\", \"value\": \"valeur_a_filtrer\"}\n",
    "#\n",
    "# Exemple 1: Filtrer par un ID ArXiv spécifique.\n",
    "# Pour cela, nous devons d'abord connaître un ID ArXiv présent dans nos données.\n",
    "# Idéalement, on le récupère dynamiquement à partir des résultats précédents ou d'une exploration.\n",
    "# Supposons que l'un des ArXiv IDs des chunks récupérés à l'étape précédente était '2505.24878' (à adapter).\n",
    "\n",
    "# Tentative de récupérer un arxiv_id à partir des résultats précédents (si disponibles)\n",
    "target_arxiv_id_for_filter = None\n",
    "if retrieved_nodes_simple_search and retrieved_nodes_simple_search[0].metadata:\n",
    "    target_arxiv_id_for_filter = retrieved_nodes_simple_search[0].metadata.get('arxiv_id')\n",
    "\n",
    "if not target_arxiv_id_for_filter:\n",
    "    logger.warning(\"Impossible de déterminer un target_arxiv_id à partir des résultats précédents pour le filtre. Utilisation d'une valeur par défaut ou test désactivé.\")\n",
    "    # Mettez ici un ID ArXiv que vous savez exister dans votre collection de test si besoin, ex:\n",
    "    # target_arxiv_id_for_filter = \"ID_ARXIV_CONNU_DANS_VOTRE_JEU_DE_TEST\" \n",
    "    # Ou, si vous ne pouvez pas en fournir un, la recherche filtrée pourrait ne pas être très utile.\n",
    "\n",
    "if target_arxiv_id_for_filter:\n",
    "    logger.info(f\"Application d'un filtre sur arxiv_id = '{target_arxiv_id_for_filter}'\")\n",
    "    metadata_filters_example = [\n",
    "        {\"key\": \"arxiv_id\", \"value\": target_arxiv_id_for_filter}\n",
    "    ]\n",
    "    \n",
    "    # Vous pouvez ajouter d'autres filtres, par exemple sur la catégorie principale\n",
    "    # (assurez-vous que 'primary_category' est bien une clé dans vos métadonnées de chunk)\n",
    "    # metadata_filters_example.append({\"key\": \"primary_category\", \"value\": \"cs.RO\"}) # Exemple: Robotics\n",
    "\n",
    "    retrieved_nodes_filtered_search: Optional[List[RetrievedNode]] = None\n",
    "    if retrieval_engine_instance:\n",
    "        try:\n",
    "            retrieved_nodes_filtered_search = retrieval_engine_instance.retrieve_simple_vector_search(\n",
    "                query_text=query_for_filtered_search,\n",
    "                top_k=3, # Demander 3 résultats\n",
    "                metadata_filters=metadata_filters_example\n",
    "            )\n",
    "            \n",
    "            display_retrieved_nodes(\n",
    "                retrieved_nodes_filtered_search, \n",
    "                query_for_filtered_search, \n",
    "                search_type=f\"Recherche Filtrée (arxiv_id: {target_arxiv_id_for_filter})\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erreur lors de la recherche vectorielle filtrée : {e}\", exc_info=True)\n",
    "            print(f\"Une erreur est survenue lors de la recherche filtrée.\")\n",
    "    else:\n",
    "        logger.error(\"RetrievalEngine non initialisé. Impossible d'exécuter la recherche filtrée.\")\n",
    "else:\n",
    "    logger.warning(\"Aucun target_arxiv_id n'a été défini pour le filtre. La recherche filtrée par ArXiv ID est sautée.\")\n",
    "\n",
    "logger.info(f\"--- Fin Stratégie 2 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c41b8",
   "metadata": {},
   "source": [
    "### Stratégie 3: Recherche Hybride (Optionnel)\n",
    "\n",
    "La recherche hybride combine la recherche vectorielle sémantique avec la recherche par mots-clés traditionnelle (souvent BM25 ou via des index textuels MongoDB). Cela peut être utile pour capturer à la fois la pertinence sémantique et les correspondances exactes de termes.\n",
    "\n",
    "**Implémentation dans `RetrievalEngine`:**\n",
    "*   Pour supporter la recherche hybride, le `RetrievalEngine` devrait être capable d'exécuter les deux types de recherche et de fusionner intelligemment les résultats (par exemple, en utilisant Reciprocal Rank Fusion - RRF).\n",
    "*   Cela nécessiterait que `RetrievalEngine` ait accès non seulement à l'index vectoriel (`VECTOR_INDEX_NAME_FOR_RAG_TEST`) mais aussi à l'index textuel (`TEXT_INDEX_NAME_FOR_RAG_TEST`) créé dans MongoDB.\n",
    "*   La classe `RetrievalEngine` devrait exposer une méthode dédiée, par exemple `retrieve_hybrid_search(...)`.\n",
    "\n",
    "**Note pour ce Notebook:**\n",
    "L'implémentation actuelle de `RetrievalEngine` (selon `src/rag/retrieval_engine.py` au moment de la rédaction de ce notebook) se concentre sur la recherche vectorielle via LlamaIndex et `MongoDBAtlasVectorSearch`. Une véritable recherche hybride nécessiterait des modifications plus substantielles dans `RetrievalEngine` pour intégrer une logique de fusion ou utiliser des fonctionnalités avancées de LlamaIndex pour des retrievers composites.\n",
    "\n",
    "**Si la recherche hybride n'est pas encore implémentée dans votre `RetrievalEngine`, cette section ne sera pas exécutable.** Vous pouvez la considérer comme une piste d'amélioration future.\n",
    "\n",
    "Si vous avez implémenté une méthode pour la recherche hybride (ex: `retrieve_hybrid`), vous pouvez décommenter et adapter la cellule de code suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945c67e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-03 23:32:44 - nb_02_rag_exploration - INFO - \n",
      "--- Début Stratégie 3: Recherche Hybride (Conceptuel/Optionnel) ---\u001b[0m\n",
      "\u001b[34m2025-06-03 23:32:44 - nb_02_rag_exploration - INFO - Requête pour la recherche hybride (conceptuelle) : \"What are the main challenges in applying reinforcement learning to robotic manipulation?\"\u001b[0m\n",
      "\u001b[34m2025-06-03 23:32:44 - nb_02_rag_exploration - INFO - Section de recherche hybride (conceptuelle) passée. Décommentez et adaptez si la fonctionnalité est disponible.\u001b[0m\n",
      "\u001b[34m2025-06-03 23:32:44 - nb_02_rag_exploration - INFO - --- Fin Stratégie 3 ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"\\n--- Début Stratégie 3: Recherche Hybride (Conceptuel/Optionnel) ---\")\n",
    "\n",
    "# Définir une requête pour le test de recherche hybride\n",
    "query_for_hybrid_search = selected_test_query \n",
    "# query_for_hybrid_search = \"Explainable AI for robot vision using Transformers\" # Une requête avec des termes spécifiques\n",
    "\n",
    "logger.info(f\"Requête pour la recherche hybride (conceptuelle) : \\\"{query_for_hybrid_search}\\\"\")\n",
    "\n",
    "# La cellule suivante est commentée car la recherche hybride nécessite une implémentation spécifique \n",
    "# dans RetrievalEngine qui n'est peut-être pas encore présente.\n",
    "\n",
    "# if retrieval_engine_instance:\n",
    "#     # Vérifier si la méthode pour la recherche hybride existe\n",
    "#     if hasattr(retrieval_engine_instance, 'retrieve_hybrid_search'):\n",
    "#         logger.info(\"Tentative de recherche hybride...\")\n",
    "#         try:\n",
    "#             retrieved_nodes_hybrid: Optional[List[RetrievedNode]] = retrieval_engine_instance.retrieve_hybrid_search(\n",
    "#                 query_text=query_for_hybrid_search,\n",
    "#                 top_k=5, # La recherche hybride peut bénéficier de plus de candidats initiaux avant fusion\n",
    "#                 # D'autres paramètres spécifiques à la recherche hybride pourraient être nécessaires:\n",
    "#                 # alpha=0.5, # Par exemple, un poids pour la fusion RRF\n",
    "#                 # text_search_weight=0.3, vector_search_weight=0.7\n",
    "#             )\n",
    "#             \n",
    "#             display_retrieved_nodes(\n",
    "#                 retrieved_nodes_hybrid, \n",
    "#                 query_for_hybrid_search, \n",
    "#                 search_type=\"Recherche Hybride\"\n",
    "#             )\n",
    "# \n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Erreur lors de la recherche hybride : {e}\", exc_info=True)\n",
    "#             print(f\"Une erreur est survenue lors de la recherche hybride.\")\n",
    "#     else:\n",
    "#         logger.warning(\"La méthode 'retrieve_hybrid_search' n'est pas implémentée dans RetrievalEngine.\")\n",
    "#         print(\"Fonctionnalité de recherche hybride non disponible dans cette version du RetrievalEngine.\")\n",
    "# else:\n",
    "#     logger.error(\"RetrievalEngine non initialisé. Impossible d'exécuter la recherche hybride.\")\n",
    "\n",
    "logger.info(\"Section de recherche hybride (conceptuelle) passée. Décommentez et adaptez si la fonctionnalité est disponible.\")\n",
    "logger.info(f\"--- Fin Stratégie 3 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb7e36",
   "metadata": {},
   "source": [
    "## Conclusion du Notebook 02: Exploration des Stratégies RAG\n",
    "\n",
    "Ce notebook a démontré comment utiliser le `RetrievalEngine` pour :\n",
    "1.  Effectuer une **recherche vectorielle simple** basée sur la similarité sémantique.\n",
    "2.  Affiner les résultats de la recherche vectorielle en appliquant des **filtres sur les métadonnées** des chunks.\n",
    "3.  Esquissé le concept de **recherche hybride** comme une amélioration potentielle.\n",
    "\n",
    "**Points Clés et Pistes d'Amélioration :**\n",
    "\n",
    "*   **Qualité des Embeddings** : La pertinence des résultats dépend fortement de la qualité des embeddings générés (à la fois pour les chunks stockés et pour la requête). Le choix du modèle d'embedding est crucial.\n",
    "*   **Stratégie de Chunking** : La manière dont les documents sont segmentés en chunks (taille, chevauchement, respect des frontières sémantiques) impacte directement ce qui peut être récupéré.\n",
    "*   **Pertinence des Métadonnées** : Des métadonnées riches et précises permettent un filtrage plus efficace et un meilleur contexte pour le LLM en aval.\n",
    "*   **Techniques de Re-ranking** : Pour améliorer davantage la pertinence, des modèles de re-ranking (par exemple, Cohere Rerank, ou des cross-encoders) peuvent être appliqués sur les résultats initiaux du retriever.\n",
    "*   **Expansion de Requête** : Des techniques comme HyDE (Hypothetical Document Embeddings) ou la réécriture de requête par un LLM peuvent améliorer la formulation de la requête avant la recherche vectorielle.\n",
    "*   **Interface Utilisateur** : Les fonctionnalités explorées ici sont les briques de base pour une interface de type question-réponse ou un système de recherche sémantique plus complet.\n",
    "\n",
    "**Prochaines Étapes Suggérées :**\n",
    "*   Expérimenter avec différentes requêtes et filtres pour bien comprendre le comportement de votre `RetrievalEngine`.\n",
    "*   Si la recherche hybride n'est pas implémentée, considérer son ajout pour des cas d'usage nécessitant des correspondances exactes de termes.\n",
    "*   Passer au **Notebook 03: Développement d'Agents et Outillage**, où nous commencerons à construire des agents intelligents qui pourront utiliser ce moteur de récupération comme un outil."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
