{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666a8bbe",
   "metadata": {},
   "source": [
    "# Notebook 04: Conception et Exécution du Workflow LangGraph\n",
    "\n",
    "Ce notebook est dédié à l'exécution et à l'observation de notre workflow multi-agents \"Cognitive Swarm\", tel que défini dans `src/graph/main_workflow.py`. Nous allons soumettre une requête complexe et suivre le déroulement des opérations à travers les différents agents et outils.\n",
    "\n",
    "**Prérequis :**\n",
    "* Environnement configuré via `00_setup_environment.ipynb`.\n",
    "* Base de données MongoDB peuplée (via `01_data_ingestion_and_embedding.ipynb` ou `scripts/run_ingestion.py`) pour que le `DocumentAnalysisAgent` ait des données à analyser.\n",
    "* Les clés API (`OPENAI_API_KEY`, `WANDB_API_KEY` si le logger est utilisé, etc.) doivent être dans `.env`.\n",
    "* Le `MongoDBSaver` (checkpointer) est activé par défaut dans la version actuelle de `main_workflow.py`. Assurez-vous que MongoDB est accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58690d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import asyncio # Pour exécuter notre fonction de workflow asynchrone\n",
    "import uuid   # Pour générer des thread_id uniques\n",
    "\n",
    "# Ajout de la racine du projet au PYTHONPATH\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "    print(f\"Ajout de {project_root} au PYTHONPATH\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "dotenv_path = project_root / \".env\"\n",
    "if dotenv_path.exists():\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "    print(f\"Variables d'environnement chargées depuis : {dotenv_path}\")\n",
    "else:\n",
    "    print(f\"ATTENTION: Fichier .env non trouvé à {dotenv_path}.\")\n",
    "\n",
    "from config.settings import settings\n",
    "from config.logging_config import setup_logging\n",
    "\n",
    "# Importer la fonction d'exécution du workflow principal\n",
    "from src.graph.main_workflow import run_cognitive_swarm_v2_1, graph_app_v2_1 # Importer aussi le graphe compilé\n",
    "\n",
    "# Configurer le logging pour le notebook\n",
    "LOG_LEVEL_NOTEBOOK = \"INFO\" # ou \"DEBUG\"\n",
    "setup_logging(level=LOG_LEVEL_NOTEBOOK) \n",
    "logger = logging.getLogger(\"nb_04_workflow_execution\")\n",
    "\n",
    "# --- MODIFIÉ : Vérification des prérequis pour LLMs et Embeddings utilisés par le workflow ---\n",
    "logger.info(f\"--- Configuration Active pour le Workflow ---\")\n",
    "# Pour les LLMs génératifs utilisés par les agents du workflow\n",
    "active_llm_provider = settings.DEFAULT_LLM_MODEL_PROVIDER.lower()\n",
    "logger.info(f\"Fournisseur LLM génératif principal : '{active_llm_provider}'\")\n",
    "if active_llm_provider == \"openai\" and not settings.OPENAI_API_KEY:\n",
    "    logger.error(f\"ERREUR : Le fournisseur LLM est 'openai', mais OPENAI_API_KEY n'est pas configurée.\")\n",
    "elif active_llm_provider == \"huggingface_api\" and not settings.HUGGINGFACE_API_KEY:\n",
    "    logger.error(f\"ERREUR : Le fournisseur LLM est 'huggingface_api', mais HUGGINGFACE_API_KEY n'est pas configurée.\")\n",
    "elif active_llm_provider == \"ollama\" and not settings.OLLAMA_BASE_URL:\n",
    "    logger.error(f\"ERREUR : Le fournisseur LLM est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée.\")\n",
    "\n",
    "# Pour les embeddings (utilisés par RetrievalEngine via les outils)\n",
    "active_embedding_provider = settings.DEFAULT_EMBEDDING_PROVIDER.lower()\n",
    "logger.info(f\"Fournisseur d'Embedding (pour RAG) : '{active_embedding_provider}'\")\n",
    "if active_embedding_provider == \"openai\" and not settings.OPENAI_API_KEY:\n",
    "    logger.error(f\"ERREUR : Le fournisseur d'embedding est 'openai', mais OPENAI_API_KEY n'est pas configurée.\")\n",
    "elif active_embedding_provider == \"ollama\" and not settings.OLLAMA_BASE_URL:\n",
    "    logger.error(f\"ERREUR : Le fournisseur d'embedding est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée.\")\n",
    "\n",
    "# Pour MongoDB (checkpointer et RAG)\n",
    "if not settings.MONGO_URI:\n",
    "    logger.error(\"ERREUR : MONGO_URI non trouvé. Le checkpointer et le RetrievalEngine (RAG) échoueront.\")\n",
    "# --- FIN MODIFIÉ ---\n",
    "\n",
    "# Petite fonction pour afficher l'état final de manière plus structurée\n",
    "def pretty_print_final_state(final_state: dict):\n",
    "    print(\"\\n--- État Final Détaillé du Graphe ---\")\n",
    "    if not final_state:\n",
    "        print(\"Aucun état final retourné.\")\n",
    "        return\n",
    "        \n",
    "    for key, value in final_state.items():\n",
    "        if key == \"messages\":\n",
    "            print(f\"\\n  {key.upper()}:\")\n",
    "            if isinstance(value, list):\n",
    "                for i, msg in enumerate(value[-5:]): # Afficher les 5 derniers messages pour concision\n",
    "                    msg_type = getattr(msg, 'type', 'UNKNOWN_MSG_TYPE').upper()\n",
    "                    msg_name = getattr(msg, 'name', None)\n",
    "                    msg_content_str = str(getattr(msg, 'content', 'N/A'))\n",
    "                    display_name = f\"{msg_type} ({msg_name})\" if msg_name else msg_type\n",
    "                    \n",
    "                    print(f\"    Message {len(value) - 5 + i +1 if len(value)>5 else i+1}: [{display_name}]\")\n",
    "                    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                        print(f\"      Contenu: {msg_content_str[:100]}... [Appels d'outils: {len(msg.tool_calls)}]\")\n",
    "                        for tc in msg.tool_calls:\n",
    "                            print(f\"        Tool Call ID: {tc.get('id')}, Name: {tc.get('name')}, Args: {tc.get('args')}\")\n",
    "                    elif msg_type == \"TOOL\": # ToolMessage\n",
    "                        tool_call_id = getattr(msg, 'tool_call_id', 'N/A')\n",
    "                        # Tenter de parser le contenu si c'est une chaîne JSON (pour les résultats d'outils structurés)\n",
    "                        parsed_tool_content = None\n",
    "                        if isinstance(msg_content_str, str):\n",
    "                            try:\n",
    "                                parsed_tool_content = json.loads(msg_content_str)\n",
    "                            except json.JSONDecodeError:\n",
    "                                pass # Laisser comme chaîne si ce n'est pas du JSON valide\n",
    "                        \n",
    "                        if parsed_tool_content and isinstance(parsed_tool_content, list) and parsed_tool_content:\n",
    "                            print(f\"      Tool Call ID: {tool_call_id} - Résultat Outil (Liste de {len(parsed_tool_content)} éléments):\")\n",
    "                            for item_idx, item_data in enumerate(parsed_tool_content[:2]): # Afficher les 2 premiers items\n",
    "                                if isinstance(item_data, dict):\n",
    "                                     print(f\"        Item {item_idx+1}: { {k: str(v)[:70] + '...' if isinstance(v,str) and len(str(v)) > 70 else v for k,v in item_data.items()} }\")\n",
    "                                else:\n",
    "                                     print(f\"        Item {item_idx+1}: {str(item_data)[:100]}...\")\n",
    "                            if len(parsed_tool_content) > 2:\n",
    "                                print(\"        ...\")\n",
    "                        else:\n",
    "                            print(f\"      Tool Call ID: {tool_call_id} - Contenu (Résultat Outil): {msg_content_str[:200]}...\")\n",
    "                    else:\n",
    "                        print(f\"      Contenu: {msg_content_str[:200]}...\")\n",
    "            else:\n",
    "                print(f\"    {str(value)[:500]}...\")\n",
    "        elif key == \"research_plan\" or key == \"synthesis_output\" or key == \"document_analysis_summary\":\n",
    "            print(f\"\\n  {key.upper()}:\\n{str(value)[:1000]}{'...' if value and len(str(value)) > 1000 else ''}\\n\")\n",
    "        elif key == \"user_query\":\n",
    "             print(f\"\\n  {key.upper()}: {value}\")\n",
    "        else: # Pour les autres clés de l'état\n",
    "            print(f\"  {key.upper()}: {str(value)[:500]}{'...' if value and len(str(value)) > 500 else ''}\")\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b98bc",
   "metadata": {},
   "source": [
    "### 1. Définition d'une Requête Utilisateur Complexe\n",
    "\n",
    "Nous allons utiliser une requête qui nécessite potentiellement plusieurs étapes de la part de nos agents (planification, recherche, analyse, synthèse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283861a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Analyze the latest advancements in reinforcement learning for robotic locomotion, focusing on how bipedal robots achieve stable gait. Include key challenges and future research directions based on recent ArXiv papers.\"\n",
    "# user_query = \"What are common methods for robot arm path planning based on recent ArXiv papers?\"\n",
    "\n",
    "logger.info(f\"Requête utilisateur pour ce test : '{user_query}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea283af",
   "metadata": {},
   "source": [
    "### 2. Exécution du Workflow \"Cognitive Swarm\" (Premier Passage)\n",
    "\n",
    "Nous exécutons ici la fonction `run_cognitive_swarm_v2_1` avec notre requête. Un nouvel ID de thread (`thread_id`) sera généré.\n",
    "La sortie de `astream_events` dans `run_cognitive_swarm_v2_1` affichera le flux en temps réel (chunks de LLM, appels d'outils).\n",
    "Le checkpointer MongoDB (activé par défaut dans `main_workflow.py`) sauvegardera l'état à chaque étape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad390ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer un ID de thread unique pour cette exécution\n",
    "test_thread_id = \"nb_workflow_run_\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Lancement du workflow pour la requête avec thread_id: {test_thread_id}\")\n",
    "print(\"Les logs DEBUG du workflow (si activés) et les sorties des agents/outils via astream_events apparaîtront ci-dessous.\")\n",
    "\n",
    "# Exécuter le workflow\n",
    "# Si vous exécutez ce notebook dans un environnement où une boucle d'événements asyncio est déjà en cours\n",
    "# (par exemple, certains IDEs ou des versions de Jupyter), vous pourriez avoir besoin de `nest_asyncio`.\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "final_state_run1 = None\n",
    "if settings.OPENAI_API_KEY and settings.MONGO_URI: # Vérifications de base\n",
    "    try:\n",
    "        # Exécution de la fonction asynchrone\n",
    "        final_state_run1 = asyncio.run(run_cognitive_swarm_v2_1(user_query, thread_id=test_thread_id))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'exécution de asyncio.run(run_cognitive_swarm_v2_1): {e}\", exc_info=True)\n",
    "        print(f\"ERREUR pendant l'exécution du workflow : {e}\")\n",
    "else:\n",
    "    print(\"Clés API OpenAI ou MONGO_URI manquantes. Exécution du workflow annulée.\")\n",
    "\n",
    "# Afficher l'état final de manière plus structurée\n",
    "if final_state_run1:\n",
    "    pretty_print_final_state(final_state_run1)\n",
    "else:\n",
    "    print(\"L'exécution du workflow n'a pas retourné d'état final.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821f382",
   "metadata": {},
   "source": [
    "### 3. Analyse des Sorties et du Comportement\n",
    "\n",
    "Après l'exécution :\n",
    "* Examinez les logs produits dans la console du notebook (si le niveau de log est DEBUG pour `main_workflow` ou les agents, vous verrez beaucoup de détails).\n",
    "* Observez la sortie finale (`synthesis_output`) dans l'état final.\n",
    "* Si vous avez accès à MongoDB (par exemple, via MongoDB Compass ou un autre client), vous pouvez inspecter la collection des checkpoints (par défaut `langgraph_checkpoints` dans la base `cognitive_swarm_db`). Vous devriez y trouver des documents correspondant au `thread_id` utilisé. Chaque document représente un état sauvegardé du graphe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a61a3f",
   "metadata": {},
   "source": [
    "### 4. (Optionnel) Exécution d'une Requête de Suivi sur le Même Thread\n",
    "\n",
    "Si le checkpointer a fonctionné, l'historique des messages et l'état du thread précédent sont sauvegardés. Envoyer une nouvelle requête avec le *même `thread_id`* permettra au système de potentiellement utiliser cet historique.\n",
    "\n",
    "Notre workflow actuel est plutôt linéaire et ne gère pas explicitement les \"questions de suivi\" pour modifier un rapport existant. Une nouvelle invocation avec le même `thread_id` ajoutera à l'historique des messages et relancera le flux depuis le début, mais les agents verront l'historique complet.\n",
    "\n",
    "Pour une vraie \"reprise\" d'un graphe interrompu, LangGraph le gère automatiquement si vous relancez avec la même configuration (thread_id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a3c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Décommentez pour tester un suivi.\n",
    "# # Note: Cela relancera le flux avec l'historique accumulé.\n",
    "#\n",
    "# follow_up_query = \"Can you provide more details on the challenges mentioned regarding sim-to-real transfer?\"\n",
    "# logger.info(f\"Requête de suivi pour le thread {test_thread_id}: '{follow_up_query}'\")\n",
    "# print(f\"\\nLancement d'une requête de suivi sur le même thread_id: {test_thread_id}\")\n",
    "\n",
    "# final_state_run2 = None\n",
    "# if settings.OPENAI_API_KEY and settings.MONGO_URI and test_thread_id: # S'assurer que test_thread_id est défini\n",
    "#     try:\n",
    "#         final_state_run2 = asyncio.run(run_cognitive_swarm_v2_1(follow_up_query, thread_id=test_thread_id))\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Erreur lors de l'exécution de la requête de suivi : {e}\", exc_info=True)\n",
    "#         print(f\"ERREUR pendant l'exécution de la requête de suivi : {e}\")\n",
    "# else:\n",
    "#     print(\"Conditions non remplies pour la requête de suivi (API Keys, MongoDB URI, ou thread_id manquant).\")\n",
    "\n",
    "# if final_state_run2:\n",
    "#     pretty_print_final_state(final_state_run2)\n",
    "# else:\n",
    "#     print(\"L'exécution de la requête de suivi n'a pas retourné d'état final.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6790d",
   "metadata": {},
   "source": [
    "### 5. Inspection des Checkpoints dans MongoDB (Conceptuel)\n",
    "\n",
    "Si le `MongoDBSaver` est actif, vous pouvez vous connecter à votre instance MongoDB et examiner la collection `langgraph_checkpoints` (ou le nom que vous avez configuré dans `settings.py`). Vous y trouverez des documents JSON représentant les différents états sauvegardés pour chaque `thread_id`.\n",
    "\n",
    "Chaque document de checkpoint contient typiquement :\n",
    "* `thread_id`\n",
    "* `thread_ts` (un timestamp identifiant ce snapshot spécifique de l'état)\n",
    "* `checkpoint` (l'état sérialisé du graphe, incluant les valeurs des canaux comme `messages`)\n",
    "* `metadata` (métadonnées associées au checkpoint)\n",
    "* `parent_ts` (s'il y a un checkpoint parent)\n",
    "\n",
    "Cela démontre la persistance et la capacité de reprise du workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc9d2e",
   "metadata": {},
   "source": [
    "## Conclusion de la Démonstration du Workflow\n",
    "\n",
    "Ce notebook a permis de lancer le workflow LangGraph complet et d'observer son exécution.\n",
    "Les prochaines étapes pourraient inclure :\n",
    "* Des tests avec des requêtes plus variées.\n",
    "* L'analyse détaillée des checkpoints dans MongoDB.\n",
    "* L'utilisation du script `scripts/run_evaluation.py` pour évaluer quantitativement les résultats.\n",
    "* L'amélioration itérative de la logique de routage et des prompts des agents dans `src/graph/main_workflow.py` et `src/agents/agent_architectures.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitive-swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
