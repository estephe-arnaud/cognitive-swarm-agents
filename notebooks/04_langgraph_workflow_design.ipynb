{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Notebook 04: Conception et Exécution du Workflow LangGraph\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Ce notebook est dédié à l'exécution et à l'observation de notre workflow multi-agents \"MAKERS\", tel que défini dans `src/graph/main_workflow.py`. Nous allons soumettre une requête complexe et suivre le déroulement des opérations à travers les différents agents et outils.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Prérequis :**\n",
    "\n",
    "\n",
    "\n",
    "  * **Environnement de Base :** Avoir exécuté le notebook `00_setup_environment.ipynb` pour configurer l'environnement Conda, les dépendances Python, et s'assurer que le fichier `.env` à la racine du projet est correctement rempli.\n",
    "\n",
    "\n",
    "\n",
    "  * **Base de Données MongoDB :**\n",
    "\n",
    "\n",
    "\n",
    "      * `MONGODB_URI` doit être correctement configuré dans `.env` et votre instance MongoDB doit être accessible. Ceci est utilisé par le checkpointer LangGraph (`MongoDBSaver`) et les outils RAG.\n",
    "\n",
    "\n",
    "\n",
    "      * La base de données doit être peuplée avec des documents et leurs embeddings (via `01_data_ingestion_and_embedding.ipynb` ou `scripts/run_ingestion.py`). Les embeddings stockés doivent correspondre au fournisseur configuré via `DEFAULT_EMBEDDING_PROVIDER` pour que les outils RAG fonctionnent de manière optimale.\n",
    "\n",
    "\n",
    "\n",
    "  * **Configuration des Fournisseurs de Modèles (dans `.env`) :** Le workflow utilisera les fournisseurs configurés via les variables `DEFAULT_LLM_MODEL_PROVIDER` (pour les agents) et `DEFAULT_EMBEDDING_PROVIDER` (pour la RAG et l'embedding des requêtes).\n",
    "\n",
    "\n",
    "\n",
    "      * **Pour les LLMs des Agents (`DEFAULT_LLM_MODEL_PROVIDER`) :**\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"openai\"` : `OPENAI_API_KEY` est requise.\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"huggingface_api\"` : `HUGGINGFACE_API_KEY` et `HUGGINGFACE_REPO_ID` (pour le modèle génératif) sont requis.\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"ollama\"` : Assurez-vous que `OLLAMA_BASE_URL` pointe vers votre instance Ollama en cours d'exécution, et que `OLLAMA_GENERATIVE_MODEL_NAME` est un modèle que vous avez téléchargé (`ollama pull ...`).\n",
    "\n",
    "\n",
    "\n",
    "      * **Pour les Embeddings (`DEFAULT_EMBEDDING_PROVIDER`, utilisé par `RetrievalEngine`) :**\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"openai\"` : `OPENAI_API_KEY` est requise (pour `LlamaIndex OpenAIEmbedding`).\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"huggingface\"` (local Sentence Transformers) : Aucune clé API spécifique n'est généralement requise pour cette étape.\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"ollama\"` : Assurez-vous que `OLLAMA_BASE_URL` est correct et que `OLLAMA_EMBEDDING_MODEL_NAME` est un modèle d'embedding disponible sur votre instance Ollama.\n",
    "\n",
    "\n",
    "\n",
    "  * **(Optionnel) Weights & Biases :** Si vous souhaitez utiliser le logging des évaluations avec W&B (via `scripts/run_evaluation.py`, non directement testé dans ce notebook mais bon à savoir), `WANDB_API_KEY` doit être configurée dans `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTENTION: Fichier .env non trouvé à .env. Assurez-vous qu'il est à la racine du projet.\n",
      "\u001b[34m2025-06-04 00:07:41 - nb_04_workflow_execution - INFO - --- Configuration Active pour le Workflow (depuis settings.py et .env) ---\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:41 - nb_04_workflow_execution - INFO - Fournisseur LLM génératif principal pour les agents : 'ollama'\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:41 - nb_04_workflow_execution - INFO - Fournisseur d'Embedding (pour RAG via RetrievalEngine) : 'ollama'\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:41 - nb_04_workflow_execution - INFO - MongoDB URI configuré.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:41 - nb_04_workflow_execution - INFO - Base de données MongoDB: makers_db\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:41 - nb_04_workflow_execution - INFO - Collection des checkpoints LangGraph: langgraph_checkpoints\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:41 - nb_04_workflow_execution - INFO - --- Fin de la Vérification de Configuration Active ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import asyncio # Pour exécuter notre fonction de workflow asynchrone\n",
    "import uuid    # Pour générer des thread_id uniques\n",
    "from typing import Dict, Any, List # Ajout pour pretty_print_final_state\n",
    "\n",
    "project_root = Path()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# De même, si CWD est la racine du projet, dotenv_path serait `Path().resolve() / \".env\"`\n",
    "dotenv_path = project_root / \".env\"\n",
    "if dotenv_path.exists():\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "    print(f\"Variables d'environnement chargées depuis : {dotenv_path}\")\n",
    "else:\n",
    "    print(f\"ATTENTION: Fichier .env non trouvé à {dotenv_path}. Assurez-vous qu'il est à la racine du projet.\")\n",
    "\n",
    "from config.settings import settings\n",
    "from config.logging_config import setup_logging\n",
    "\n",
    "# Importer la fonction d'exécution du workflow principal.\n",
    "# Pour inspecter la structure du graphe, vous pouvez importer `create_workflow_graph` \n",
    "# depuis `src.graph.main_workflow` et le compiler.\n",
    "from src.graph.main_workflow import run_makers_v2_1 \n",
    "\n",
    "# Configurer le logging pour le notebook\n",
    "LOG_LEVEL_NOTEBOOK = \"INFO\" # Changer en \"DEBUG\" pour un maximum de détails du workflow LangGraph\n",
    "setup_logging(level=LOG_LEVEL_NOTEBOOK) \n",
    "logger = logging.getLogger(\"nb_04_workflow_execution\")\n",
    "\n",
    "# --- Vérification des prérequis pour le Workflow (LLMs, Embeddings, MongoDB) ---\n",
    "logger.info(f\"--- Configuration Active pour le Workflow (depuis settings.py et .env) ---\")\n",
    "\n",
    "# 1. Pour les LLMs génératifs (utilisés par les agents du workflow via llm_factory.py)\n",
    "generative_llm_provider = settings.DEFAULT_LLM_MODEL_PROVIDER.lower()\n",
    "logger.info(f\"Fournisseur LLM génératif principal pour les agents : '{generative_llm_provider}'\")\n",
    "if generative_llm_provider == \"openai\":\n",
    "    if not settings.OPENAI_API_KEY:\n",
    "        logger.error(\"ERREUR : LLM Provider est 'openai', mais OPENAI_API_KEY n'est pas configurée.\")\n",
    "    if not settings.DEFAULT_OPENAI_GENERATIVE_MODEL:\n",
    "         logger.warning(\"AVERTISSEMENT : DEFAULT_OPENAI_GENERATIVE_MODEL n'est pas explicitement défini (utilisera le défaut de ChatOpenAI).\")\n",
    "elif generative_llm_provider == \"huggingface_api\":\n",
    "    if not settings.HUGGINGFACE_API_KEY:\n",
    "        logger.error(\"ERREUR : LLM Provider est 'huggingface_api', mais HUGGINGFACE_API_KEY n'est pas configurée.\")\n",
    "    if not settings.HUGGINGFACE_REPO_ID:\n",
    "        logger.error(\"ERREUR : LLM Provider est 'huggingface_api', mais HUGGINGFACE_REPO_ID n'est pas configuré.\")\n",
    "elif generative_llm_provider == \"ollama\":\n",
    "    if not settings.OLLAMA_BASE_URL:\n",
    "        logger.error(\"ERREUR : LLM Provider est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée.\")\n",
    "    if not settings.OLLAMA_GENERATIVE_MODEL_NAME:\n",
    "        logger.error(\"ERREUR : LLM Provider est 'ollama', mais OLLAMA_GENERATIVE_MODEL_NAME n'est pas configuré.\")\n",
    "else:\n",
    "    logger.error(f\"ERREUR : Fournisseur LLM génératif inconnu ou non supporté : '{generative_llm_provider}'\")\n",
    "\n",
    "# 2. Pour les modèles d'Embedding (utilisés par RetrievalEngine via les outils)\n",
    "embedding_provider = settings.DEFAULT_EMBEDDING_PROVIDER.lower()\n",
    "logger.info(f\"Fournisseur d'Embedding (pour RAG via RetrievalEngine) : '{embedding_provider}'\")\n",
    "if embedding_provider == \"openai\":\n",
    "    if not settings.OPENAI_API_KEY: # Nécessaire pour LlamaIndex OpenAIEmbedding\n",
    "        logger.error(\"ERREUR : Embedding Provider est 'openai', mais OPENAI_API_KEY n'est pas configurée.\")\n",
    "    if not settings.OPENAI_EMBEDDING_MODEL_NAME:\n",
    "        logger.warning(\"AVERTISSEMENT : OPENAI_EMBEDDING_MODEL_NAME n'est pas explicitement défini.\")\n",
    "elif embedding_provider == \"huggingface\":\n",
    "    # Les embeddings HuggingFace locaux (SentenceTransformers) ne nécessitent pas de clé API.\n",
    "    if not settings.HUGGINGFACE_EMBEDDING_MODEL_NAME:\n",
    "        logger.error(\"ERREUR : Embedding Provider est 'huggingface', mais HUGGINGFACE_EMBEDDING_MODEL_NAME n'est pas configuré.\")\n",
    "elif embedding_provider == \"ollama\":\n",
    "    if not settings.OLLAMA_BASE_URL: # Partagé avec le LLM génératif Ollama\n",
    "        logger.error(\"ERREUR : Embedding Provider est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée.\")\n",
    "    if not settings.OLLAMA_EMBEDDING_MODEL_NAME:\n",
    "        logger.error(\"ERREUR : Embedding Provider est 'ollama', mais OLLAMA_EMBEDDING_MODEL_NAME n'est pas configuré.\")\n",
    "else:\n",
    "    logger.error(f\"ERREUR : Fournisseur d'embedding inconnu ou non supporté : '{embedding_provider}'\")\n",
    "\n",
    "# 3. Pour MongoDB (utilisé par le checkpointer LangGraph et RetrievalEngine)\n",
    "if not settings.MONGODB_URI or \"<user>\" in settings.MONGODB_URI: # Ajout d'un check pour les placeholders\n",
    "    logger.error(\"ERREUR : MONGODB_URI non trouvé ou semble non configuré (contient des placeholders). Le checkpointer et le RetrievalEngine (RAG) échoueront.\")\n",
    "else:\n",
    "    logger.info(\"MongoDB URI configuré.\")\n",
    "    logger.info(f\"Base de données MongoDB: {settings.MONGO_DATABASE_NAME}\")\n",
    "    logger.info(f\"Collection des checkpoints LangGraph: {settings.LANGGRAPH_CHECKPOINTS_COLLECTION}\")\n",
    "\n",
    "logger.info(\"--- Fin de la Vérification de Configuration Active ---\")\n",
    "\n",
    "# Helper function to display the final state of the graph in a structured way.\n",
    "def pretty_print_final_state(final_state: Dict[str, Any]): # S'assurer que Dict et Any sont importés de typing\n",
    "    print(\"\\n--- État Final Détaillé du Graphe ---\")\n",
    "    if not final_state:\n",
    "        print(\"Aucun état final retourné.\")\n",
    "        return\n",
    "            \n",
    "    for key, value in final_state.items():\n",
    "        if key == \"messages\":\n",
    "            print(f\"\\n  {key.upper()}:\")\n",
    "            if isinstance(value, list):\n",
    "                for i, msg in enumerate(value[-5:]): # Afficher les 5 derniers messages pour concision\n",
    "                    msg_type = getattr(msg, 'type', 'UNKNOWN_MSG_TYPE').upper()\n",
    "                    msg_name = getattr(msg, 'name', None)\n",
    "                    msg_content_str = str(getattr(msg, 'content', 'N/A'))\n",
    "                    display_name = f\"{msg_type} ({msg_name})\" if msg_name else msg_type\n",
    "                    \n",
    "                    print(f\"    Message {len(value) - 5 + i +1 if len(value)>5 else i+1}: [{display_name}]\")\n",
    "                    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                        print(f\"      Contenu: {msg_content_str[:100]}... [Appels d'outils: {len(msg.tool_calls)}]\")\n",
    "                        for tc in msg.tool_calls:\n",
    "                            # La structure de tc peut varier, adaptez au besoin si ce n'est pas un dict direct\n",
    "                            tc_args = tc.get('args') if isinstance(tc, dict) else getattr(tc, 'args', {})\n",
    "                            tc_name = tc.get('name') if isinstance(tc, dict) else getattr(tc, 'name', 'unknown_tool')\n",
    "                            tc_id = tc.get('id') if isinstance(tc, dict) else getattr(tc, 'id', None)\n",
    "                            print(f\"        Tool Call ID: {tc_id}, Name: {tc_name}, Args: {tc_args}\")\n",
    "                    elif msg_type == \"TOOL\": # ToolMessage\n",
    "                        tool_call_id = getattr(msg, 'tool_call_id', 'N/A')\n",
    "                        parsed_tool_content = None\n",
    "                        if isinstance(msg_content_str, str):\n",
    "                            try:\n",
    "                                parsed_tool_content = json.loads(msg_content_str)\n",
    "                            except json.JSONDecodeError:\n",
    "                                pass \n",
    "                        \n",
    "                        if parsed_tool_content and isinstance(parsed_tool_content, list) and parsed_tool_content:\n",
    "                            print(f\"      Tool Call ID: {tool_call_id} - Résultat Outil (Liste de {len(parsed_tool_content)} éléments):\")\n",
    "                            for item_idx, item_data in enumerate(parsed_tool_content[:2]): \n",
    "                                if isinstance(item_data, dict):\n",
    "                                    print(f\"        Item {item_idx+1}: { {k: str(v)[:70] + '...' if isinstance(v,str) and len(str(v)) > 70 else v for k,v in item_data.items()} }\")\n",
    "                                else:\n",
    "                                    print(f\"        Item {item_idx+1}: {str(item_data)[:100]}...\")\n",
    "                            if len(parsed_tool_content) > 2:\n",
    "                                print(\"        ...\")\n",
    "                        else: # Si ce n'est pas une liste parsable ou si elle est vide\n",
    "                            print(f\"      Tool Call ID: {tool_call_id} - Contenu (Résultat Outil): {msg_content_str[:200]}...\")\n",
    "                    else:\n",
    "                        print(f\"      Contenu: {msg_content_str[:200]}...\")\n",
    "            else: # Si 'messages' n'est pas une liste\n",
    "                print(f\"    {str(value)[:500]}...\")\n",
    "        elif key in [\"research_plan\", \"synthesis_output\", \"document_analysis_summary\", \"user_query\", \"error_message\"]:\n",
    "            print(f\"\\n  {key.upper()}:\\n{str(value)[:1000]}{'...' if value and len(str(value)) > 1000 else ''}\\n\")\n",
    "        else: \n",
    "            print(f\"  {key.upper()}: {str(value)[:500]}{'...' if value and len(str(value)) > 500 else ''}\")\n",
    "    print(\"------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 1. Définition d'une Requête Utilisateur Complexe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Nous allons utiliser une requête qui nécessite potentiellement plusieurs étapes de la part de nos agents (planification, recherche, analyse, synthèse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-04 00:07:41 - nb_04_workflow_execution - INFO - Requête utilisateur pour ce test : 'Analyze the latest advancements in reinforcement learning for robotic locomotion, focusing on how bipedal robots achieve stable gait. Include key challenges and future research directions based on recent ArXiv papers.'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Analyze the latest advancements in reinforcement learning for robotic locomotion, focusing on how bipedal robots achieve stable gait. Include key challenges and future research directions based on recent ArXiv papers.\"\n",
    "# user_query = \"What are common methods for robot arm path planning based on recent ArXiv papers?\"\n",
    "\n",
    "logger.info(f\"Requête utilisateur pour ce test : '{user_query}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 2. Exécution du Workflow \"MAKERS\" (Premier Passage)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Nous exécutons ici la fonction `run_makers_v2_1` avec notre requête. Un nouvel ID de thread (`thread_id`) sera généré.\n",
    "\n",
    "\n",
    "\n",
    "  La sortie de `astream_events` dans `run_makers_v2_1` affichera le flux en temps réel (chunks de LLM, appels d'outils).\n",
    "\n",
    "\n",
    "\n",
    "  Le checkpointer MongoDB (activé par défaut dans `main_workflow.py`) sauvegardera l'état à chaque étape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement du workflow pour la requête avec thread_id: nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50\n",
      "Utilisation du LLM provider configuré: 'ollama' et du provider d'embedding: 'ollama'.\n",
      "Les logs du workflow (niveau 'INFO') et les sorties des agents/outils via astream_events apparaîtront ci-dessous.\n",
      "Le traitement peut prendre plusieurs minutes en fonction de la complexité de la requête et des modèles LLM utilisés.\n",
      "\u001b[34m2025-06-04 00:07:42 - src.graph.checkpointer - INFO - MongoDBSaver initialized for database 'makers_db', collection 'langgraph_checkpoints'.\u001b[0m\n",
      "\u001b[33m2025-06-04 00:07:42 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'__start__': 1}\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:42 - src.graph.checkpointer - INFO - `aput_writes` called for thread_id nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50 without specific thread_ts. Targeting latest checkpoint for writes for task f6928c3b-ef51-e130-84ee-e6cf40fb90d2.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:42 - src.graph.main_workflow - INFO - >>> Research Planner Node <<<\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:42 - src.graph.main_workflow - INFO - >>> ResearchPlannerAgent <<<\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:42 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50, thread_ts: 1f040c72-bd88-68bf-bfff-a828d204f40f\u001b[0m\n",
      "\u001b[33m2025-06-04 00:07:42 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'__start__': 2, 'messages': 2, 'user_query': 2, 'branch:to:planner': 2}\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:42 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50, thread_ts: 1f040c72-bd8b-6b37-8000-944a09f90e60\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:43 - src.graph.checkpointer - INFO - Persisted 3 writes to checkpoint version 1f040c72-bd8b-6b37-8000-944a09f90e60 for thread_id nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50, task_id f6928c3b-ef51-e130-84ee-e6cf40fb90d2.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:44 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:55 - src.graph.main_workflow - INFO - Research Plan Output (from 'output' key):\n",
      "1. Key Questions:\n",
      "   - What are the latest advancements in reinforcement learning (RL) for robotic locomotion?\n",
      "   - How do bipedal robots achieve a stable gait using RL techniques?\n",
      "   - What are the key challenges in applying RL for bipedal robot locomotion?\n",
      "   - What are the future research directions based on recent ArXiv papers in this field?\n",
      "\n",
      "2. Information Sources:\n",
      "   - ArXiv preprint repository (specific subcategories: Robotics, Artificial Intelligence, and Machine Learning)\n",
      "   - Recent conference proceedings from IEEE International Conference on Robotics and Automation (ICRA), International Joint Conference on Artificial Intelligence (IJCAI), and Autonomous Agents and Multi-Agent Systems Conference (AAMAS)\n",
      "   - Journals such as IEEE Transactions on Robotics, Journal of Field Robotics, and Journal of Intelligent Service Robotics\n",
      "\n",
      "3. Search Queries:\n",
      "   - \"Latest advancements in reinforcement learning for robotic locomotion\"\n",
      "   - \"Bipedal robot stable gait using reinforcement learning\"\n",
      "   - \"Challenges in applying reinforcement learning for bipedal robot locomotion\"\n",
      "   - \"Future research directions in reinforcement learning for bipedal robot locomotion\"\n",
      "   - \"Recent ArXiv papers on reinforcement learning for robotic locomotion\"\n",
      "   - \"Robotics and automation conference proceedings 20XX (replace XX with the most recent year)\"\n",
      "   - \"IJCAI/AAMAS/ICRA conference proceedings 20XX (replace XX with the most recent year)\"\n",
      "\n",
      "4. Analysis Steps:\n",
      "   - Extract relevant papers based on the search queries and evaluate their quality.\n",
      "   - Analyze the methods used in these papers for training bipedal robots to achieve stable gait using RL techniques.\n",
      "   - Identify common challenges faced by researchers in this field, such as complex dynamics, high-dimensional state spaces, and long-horizon tasks.\n",
      "   - Examine future research directions suggested by the authors of these papers, including potential solutions for the identified challenges.\n",
      "\n",
      "5. Final Output Structure:\n",
      "   - A comprehensive report detailing the latest advancements in RL for robotic locomotion, with a focus on bipedal robots and stable gait.\n",
      "   - The report should include a summary of each selected paper, its contributions to the field, and how it addresses the key questions.\n",
      "   - The report should also highlight the common challenges faced by researchers in this area and propose potential solutions based on future research directions suggested in recent ArXiv papers.\n",
      "   - The final output should be structured in a clear and concise manner, with each section addressing specific aspects of the user's original query.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:55 - src.graph.main_workflow - INFO - Extracted explicit ArXiv query from plan: 'Recent ArXiv papers on reinforcement learning for robotic locomotion'\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:55 - src.graph.main_workflow - INFO - >>> Router after Planner <<<\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:55 - src.graph.main_workflow - INFO - Router decision: Go to ArXiv Search\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:55 - src.graph.checkpointer - INFO - `aput_writes` called for thread_id nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50 without specific thread_ts. Targeting latest checkpoint for writes for task 3449bc9c-22a4-dc14-24d7-7ad4d9595637.\u001b[0m\n",
      "\u001b[33m2025-06-04 00:07:55 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'messages': 3, 'branch:to:planner': 3, 'research_plan': 3, 'arxiv_query_for_searcher': 3, 'error_message': 3, 'branch:to:arxiv_searcher': 3}\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:55 - src.graph.main_workflow - INFO - >>> ArXiv Search Node <<<\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:55 - src.graph.main_workflow - INFO - >>> ArxivSearchAgent <<<\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:55 - src.graph.main_workflow - INFO - >>> ArxivSearchAgent <<<\u001b[0m\n",
      "\u001b[34m2025-06-04 00:07:55 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:00 - src.graph.main_workflow - INFO - No ToolMessage/AIMessage with content found, using 'output' key from agent result.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:00 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50, thread_ts: 1f040c73-34b8-69bd-8001-de95652c9e98\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:00 - src.graph.main_workflow - INFO - >>> Router after ArXiv Search <<<\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:00 - src.graph.checkpointer - INFO - `aput_writes` called for thread_id nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50 without specific thread_ts. Targeting latest checkpoint for writes for task 7bbe30b4-42d7-1427-ffe7-6dbdedb8d367.\u001b[0m\n",
      "\u001b[33m2025-06-04 00:08:00 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'messages': 4, 'error_message': 4, 'branch:to:arxiv_searcher': 4, 'arxiv_search_results_str': 4, 'branch:to:document_analyzer': 4}\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:00 - src.graph.main_workflow - INFO - >>> Document Analysis Node <<<\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:00 - src.graph.main_workflow - INFO - >>> DocumentAnalyzerAgent <<<\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:00 - src.graph.checkpointer - INFO - Persisted 5 writes to checkpoint version 1f040c72-bd8b-6b37-8000-944a09f90e60 for thread_id nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50, task_id 3449bc9c-22a4-dc14-24d7-7ad4d9595637.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:00 - src.graph.checkpointer - INFO - Persisted 4 writes to checkpoint version 1f040c73-34b8-69bd-8001-de95652c9e98 for thread_id nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50, task_id 7bbe30b4-42d7-1427-ffe7-6dbdedb8d367.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:01 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:02 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50, thread_ts: 1f040c73-6a5c-67d2-8002-f7baeed6cfc5\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:13 - src.graph.main_workflow - INFO - Document Analysis Output:\n",
      " Based on the provided ArXiv search results, here is a comprehensive analysis of the latest advancements in reinforcement learning for robotic locomotion:\n",
      "\n",
      "1. Key breakthroughs and innovations:\n",
      "   - The use of deep reinforcement learning (DRL) has emerged as a promising approach to train quadrupedal robots to walk and navigate various environments. This is demonstrated by the papers \"Deep Reinforcement Learning for Robust Locomotion of a Quadrupedal Robot\" (2021) and \"Learning Locomotion Policies for Quadrupedal Robots via Deep Reinforcement Learning\" (2018).\n",
      "   - The DRL algorithms in these papers are designed to learn from sparse rewards, handle the challenges of real-world locomotion tasks, and adapt to different environments. This is a significant breakthrough as it allows robots to learn complex skills autonomously without extensive human intervention.\n",
      "\n",
      "2. Emerging trends and methodologies:\n",
      "   - The trend in reinforcement learning for robotic locomotion is moving towards using DRL algorithms that can learn from sparse rewards and adapt to real-world challenges. This approach enables robots to learn more efficiently and effectively, making them better suited for practical applications.\n",
      "   - Another emerging trend is the use of demonstrations as a means to train DRL algorithms. This methodology allows robots to learn from human demonstrations, which can be particularly useful in situations where it is difficult or impossible to collect large amounts of data through trial and error.\n",
      "\n",
      "3. Practical applications and use cases:\n",
      "   - The advancements in reinforcement learning for robotic locomotion have potential applications in various industries such as search and rescue, military operations, agriculture, and exploration. For example, quadrupedal robots could be used to navigate difficult terrains or assist in dangerous tasks.\n",
      "   - Additionally, these advancements could lead to the development of more efficient and agile industrial robots that can work alongside humans in manufacturing environments.\n",
      "\n",
      "4. Challenges and limitations:\n",
      "   - One major challenge is the computational requirements of DRL algorithms, which can be prohibitively expensive for some applications. This is particularly true when training robots to perform complex tasks or adapt to a wide range of environments.\n",
      "   - Another limitation is the need for large amounts of data to train these algorithms effectively. In many cases, it may be difficult or impossible to collect sufficient data through trial and error or human demonstrations.\n",
      "\n",
      "5. Future directions and opportunities:\n",
      "   - To address the computational challenges, researchers could explore more efficient DRL algorithms or methods that require less computation. This could include using smaller neural networks, more efficient optimization techniques, or parallelizing the training process.\n",
      "   - Another opportunity for future research is to develop methods for transferring learned skills from one environment to another. This would enable robots to adapt more quickly and efficiently to new situations without requiring extensive retraining.\n",
      "   - Additionally, there is potential for collaboration between researchers in robotics, machine learning, and control systems to further advance the state of reinforcement learning for robotic locomotion.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:13 - src.graph.main_workflow - INFO - >>> Router after Document Analysis <<<\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:13 - src.graph.checkpointer - INFO - `aput_writes` called for thread_id nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50 without specific thread_ts. Targeting latest checkpoint for writes for task aa964fba-5b12-e407-c2b8-bde78948e353.\u001b[0m\n",
      "\u001b[33m2025-06-04 00:08:13 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'messages': 5, 'error_message': 5, 'branch:to:document_analyzer': 5, 'document_analysis_summary': 5, 'branch:to:synthesis': 5}\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:13 - src.graph.main_workflow - INFO - >>> Synthesis Node <<<\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:14 - src.graph.checkpointer - INFO - Persisted 4 writes to checkpoint version 1f040c73-6a5c-67d2-8002-f7baeed6cfc5 for thread_id nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50, task_id aa964fba-5b12-e407-c2b8-bde78948e353.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:14 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50, thread_ts: 1f040c73-e735-6f50-8003-5731700f0ccf\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:14 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:24 - src.graph.main_workflow - INFO - Extracted synthesis from 'output' key:  In the realm of Reinforcement Learning (RL) for robotic locomotion, recent advancements have been substantial and promising. Here's a concise summary of these developments:\n",
      "\n",
      "1. Significant Recent Developments:\n",
      "   - The application of Deep Reinforcement Learning (DRL) has proven to be an effective approach in training quadrupedal robots for walking and navigating various environments, as demonstrated by the papers \"Deep Reinforcement Learning for Robust Locomotion of a Quadrupedal Robot\" (2021) and \"Learning Locomotion Policies for Quadrupedal Robots via Deep Reinforcement Learning\" (2018).\n",
      "   - These DRL algorithms are designed to learn from sparse rewards, handle real-world locomotion tasks, and adapt to different environments, representing a significant breakthrough as it allows robots to learn complex skills autonomously with minimal human intervention.\n",
      "\n",
      "2. Key Trends and Breakthroughs:\n",
      "   - The trend in RL for robotic locomotion is shifting towards DRL algorithms that can learn from sparse rewards and adapt to real-world challenges, enabling more efficient and effective learning for practical applications.\n",
      "   - Another emerging trend is the use of demonstrations as a means to train DRL algorithms, allowing robots to learn from human demonstrations in situations where data collection through trial and error may be difficult or impossible.\n",
      "\n",
      "3. Real-World Applications:\n",
      "   - The advancements in RL for robotic locomotion have potential applications across various industries such as search and rescue, military operations, agriculture, and exploration. For instance, quadrupedal robots could navigate challenging terrains or assist in dangerous tasks.\n",
      "   - Additionally, these advancements could lead to the development of more efficient and agile industrial robots that can work alongside humans in manufacturing environments.\n",
      "\n",
      "4. Challenges, Limitations, Future Directions:\n",
      "   - One major challenge is the high computational requirements of DRL algorithms, which can be cost-prohibitive for certain applications. Researchers are exploring more efficient DRL algorithms, smaller neural networks, and parallelized training processes to address this issue.\n",
      "   - Another limitation is the need for large amounts of data to train these algorithms effectively. Future research may focus on developing methods for transferring learned skills from one environment to another, enabling robots to adapt more quickly to new situations without extensive retraining.\n",
      "   - Collaboration between researchers in robotics, machine learning, and control systems could further advance the state of RL for robotic locomotion.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:24 - src.graph.main_workflow - INFO - Final Synthesis Output:\n",
      " In the realm of Reinforcement Learning (RL) for robotic locomotion, recent advancements have been substantial and promising. Here's a concise summary of these developments:\n",
      "\n",
      "1. Significant Recent Developments:\n",
      "   - The application of Deep Reinforcement Learning (DRL) has proven to be an effective approach in training quadrupedal robots for walking and navigating various environments, as demonstrated by the papers \"Deep Reinforcement Learning for Robust Locomotion of a Quadrupedal Robot\" (2021) and \"Learning Locomotion Policies for Quadrupedal Robots via Deep Reinforcement Learning\" (2018).\n",
      "   - These DRL algorithms are designed to learn from sparse rewards, handle real-world locomotion tasks, and adapt to different environments, representing a significant breakthrough as it allows robots to learn complex skills autonomously with minimal human intervention.\n",
      "\n",
      "2. Key Trends and Breakthroughs:\n",
      "   - The trend in RL for robotic locomotion is shifting towards DRL algorithms that can learn from sparse rewards and adapt to real-world challenges, enabling more efficient and effective learning for practical applications.\n",
      "   - Another emerging trend is the use of demonstrations as a means to train DRL algorithms, allowing robots to learn from human demonstrations in situations where data collection through trial and error may be difficult or impossible.\n",
      "\n",
      "3. Real-World Applications:\n",
      "   - The advancements in RL for robotic locomotion have potential applications across various industries such as search and rescue, military operations, agriculture, and exploration. For instance, quadrupedal robots could navigate challenging terrains or assist in dangerous tasks.\n",
      "   - Additionally, these advancements could lead to the development of more efficient and agile industrial robots that can work alongside humans in manufacturing environments.\n",
      "\n",
      "4. Challenges, Limitations, Future Directions:\n",
      "   - One major challenge is the high computational requirements of DRL algorithms, which can be cost-prohibitive for certain applications. Researchers are exploring more efficient DRL algorithms, smaller neural networks, and parallelized training processes to address this issue.\n",
      "   - Another limitation is the need for large amounts of data to train these algorithms effectively. Future research may focus on developing methods for transferring learned skills from one environment to another, enabling robots to adapt more quickly to new situations without extensive retraining.\n",
      "   - Collaboration between researchers in robotics, machine learning, and control systems could further advance the state of RL for robotic locomotion.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:24 - src.graph.checkpointer - INFO - `aput_writes` called for thread_id nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50 without specific thread_ts. Targeting latest checkpoint for writes for task 645734a4-622d-be62-2e83-86f801731112.\u001b[0m\n",
      "\u001b[33m2025-06-04 00:08:24 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'messages': 6, 'error_message': 6, 'branch:to:synthesis': 6, 'synthesis_output': 6}\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:25 - src.graph.checkpointer - INFO - Persisted 3 writes to checkpoint version 1f040c73-e735-6f50-8003-5731700f0ccf for thread_id nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50, task_id 645734a4-622d-be62-2e83-86f801731112.\u001b[0m\n",
      "\u001b[34m2025-06-04 00:08:25 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50, thread_ts: 1f040c74-4fdd-6d95-8004-d251dc93e72c\u001b[0m\n",
      "\n",
      "--- État Final Détaillé du Graphe ---\n",
      "  THREAD_ID: nb_workflow_run_fec86a6e-51fe-4810-90ea-9f5cdb311a50\n",
      "  RESULT: {'messages': [HumanMessage(content='Analyze the latest advancements in reinforcement learning for robotic locomotion, focusing on how bipedal robots achieve stable gait. Include key challenges and future research directions based on recent ArXiv papers.', additional_kwargs={}, response_metadata={}), AIMessage(content='1. Key Questions:\\n   - What are the latest advancements in reinforcement learning (RL) for robotic locomotion?\\n   - How do bipedal robots achieve a stable gait using RL technique...\n",
      "  SYNTHESIS:  In the realm of Reinforcement Learning (RL) for robotic locomotion, recent advancements have been substantial and promising. Here's a concise summary of these developments:\n",
      "\n",
      "1. Significant Recent Developments:\n",
      "   - The application of Deep Reinforcement Learning (DRL) has proven to be an effective approach in training quadrupedal robots for walking and navigating various environments, as demonstrated by the papers \"Deep Reinforcement Learning for Robust Locomotion of a Quadrupedal Robot\" (2021) ...\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Générer un ID de thread unique pour cette exécution\n",
    "test_thread_id = \"nb_workflow_run_\" + str(uuid.uuid4())\n",
    "\n",
    "# LOG_LEVEL_NOTEBOOK est défini dans la section d'initialisation de ce script.\n",
    "print(f\"Lancement du workflow pour la requête avec thread_id: {test_thread_id}\")\n",
    "print(f\"Utilisation du LLM provider configuré: '{settings.DEFAULT_LLM_MODEL_PROVIDER}' et du provider d'embedding: '{settings.DEFAULT_EMBEDDING_PROVIDER}'.\")\n",
    "print(f\"Les logs du workflow (niveau '{LOG_LEVEL_NOTEBOOK}') et les sorties des agents/outils via astream_events apparaîtront ci-dessous.\")\n",
    "print(\"Le traitement peut prendre plusieurs minutes en fonction de la complexité de la requête et des modèles LLM utilisés.\")\n",
    "\n",
    "# MODIFICATION : Activer nest_asyncio pour permettre asyncio.run() dans Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "final_state_run1 = None\n",
    "\n",
    "if not settings.MONGODB_URI or (\"<user>\" in settings.MONGODB_URI and \"<password>\" in settings.MONGODB_URI) or \"<cluster_url>\" in settings.MONGODB_URI:\n",
    "    print(\"\\nERREUR CRITIQUE: MONGODB_URI n'est pas configuré correctement dans le fichier .env (il manque ou contient des placeholders).\")\n",
    "    print(\"L'exécution du workflow est annulée car le checkpointer MongoDB est requis.\")\n",
    "    logger.error(\"MONGODB_URI non configuré ou contient des placeholders. Workflow non exécuté.\")\n",
    "else:\n",
    "    try:\n",
    "        # asyncio.run() devrait maintenant fonctionner correctement grâce à nest_asyncio.apply()\n",
    "        final_state_run1 = asyncio.run(run_makers_v2_1(user_query, thread_id=test_thread_id))\n",
    "        \n",
    "    except ValueError as ve: \n",
    "        logger.error(f\"Erreur de configuration (ValueError) lors de l'exécution de run_makers_v2_1: {ve}\", exc_info=True)\n",
    "        print(f\"\\nERREUR DE CONFIGURATION PENDANT L'EXÉCUTION DU WORKFLOW : {ve}\")\n",
    "        print(\"Veuillez vérifier les configurations pour DEFAULT_LLM_MODEL_PROVIDER, DEFAULT_EMBEDDING_PROVIDER, \")\n",
    "        print(\"et leurs dépendances respectives (clés API, URLs de base, noms de modèles exacts) dans votre fichier .env et settings.py.\")\n",
    "        print(f\"Provider LLM actuel: {settings.DEFAULT_LLM_MODEL_PROVIDER}, Provider Embedding actuel: {settings.DEFAULT_EMBEDDING_PROVIDER}\")\n",
    "    except RuntimeError as re: # Attraper spécifiquement le RuntimeError si nest_asyncio n'a pas fonctionné\n",
    "        if \"cannot be called from a running event loop\" in str(re):\n",
    "            logger.error(f\"Erreur RuntimeError avec asyncio.run(): {re}. 'nest_asyncio.apply()' n'a peut-être pas fonctionné comme prévu.\", exc_info=True)\n",
    "            print(f\"\\nERREUR asyncio : {re}. Assurez-vous que 'nest_asyncio' est installé et que 'nest_asyncio.apply()' a été appelé.\")\n",
    "        else:\n",
    "            logger.error(f\"Erreur RuntimeError inattendue lors de l'exécution de asyncio.run(run_makers_v2_1): {re}\", exc_info=True)\n",
    "            print(f\"\\nERREUR RUNTIME INATTENDUE PENDANT L'EXÉCUTION DU WORKFLOW : {re}\")\n",
    "    except Exception as e: \n",
    "        logger.error(f\"Erreur inattendue lors de l'exécution de asyncio.run(run_makers_v2_1): {e}\", exc_info=True)\n",
    "        print(f\"\\nERREUR INATTENDUE PENDANT L'EXÉCUTION DU WORKFLOW : {e}\")\n",
    "\n",
    "if final_state_run1:\n",
    "    # pretty_print_final_state est défini plus haut dans ce script.\n",
    "    pretty_print_final_state(final_state_run1)\n",
    "else:\n",
    "    print(\"\\nL'exécution du workflow n'a pas retourné d'état final ou a échoué avant de pouvoir retourner un état.\")\n",
    "    if not settings.MONGODB_URI or (\"<user>\" in settings.MONGODB_URI and \"<password>\" in settings.MONGODB_URI) or \"<cluster_url>\" in settings.MONGODB_URI :\n",
    "        print(\"Rappel : MONGODB_URI n'était pas (ou mal) configuré, ce qui a pu empêcher l'exécution.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if final_state_run1 and 'synthesis_output' in final_state_run1:\n",
    "    print(final_state_run1['synthesis_output'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 3. Analyse des Sorties et du Comportement\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Après l'exécution :\n",
    "\n",
    "\n",
    "\n",
    "  * Examinez les logs produits dans la console du notebook (si le niveau de log est DEBUG pour `main_workflow` ou les agents, vous verrez beaucoup de détails).\n",
    "\n",
    "\n",
    "\n",
    "  * Observez la sortie finale (`synthesis_output`) dans l'état final.\n",
    "\n",
    "\n",
    "\n",
    "  * Si vous avez accès à MongoDB (par exemple, via MongoDB Compass ou un autre client), vous pouvez inspecter la collection des checkpoints (par défaut `langgraph_checkpoints` dans la base `makers_db`). Vous devriez y trouver des documents correspondant au `thread_id` utilisé. Chaque document représente un état sauvegardé du graphe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 4. (Optionnel) Exécution d'une Requête de Suivi sur le Même Thread\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Si le checkpointer a fonctionné, l'historique des messages et l'état du thread précédent sont sauvegardés. Envoyer une nouvelle requête avec le *même `thread_id`* permettra au système de potentiellement utiliser cet historique.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Notre workflow actuel est plutôt linéaire et ne gère pas explicitement les \"questions de suivi\" pour modifier un rapport existant. Une nouvelle invocation avec le même `thread_id` ajoutera à l'historique des messages et relancera le flux depuis le début, mais les agents verront l'historique complet.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Pour une vraie \"reprise\" d'un graphe interrompu, LangGraph le gère automatiquement si vous relancez avec la même configuration (thread_id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test d'une Requête de Suivi (Optionnel) ---\n",
    "# Décommentez les lignes ci-dessous pour tester une requête de suivi sur le même thread.\n",
    "# Note: Cela relancera le flux avec l'historique des messages accumulé. Le workflow actuel\n",
    "# est plutôt linéaire et une nouvelle invocation relancera le processus depuis le début,\n",
    "# mais les agents verront l'historique complet. La persistance via checkpointer est démontrée.\n",
    "\n",
    "# # S'assurer que test_thread_id est défini par la cellule d'exécution principale du workflow ci-dessus.\n",
    "# if 'test_thread_id' in locals() and test_thread_id:\n",
    "#     follow_up_query = \"Could you elaborate on the sim-to-real transfer challenges mentioned previously?\" # Exemple de requête de suivi\n",
    "#     logger.info(f\"Requête de suivi pour le thread {test_thread_id}: '{follow_up_query}'\")\n",
    "#     print(f\"\\nLancement d'une requête de suivi sur le même thread_id: {test_thread_id}\")\n",
    "#     print(f\"Utilisation du LLM provider configuré: '{settings.DEFAULT_LLM_MODEL_PROVIDER}' et du provider d'embedding: '{settings.DEFAULT_EMBEDDING_PROVIDER}'.\")\n",
    "#     print(\"Le traitement peut prendre plusieurs minutes...\")\n",
    "\n",
    "#     final_state_run2 = None\n",
    "#     # Vérification principale: MongoDB est essentiel.\n",
    "#     if not settings.MONGODB_URI or (\"<user>\" in settings.MONGODB_URI and \"<password>\" in settings.MONGODB_URI) or \"<cluster_url>\" in settings.MONGODB_URI:\n",
    "#         print(\"ERREUR CRITIQUE: MONGODB_URI n'est pas configuré correctement. Requête de suivi annulée.\")\n",
    "#         logger.error(\"MONGODB_URI non configuré ou contient des placeholders. Requête de suivi non exécutée.\")\n",
    "#     else:\n",
    "#         try:\n",
    "#             final_state_run2 = asyncio.run(run_makers_v2_1(follow_up_query, thread_id=test_thread_id))\n",
    "#         except ValueError as ve: \n",
    "#             logger.error(f\"Erreur de configuration (ValueError) lors de la requête de suivi: {ve}\", exc_info=True)\n",
    "#             print(f\"\\nERREUR DE CONFIGURATION PENDANT LA REQUÊTE DE SUIVI : {ve}\")\n",
    "#             print(\"Veuillez vérifier les configurations pour DEFAULT_LLM_MODEL_PROVIDER, DEFAULT_EMBEDDING_PROVIDER, et leurs dépendances.\")\n",
    "#         except Exception as e: \n",
    "#             logger.error(f\"Erreur inattendue lors de l'exécution de la requête de suivi : {e}\", exc_info=True)\n",
    "#             print(f\"\\nERREUR INATTENDUE PENDANT LA REQUÊTE DE SUIVI : {e}\")\n",
    "\n",
    "#     # pretty_print_final_state est défini plus haut dans ce script.\n",
    "#     if final_state_run2:\n",
    "#         pretty_print_final_state(final_state_run2)\n",
    "#     else:\n",
    "#         print(\"\\nL'exécution de la requête de suivi n'a pas retourné d'état final ou a échoué.\")\n",
    "# else:\n",
    "#     # Ce message s'affichera si cette cellule est exécutée avant que test_thread_id ne soit défini.\n",
    "#     print(\"\\nVariable 'test_thread_id' non trouvée ou non initialisée.\")\n",
    "#     print(\"Veuillez exécuter la cellule précédente (exécution du workflow principal) pour définir un 'test_thread_id' avant de décommenter et d'exécuter cette cellule.\")\n",
    "#     logger.warning(\"'test_thread_id' non défini. Saut de la cellule de requête de suivi optionnelle.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 5. Inspection des Checkpoints dans MongoDB (Conceptuel)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Si le `MongoDBSaver` est actif, vous pouvez vous connecter à votre instance MongoDB et examiner la collection `langgraph_checkpoints` (ou le nom que vous avez configuré dans `settings.py`). Vous y trouverez des documents JSON représentant les différents états sauvegardés pour chaque `thread_id`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Chaque document de checkpoint contient typiquement :\n",
    "\n",
    "\n",
    "\n",
    "  * `thread_id`\n",
    "\n",
    "\n",
    "\n",
    "  * `thread_ts` (un timestamp identifiant ce snapshot spécifique de l'état)\n",
    "\n",
    "\n",
    "\n",
    "  * `checkpoint` (l'état sérialisé du graphe, incluant les valeurs des canaux comme `messages`)\n",
    "\n",
    "\n",
    "\n",
    "  * `metadata` (métadonnées associées au checkpoint)\n",
    "\n",
    "\n",
    "\n",
    "  * `parent_ts` (s'il y a un checkpoint parent)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Cela démontre la persistance et la capacité de reprise du workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Conclusion de la Démonstration du Workflow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Ce notebook a permis de lancer le workflow LangGraph complet et d'observer son exécution.\n",
    "\n",
    "\n",
    "\n",
    "  Les prochaines étapes pourraient inclure :\n",
    "\n",
    "\n",
    "\n",
    "  * Des tests avec des requêtes plus variées.\n",
    "\n",
    "\n",
    "\n",
    "  * L'analyse détaillée des checkpoints dans MongoDB.\n",
    "\n",
    "\n",
    "\n",
    "  * L'utilisation du script `scripts/run_evaluation.py` pour évaluer quantitativement les résultats.\n",
    "\n",
    "\n",
    "\n",
    "  * L'amélioration itérative de la logique de routage et des prompts des agents dans `src/graph/main_workflow.py` et `src/agents/agent_architectures.py`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
