{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Notebook 04: Conception et Exécution du Workflow LangGraph\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Ce notebook est dédié à l'exécution et à l'observation de notre workflow multi-agents \"MAKERS\", tel que défini dans `src/graph/main_workflow.py`. Nous allons soumettre une requête complexe et suivre le déroulement des opérations à travers les différents agents et outils.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Prérequis :**\n",
    "\n",
    "\n",
    "\n",
    "  * **Environnement de Base :** Avoir exécuté le notebook `00_setup_environment.ipynb` pour configurer l'environnement Conda, les dépendances Python, et s'assurer que le fichier `.env` à la racine du projet est correctement rempli.\n",
    "\n",
    "\n",
    "\n",
    "  * **Base de Données MongoDB :**\n",
    "\n",
    "\n",
    "\n",
    "      * `MONGODB_URI` doit être correctement configuré dans `.env` et votre instance MongoDB doit être accessible. Ceci est utilisé par le checkpointer LangGraph (`MongoDBSaver`) et les outils RAG.\n",
    "\n",
    "\n",
    "\n",
    "      * La base de données doit être peuplée avec des documents et leurs embeddings (via `01_data_ingestion_and_embedding.ipynb` ou `scripts/run_ingestion.py`). Les embeddings stockés doivent correspondre au fournisseur configuré via `DEFAULT_EMBEDDING_PROVIDER` pour que les outils RAG fonctionnent de manière optimale.\n",
    "\n",
    "\n",
    "\n",
    "  * **Configuration des Fournisseurs de Modèles (dans `.env`) :** Le workflow utilisera les fournisseurs configurés via les variables `DEFAULT_LLM_MODEL_PROVIDER` (pour les agents) et `DEFAULT_EMBEDDING_PROVIDER` (pour la RAG et l'embedding des requêtes).\n",
    "\n",
    "\n",
    "\n",
    "      * **Pour les LLMs des Agents (`DEFAULT_LLM_MODEL_PROVIDER`) :**\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"openai\"` : `OPENAI_API_KEY` est requise.\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"huggingface_api\"` : `HUGGINGFACE_API_KEY` et `HUGGINGFACE_REPO_ID` (pour le modèle génératif) sont requis.\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"ollama\"` : Assurez-vous que `OLLAMA_BASE_URL` pointe vers votre instance Ollama en cours d'exécution, et que `OLLAMA_GENERATIVE_MODEL_NAME` est un modèle que vous avez téléchargé (`ollama pull ...`).\n",
    "\n",
    "\n",
    "\n",
    "      * **Pour les Embeddings (`DEFAULT_EMBEDDING_PROVIDER`, utilisé par `RetrievalEngine`) :**\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"openai\"` : `OPENAI_API_KEY` est requise (pour `LlamaIndex OpenAIEmbedding`).\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"huggingface\"` (local Sentence Transformers) : Aucune clé API spécifique n'est généralement requise pour cette étape.\n",
    "\n",
    "\n",
    "\n",
    "          * Si réglé sur `\"ollama\"` : Assurez-vous que `OLLAMA_BASE_URL` est correct et que `OLLAMA_EMBEDDING_MODEL_NAME` est un modèle d'embedding disponible sur votre instance Ollama.\n",
    "\n",
    "\n",
    "\n",
    "  * **(Optionnel) Weights & Biases :** Si vous souhaitez utiliser le logging des évaluations avec W&B (via `scripts/run_evaluation.py`, non directement testé dans ce notebook mais bon à savoir), `WANDB_API_KEY` doit être configurée dans `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTENTION: Fichier .env non trouvé à .env. Assurez-vous qu'il est à la racine du projet.\n",
      "\u001b[34m2025-06-05 21:05:08 - nb_04_workflow_execution - INFO - --- Configuration Active pour le Workflow (depuis settings.py et .env) ---\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:08 - nb_04_workflow_execution - INFO - Fournisseur LLM génératif principal pour les agents : 'ollama'\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:08 - nb_04_workflow_execution - INFO - Fournisseur d'Embedding (pour RAG via RetrievalEngine) : 'ollama'\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:08 - nb_04_workflow_execution - INFO - MongoDB URI configuré.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:08 - nb_04_workflow_execution - INFO - Base de données MongoDB: makers_db\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:08 - nb_04_workflow_execution - INFO - Collection des checkpoints LangGraph: langgraph_checkpoints\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:08 - nb_04_workflow_execution - INFO - --- Fin de la Vérification de Configuration Active ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import asyncio # Pour exécuter notre fonction de workflow asynchrone\n",
    "import uuid    # Pour générer des thread_id uniques\n",
    "from typing import Dict, Any, List # Ajout pour pretty_print_final_state\n",
    "\n",
    "project_root = Path()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# De même, si CWD est la racine du projet, dotenv_path serait `Path().resolve() / \".env\"`\n",
    "dotenv_path = project_root / \".env\"\n",
    "if dotenv_path.exists():\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "    print(f\"Variables d'environnement chargées depuis : {dotenv_path}\")\n",
    "else:\n",
    "    print(f\"ATTENTION: Fichier .env non trouvé à {dotenv_path}. Assurez-vous qu'il est à la racine du projet.\")\n",
    "\n",
    "from config.settings import settings\n",
    "from config.logging_config import setup_logging\n",
    "\n",
    "# Importer la fonction d'exécution du workflow principal.\n",
    "# Pour inspecter la structure du graphe, vous pouvez importer `create_workflow_graph` \n",
    "# depuis `src.graph.main_workflow` et le compiler.\n",
    "from src.graph.main_workflow import run_workflow \n",
    "\n",
    "# Configurer le logging pour le notebook\n",
    "LOG_LEVEL_NOTEBOOK = \"INFO\" # Changer en \"DEBUG\" pour un maximum de détails du workflow LangGraph\n",
    "setup_logging(level=LOG_LEVEL_NOTEBOOK) \n",
    "logger = logging.getLogger(\"nb_04_workflow_execution\")\n",
    "\n",
    "# --- Vérification des prérequis pour le Workflow (LLMs, Embeddings, MongoDB) ---\n",
    "logger.info(f\"--- Configuration Active pour le Workflow (depuis settings.py et .env) ---\")\n",
    "\n",
    "# 1. Pour les LLMs génératifs (utilisés par les agents du workflow via llm_factory.py)\n",
    "generative_llm_provider = settings.DEFAULT_LLM_MODEL_PROVIDER.lower()\n",
    "logger.info(f\"Fournisseur LLM génératif principal pour les agents : '{generative_llm_provider}'\")\n",
    "if generative_llm_provider == \"openai\":\n",
    "    if not settings.OPENAI_API_KEY:\n",
    "        logger.error(\"ERREUR : LLM Provider est 'openai', mais OPENAI_API_KEY n'est pas configurée.\")\n",
    "    if not settings.DEFAULT_OPENAI_GENERATIVE_MODEL:\n",
    "         logger.warning(\"AVERTISSEMENT : DEFAULT_OPENAI_GENERATIVE_MODEL n'est pas explicitement défini (utilisera le défaut de ChatOpenAI).\")\n",
    "elif generative_llm_provider == \"huggingface_api\":\n",
    "    if not settings.HUGGINGFACE_API_KEY:\n",
    "        logger.error(\"ERREUR : LLM Provider est 'huggingface_api', mais HUGGINGFACE_API_KEY n'est pas configurée.\")\n",
    "    if not settings.HUGGINGFACE_REPO_ID:\n",
    "        logger.error(\"ERREUR : LLM Provider est 'huggingface_api', mais HUGGINGFACE_REPO_ID n'est pas configuré.\")\n",
    "elif generative_llm_provider == \"ollama\":\n",
    "    if not settings.OLLAMA_BASE_URL:\n",
    "        logger.error(\"ERREUR : LLM Provider est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée.\")\n",
    "    if not settings.OLLAMA_GENERATIVE_MODEL_NAME:\n",
    "        logger.error(\"ERREUR : LLM Provider est 'ollama', mais OLLAMA_GENERATIVE_MODEL_NAME n'est pas configuré.\")\n",
    "else:\n",
    "    logger.error(f\"ERREUR : Fournisseur LLM génératif inconnu ou non supporté : '{generative_llm_provider}'\")\n",
    "\n",
    "# 2. Pour les modèles d'Embedding (utilisés par RetrievalEngine via les outils)\n",
    "embedding_provider = settings.DEFAULT_EMBEDDING_PROVIDER.lower()\n",
    "logger.info(f\"Fournisseur d'Embedding (pour RAG via RetrievalEngine) : '{embedding_provider}'\")\n",
    "if embedding_provider == \"openai\":\n",
    "    if not settings.OPENAI_API_KEY: # Nécessaire pour LlamaIndex OpenAIEmbedding\n",
    "        logger.error(\"ERREUR : Embedding Provider est 'openai', mais OPENAI_API_KEY n'est pas configurée.\")\n",
    "    if not settings.OPENAI_EMBEDDING_MODEL_NAME:\n",
    "        logger.warning(\"AVERTISSEMENT : OPENAI_EMBEDDING_MODEL_NAME n'est pas explicitement défini.\")\n",
    "elif embedding_provider == \"huggingface\":\n",
    "    # Les embeddings HuggingFace locaux (SentenceTransformers) ne nécessitent pas de clé API.\n",
    "    if not settings.HUGGINGFACE_EMBEDDING_MODEL_NAME:\n",
    "        logger.error(\"ERREUR : Embedding Provider est 'huggingface', mais HUGGINGFACE_EMBEDDING_MODEL_NAME n'est pas configuré.\")\n",
    "elif embedding_provider == \"ollama\":\n",
    "    if not settings.OLLAMA_BASE_URL: # Partagé avec le LLM génératif Ollama\n",
    "        logger.error(\"ERREUR : Embedding Provider est 'ollama', mais OLLAMA_BASE_URL n'est pas configurée.\")\n",
    "    if not settings.OLLAMA_EMBEDDING_MODEL_NAME:\n",
    "        logger.error(\"ERREUR : Embedding Provider est 'ollama', mais OLLAMA_EMBEDDING_MODEL_NAME n'est pas configuré.\")\n",
    "else:\n",
    "    logger.error(f\"ERREUR : Fournisseur d'embedding inconnu ou non supporté : '{embedding_provider}'\")\n",
    "\n",
    "# 3. Pour MongoDB (utilisé par le checkpointer LangGraph et RetrievalEngine)\n",
    "if not settings.MONGODB_URI or \"<user>\" in settings.MONGODB_URI: # Ajout d'un check pour les placeholders\n",
    "    logger.error(\"ERREUR : MONGODB_URI non trouvé ou semble non configuré (contient des placeholders). Le checkpointer et le RetrievalEngine (RAG) échoueront.\")\n",
    "else:\n",
    "    logger.info(\"MongoDB URI configuré.\")\n",
    "    logger.info(f\"Base de données MongoDB: {settings.MONGO_DATABASE_NAME}\")\n",
    "    logger.info(f\"Collection des checkpoints LangGraph: {settings.LANGGRAPH_CHECKPOINTS_COLLECTION}\")\n",
    "\n",
    "logger.info(\"--- Fin de la Vérification de Configuration Active ---\")\n",
    "\n",
    "# Helper function to display the final state of the graph in a structured way.\n",
    "def pretty_print_final_state(final_state: Dict[str, Any]): # S'assurer que Dict et Any sont importés de typing\n",
    "    print(\"\\n--- État Final Détaillé du Graphe ---\")\n",
    "    if not final_state:\n",
    "        print(\"Aucun état final retourné.\")\n",
    "        return\n",
    "            \n",
    "    for key, value in final_state.items():\n",
    "        if key == \"messages\":\n",
    "            print(f\"\\n  {key.upper()}:\")\n",
    "            if isinstance(value, list):\n",
    "                for i, msg in enumerate(value[-5:]): # Afficher les 5 derniers messages pour concision\n",
    "                    msg_type = getattr(msg, 'type', 'UNKNOWN_MSG_TYPE').upper()\n",
    "                    msg_name = getattr(msg, 'name', None)\n",
    "                    msg_content_str = str(getattr(msg, 'content', 'N/A'))\n",
    "                    display_name = f\"{msg_type} ({msg_name})\" if msg_name else msg_type\n",
    "                    \n",
    "                    print(f\"    Message {len(value) - 5 + i +1 if len(value)>5 else i+1}: [{display_name}]\")\n",
    "                    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                        print(f\"      Contenu: {msg_content_str[:100]}... [Appels d'outils: {len(msg.tool_calls)}]\")\n",
    "                        for tc in msg.tool_calls:\n",
    "                            # La structure de tc peut varier, adaptez au besoin si ce n'est pas un dict direct\n",
    "                            tc_args = tc.get('args') if isinstance(tc, dict) else getattr(tc, 'args', {})\n",
    "                            tc_name = tc.get('name') if isinstance(tc, dict) else getattr(tc, 'name', 'unknown_tool')\n",
    "                            tc_id = tc.get('id') if isinstance(tc, dict) else getattr(tc, 'id', None)\n",
    "                            print(f\"        Tool Call ID: {tc_id}, Name: {tc_name}, Args: {tc_args}\")\n",
    "                    elif msg_type == \"TOOL\": # ToolMessage\n",
    "                        tool_call_id = getattr(msg, 'tool_call_id', 'N/A')\n",
    "                        parsed_tool_content = None\n",
    "                        if isinstance(msg_content_str, str):\n",
    "                            try:\n",
    "                                parsed_tool_content = json.loads(msg_content_str)\n",
    "                            except json.JSONDecodeError:\n",
    "                                pass \n",
    "                        \n",
    "                        if parsed_tool_content and isinstance(parsed_tool_content, list) and parsed_tool_content:\n",
    "                            print(f\"      Tool Call ID: {tool_call_id} - Résultat Outil (Liste de {len(parsed_tool_content)} éléments):\")\n",
    "                            for item_idx, item_data in enumerate(parsed_tool_content[:2]): \n",
    "                                if isinstance(item_data, dict):\n",
    "                                    print(f\"        Item {item_idx+1}: { {k: str(v)[:70] + '...' if isinstance(v,str) and len(str(v)) > 70 else v for k,v in item_data.items()} }\")\n",
    "                                else:\n",
    "                                    print(f\"        Item {item_idx+1}: {str(item_data)[:100]}...\")\n",
    "                            if len(parsed_tool_content) > 2:\n",
    "                                print(\"        ...\")\n",
    "                        else: # Si ce n'est pas une liste parsable ou si elle est vide\n",
    "                            print(f\"      Tool Call ID: {tool_call_id} - Contenu (Résultat Outil): {msg_content_str[:200]}...\")\n",
    "                    else:\n",
    "                        print(f\"      Contenu: {msg_content_str[:200]}...\")\n",
    "            else: # Si 'messages' n'est pas une liste\n",
    "                print(f\"    {str(value)[:500]}...\")\n",
    "        elif key in [\"research_plan\", \"synthesis_output\", \"document_analysis_summary\", \"user_query\", \"error_message\"]:\n",
    "            print(f\"\\n  {key.upper()}:\\n{str(value)[:1000]}{'...' if value and len(str(value)) > 1000 else ''}\\n\")\n",
    "        else: \n",
    "            print(f\"  {key.upper()}: {str(value)[:500]}{'...' if value and len(str(value)) > 500 else ''}\")\n",
    "    print(\"------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 1. Définition d'une Requête Utilisateur Complexe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Nous allons utiliser une requête qui nécessite potentiellement plusieurs étapes de la part de nos agents (planification, recherche, analyse, synthèse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-06-05 21:05:08 - nb_04_workflow_execution - INFO - Requête utilisateur pour ce test : 'Analyze the latest advancements in reinforcement learning for robotic locomotion, focusing on how bipedal robots achieve stable gait. Include key challenges and future research directions based on recent ArXiv papers.'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Analyze the latest advancements in reinforcement learning for robotic locomotion, focusing on how bipedal robots achieve stable gait. Include key challenges and future research directions based on recent ArXiv papers.\"\n",
    "# user_query = \"What are common methods for robot arm path planning based on recent ArXiv papers?\"\n",
    "\n",
    "logger.info(f\"Requête utilisateur pour ce test : '{user_query}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 2. Exécution du Workflow \"MAKERS\" (Premier Passage)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Nous exécutons ici la fonction `run_makers_v2_1` avec notre requête. Un nouvel ID de thread (`thread_id`) sera généré.\n",
    "\n",
    "\n",
    "\n",
    "  La sortie de `astream_events` dans `run_makers_v2_1` affichera le flux en temps réel (chunks de LLM, appels d'outils).\n",
    "\n",
    "\n",
    "\n",
    "  Le checkpointer MongoDB (activé par défaut dans `main_workflow.py`) sauvegardera l'état à chaque étape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement du workflow pour la requête avec thread_id: nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc\n",
      "Utilisation du LLM provider configuré: 'ollama' et du provider d'embedding: 'ollama'.\n",
      "Les logs du workflow (niveau 'INFO') et les sorties des agents/outils via astream_events apparaîtront ci-dessous.\n",
      "Le traitement peut prendre plusieurs minutes en fonction de la complexité de la requête et des modèles LLM utilisés.\n",
      "\u001b[34m2025-06-05 21:05:08 - src.graph.main_workflow - INFO - Starting workflow for query: 'Analyze the latest advancements in reinforcement learning for robotic locomotion, focusing on how bipedal robots achieve stable gait. Include key challenges and future research directions based on recent ArXiv papers.' with thread_id: nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc\u001b[0m\n",
      "\u001b[33m2025-06-05 21:05:09 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'__start__': 1}\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:09 - src.graph.checkpointer - INFO - `aput_writes` called for thread_id nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc without specific thread_ts. Targeting latest checkpoint for writes for task 910386b3-fcee-b39f-0d68-3311a52234bd.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:09 - src.graph.main_workflow - INFO - --- PLANNER NODE ---\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:09 - src.graph.main_workflow - INFO - --- EXECUTING RESEARCHPLANNERAGENT NODE ---\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:09 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc, thread_ts: 1f0423ff-ffdb-6be4-bfff-38775a0f319f\u001b[0m\n",
      "\u001b[33m2025-06-05 21:05:09 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'__start__': 2, 'messages': 2, 'user_query': 2, 'branch:to:planner': 2}\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:09 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc, thread_ts: 1f0423ff-ffdf-60b2-8000-ed7ceecb7777\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:09 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:09 - src.graph.checkpointer - INFO - Persisted 3 writes to checkpoint version 1f0423ff-ffdf-60b2-8000-ed7ceecb7777 for thread_id nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc, task_id 910386b3-fcee-b39f-0d68-3311a52234bd.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:26 - src.graph.main_workflow - INFO - ResearchPlannerAgent output:\n",
      "Analyze the latest advancements in reinforcement learning for robotic locomotion, focusing on how bipedal robots achieve stable gait. Include key challenges and future research directions based on recent ArXiv papers.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:26 - src.graph.main_workflow - INFO - Extracted ArXiv query from plan (pattern 1): 'reinforcement learning'\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:26 - src.graph.main_workflow - INFO - --- ROUTER (after Planner) ---\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:26 - src.graph.main_workflow - INFO - Decision: Proceed to ArXiv Search.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:26 - src.graph.checkpointer - INFO - `aput_writes` called for thread_id nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc without specific thread_ts. Targeting latest checkpoint for writes for task a005a3dc-14dc-48a1-cdbd-03beadb9aad4.\u001b[0m\n",
      "\u001b[33m2025-06-05 21:05:26 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'messages': 3, 'branch:to:planner': 3, 'research_plan': 3, 'arxiv_query_for_searcher': 3, 'error_message': 3, 'branch:to:arxiv_searcher': 3}\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:26 - src.graph.main_workflow - INFO - --- ARXIV SEARCH NODE ---\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:26 - src.graph.checkpointer - INFO - Persisted 5 writes to checkpoint version 1f0423ff-ffdf-60b2-8000-ed7ceecb7777 for thread_id nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc, task_id a005a3dc-14dc-48a1-cdbd-03beadb9aad4.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:26 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc, thread_ts: 1f042400-a10e-68b9-8001-edcc09dfbc09\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:27 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:27 - src.agents.tool_definitions - INFO - Executing arxiv_search_tool: query='reinforcement learning', max_results=5\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:27 - arxiv - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=reinforcement+learning&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=100\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:28 - arxiv - INFO - Got first page: 100 of 392289 total results\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:28 - src.agents.tool_definitions - INFO - Found 5 papers for query: 'reinforcement learning'\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:29 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:46 - src.graph.main_workflow - INFO - Found 1 relevant papers from ArXiv.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:46 - src.graph.main_workflow - INFO - --- ROUTER (after ArXiv Search) ---\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:46 - src.graph.main_workflow - INFO - Decision: Proceed to Document Analysis.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:46 - src.graph.checkpointer - INFO - `aput_writes` called for thread_id nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc without specific thread_ts. Targeting latest checkpoint for writes for task fa6f4148-49bb-3ae1-b9b9-b9833610cc5f.\u001b[0m\n",
      "\u001b[33m2025-06-05 21:05:46 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'messages': 4, 'error_message': 4, 'branch:to:arxiv_searcher': 4, 'arxiv_search_results_str': 4, 'branch:to:document_analyzer': 4}\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:46 - src.graph.main_workflow - INFO - --- DOCUMENT ANALYSIS NODE ---\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:46 - src.graph.main_workflow - INFO - --- EXECUTING DOCUMENTANALYZERAGENT NODE ---\u001b[0m\n",
      "\u001b[34m2025-06-05 21:05:47 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:08 - src.graph.main_workflow - INFO - DocumentAnalyzerAgent output:\n",
      "\n",
      "**Context:**\n",
      "You are a research analyst. You have been provided with a list of scientific papers (with summaries and links) from ArXiv. Your goal is to produce a comprehensive analysis of the topic.\n",
      "\n",
      "**Your Task:**\n",
      "1.  **Initial Review:** First, review the titles and summaries of the papers provided below to get an overview.\n",
      "2.  **Deeper Analysis (Optional but Recommended):** The summaries are a good starting point, but may be insufficient for a deep, high-quality analysis. For the most promising papers, you are **strongly encouraged** to use the `document_deep_dive_analysis_tool`. This tool will read the full content of the PDF and provide a detailed analysis.\n",
      "3.  **Synthesize Findings:** Based on your review of the summaries and any deep dives you perform, synthesize your findings into a comprehensive analysis.\n",
      "\n",
      "**Input - ArXiv Search Results:**\n",
      " Here are the top 5 most relevant papers on ArXiv related to \"reinforcement learning\" based on your request:\n",
      "\n",
      "1. Title: Some Insights into Lifelong Reinforcement Learning Systems\n",
      "   Authors: Changjian Li\n",
      "   Published Date: January 27, 2020\n",
      "   Summary: This paper provides some arguments to show that the traditional reinforcement learning paradigm fails to model a lifelong reinforcement learning system. It offers insights into lifelong reinforcement learning and presents a simplistic prototype lifelong reinforcement learning system.\n",
      "   PDF URL: http://arxiv.org/pdf/2001.09608v1\n",
      "   Primary Category: cs.LG\n",
      "\n",
      "2. Title: Counterexample-Guided Repair of Reinforcement Learning Systems Using Safety Critics\n",
      "   Authors: David Boetius, Stefan Leue\n",
      "   Published Date: May 24, 2024\n",
      "   Summary: This paper devises a counterexample-guided repair algorithm for repairing reinforcement learning systems leveraging safety critics. The algorithm jointly repairs a reinforcement learning agent and a safety critic using gradient-based constrained optimization.\n",
      "   PDF URL: http://arxiv.org/pdf/2405.15430v1\n",
      "   Primary Category: cs.LG\n",
      "\n",
      "3. Title: Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey\n",
      "   Authors: Ngan Le, Vidhiwar Singh Rathour, Kashu Yamazaki, Khoa Luu, Marios Savvides\n",
      "   Published Date: August 25, 2021\n",
      "   Summary: This work provides a detailed review of recent and state-of-the-art research advances of deep reinforcement learning in computer vision. It discusses the advantages and limitations of various deep reinforcement learning methodologies and their applications in computer vision.\n",
      "   PDF URL: http://arxiv.org/pdf/2108.11510v1\n",
      "   Primary Category: cs.CV\n",
      "\n",
      "4. Title: Causal Reinforcement Learning: A Survey\n",
      "   Authors: Zhihong Deng, Jing Jiang, Guodong Long, Chengqi Zhang\n",
      "   Published Date: July 4, 2023\n",
      "   Summary: This survey comprehensively reviews the literature on causal reinforcement learning. It explains how causality can address core challenges in non-causal reinforcement learning and categorizes and systematically reviews existing causal reinforcement learning approaches based on their target problems and methodologies.\n",
      "   PDF URL: http://arxiv.org/pdf/2307.01452v2\n",
      "   Primary Category: cs.LG\n",
      "\n",
      "5. Title: Distributed Deep Reinforcement Learning: A Survey and A Multi-Player Multi-Agent Learning Toolbox\n",
      "   Authors: Qiyue Yin, Tongtong Yu, Shengqi Shen, Jun Yang, Meijing Zhao, Kaiqi Huang, Bin Liang, Liang Wang\n",
      "   Published Date: December 1, 2022\n",
      "   Summary: This paper compares classical distributed deep reinforcement learning methods and studies important components to achieve efficient distributed learning. It further reviews recently released toolboxes that help to realize distributed deep reinforcement learning without many modifications of their non-distributed versions. The authors develop and release a multi-player multi-agent distributed deep reinforcement learning toolbox, which is validated on Wargame, a complex environment.\n",
      "   PDF URL: http://arxiv.org/pdf/2212.00253v1\n",
      "   Primary Category: cs.LG\n",
      "\n",
      "**Instructions for your final output:**\n",
      "Structure your analysis to include:\n",
      "- Key breakthroughs and innovations.\n",
      "- Emerging trends and new methodologies.\n",
      "- Practical applications and potential impact.\n",
      "- Contradictory findings or open questions.\n",
      "- Challenges and limitations discussed in the papers.\n",
      "- Suggestions for future research directions.\n",
      "\n",
      "Begin your analysis now.\n",
      "\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:08 - src.graph.main_workflow - INFO - Document Analysis Output:\n",
      "\n",
      "**Analysis of Reinforcement Learning Papers**\n",
      "\n",
      "Reinforcement learning (RL) is a rapidly evolving field, with numerous advancements and innovations being made to address its core challenges. In this analysis, we will explore some key breakthroughs, emerging trends, practical applications, open questions, and future research directions based on a review of five recent papers from ArXiv.\n",
      "\n",
      "1. **Key Breakthroughs and Innovations**\n",
      "   - The paper \"Counterexample-Guided Repair of Reinforcement Learning Systems Using Safety Critics\" by David Boetius and Stefan Leue presents a novel counterexample-guided repair algorithm for reinforcement learning systems, leveraging safety critics to jointly repair the agent and critic using gradient-based constrained optimization.\n",
      "   - The survey \"Causal Reinforcement Learning: A Survey\" by Zhihong Deng et al. provides an in-depth review of causality's role in addressing core challenges in non-causal reinforcement learning, categorizing and systematically examining existing causal RL approaches based on their target problems and methodologies.\n",
      "\n",
      "2. **Emerging Trends and New Methodologies**\n",
      "   - The survey \"Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey\" by Ngan Le et al. discusses the advantages and limitations of various deep reinforcement learning methodologies and their applications in computer vision, offering valuable insights for researchers working on RL in this domain.\n",
      "   - The paper \"Distributed Deep Reinforcement Learning: A Survey and a Multi-Player Multi-Agent Learning Toolbox\" by Qiyue Yin et al. compares classical distributed deep reinforcement learning methods and studies important components to achieve efficient distributed learning, providing a valuable resource for researchers working on large-scale RL problems.\n",
      "\n",
      "3. **Practical Applications and Potential Impact**\n",
      "   - The survey \"Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey\" highlights the practical applications of deep reinforcement learning in computer vision, such as robotics, autonomous driving, and game playing, among others.\n",
      "   - The paper \"Some Insights into Lifelong Reinforcement Learning Systems\" presents a simplistic prototype lifelong RL system, which could have significant implications for real-world applications where agents must adapt to changing environments over time.\n",
      "\n",
      "4. **Contradictory Findings or Open Questions**\n",
      "   - The paper \"Some Insights into Lifelong Reinforcement Learning Systems\" argues that traditional reinforcement learning paradigms fail to model a lifelong RL system, but it does not offer concrete solutions for addressing this issue.\n",
      "   - The survey \"Causal Reinforcement Learning: A Survey\" discusses the challenges and limitations of causal RL, such as the difficulty in estimating causal effects from observational data, and the need for more efficient algorithms to scale up to large-scale problems.\n",
      "\n",
      "5. **Challenges and Limitations**\n",
      "   - The paper \"Distributed Deep Reinforcement Learning: A Survey and a Multi-Player Multi-Agent Learning Toolbox\" discusses the challenges of distributed deep RL, such as communication overhead, synchronization issues, and the need for efficient algorithms to scale up to large-scale problems.\n",
      "   - The survey \"Causal Reinforcement Learning: A Survey\" highlights the limitations of current causal RL methods, including their inability to handle complex interventions, confounding variables, and non-stationary environments.\n",
      "\n",
      "6. **Suggestions for Future Research Directions**\n",
      "   - To address the challenges discussed in \"Some Insights into Lifelong Reinforcement Learning Systems,\" future research could focus on developing more effective lifelong RL algorithms that can adapt to changing environments over time.\n",
      "   - For \"Counterexample-Guided Repair of Reinforcement Learning Systems Using Safety Critics,\" future work could explore the application of this repair algorithm in various RL domains and compare its performance with other repair strategies.\n",
      "   - To address the limitations discussed in \"Causal Reinforcement Learning: A Survey,\" researchers could focus on developing more efficient algorithms for causal effect estimation, handling complex interventions, confounding variables, and non-stationary environments.\n",
      "   - For \"Distributed Deep Reinforcement Learning: A Survey and a Multi-Player Multi-Agent Learning Toolbox,\" future research could aim to improve the scalability of distributed deep RL algorithms, reduce communication overhead, and address synchronization issues in large-scale problems.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:08 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc, thread_ts: 1f042401-6126-6f4c-8002-289b528913c3\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:08 - src.graph.main_workflow - INFO - --- ROUTER (after Document Analysis) ---\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:08 - src.graph.main_workflow - INFO - Decision: Proceed to Synthesis.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:08 - src.graph.checkpointer - INFO - `aput_writes` called for thread_id nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc without specific thread_ts. Targeting latest checkpoint for writes for task 192ccfb0-2c61-30b3-0e96-08b3f428f233.\u001b[0m\n",
      "\u001b[33m2025-06-05 21:06:08 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'messages': 5, 'error_message': 5, 'branch:to:document_analyzer': 5, 'document_analysis_summary': 5, 'branch:to:synthesis': 5}\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:08 - src.graph.main_workflow - INFO - --- SYNTHESIS NODE ---\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:08 - src.graph.checkpointer - INFO - Persisted 4 writes to checkpoint version 1f042400-a10e-68b9-8001-edcc09dfbc09 for thread_id nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc, task_id fa6f4148-49bb-3ae1-b9b9-b9833610cc5f.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:08 - src.graph.checkpointer - INFO - Persisted 4 writes to checkpoint version 1f042401-6126-6f4c-8002-289b528913c3 for thread_id nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc, task_id 192ccfb0-2c61-30b3-0e96-08b3f428f233.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:08 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc, thread_ts: 1f042402-3247-64e1-8003-0486fdab15d8\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:09 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:21 - src.graph.main_workflow - INFO - Final Synthesis Output:\n",
      " **Final Report**\n",
      "\n",
      "---\n",
      "\n",
      "1. **Executive Summary**\n",
      "\n",
      "In this analysis, we review recent advancements in reinforcement learning (RL), a rapidly evolving field that addresses core challenges through innovative breakthroughs and emerging trends. We highlight key developments such as counterexample-guided repair algorithms for RL systems, causal RL approaches, deep RL methodologies in computer vision, distributed RL techniques, and lifelong RL systems. Real-world applications range from robotics to autonomous driving, while challenges include adaptability to changing environments, scalability, and efficient causal effect estimation.\n",
      "\n",
      "2. **Key Developments**\n",
      "\n",
      "* \"Counterexample-Guided Repair of Reinforcement Learning Systems Using Safety Critics\" by David Boetius and Stefan Leue introduces a novel repair algorithm for RL systems using safety critics to jointly optimize the agent and critic.\n",
      "* The survey \"Causal Reinforcement Learning: A Survey\" by Zhihong Deng et al. offers an in-depth review of causality's role in addressing core challenges in non-causal RL, categorizing and examining existing causal RL approaches based on their target problems and methodologies.\n",
      "\n",
      "3. **Emerging Trends**\n",
      "\n",
      "* \"Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey\" by Ngan Le et al. discusses the advantages and limitations of various deep RL methodologies and their applications in computer vision, providing valuable insights for researchers working on RL in this domain.\n",
      "* The survey \"Distributed Deep Reinforcement Learning: A Survey and a Multi-Player Multi-Agent Learning Toolbox\" by Qiyue Yin et al. compares classical distributed deep RL methods and studies important components to achieve efficient distributed learning, offering a valuable resource for researchers working on large-scale RL problems.\n",
      "\n",
      "4. **Applications & Impact**\n",
      "\n",
      "Deep RL applications in computer vision include robotics, autonomous driving, and game playing, with potential real-world implications. A simplistic prototype lifelong RL system could have significant implications for adapting to changing environments over time.\n",
      "\n",
      "5. **Challenges & Future Outlook**\n",
      "\n",
      "Traditional reinforcement learning paradigms fail to model a lifelong RL system, and current causal RL methods struggle with complex interventions, confounding variables, and non-stationary environments. To address these challenges, future research could focus on developing more effective lifelong RL algorithms, improving the scalability of distributed deep RL algorithms, reducing communication overhead, and addressing synchronization issues in large-scale problems. Additionally, researchers should aim to develop more efficient algorithms for causal effect estimation and handle complex interventions, confounding variables, and non-stationary environments.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:21 - src.graph.checkpointer - INFO - `aput_writes` called for thread_id nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc without specific thread_ts. Targeting latest checkpoint for writes for task 56f152a6-6e0a-4fe9-c434-90fa7d9b0efd.\u001b[0m\n",
      "\u001b[33m2025-06-05 21:06:21 - src.graph.checkpointer - WARNING - parent_config provided, but its 'configurable' key was missing/not a dict, AND 'id' key was not found/valid in parent_config itself. parent_config: {'messages': 6, 'error_message': 6, 'branch:to:synthesis': 6, 'synthesis_output': 6}\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:21 - src.graph.checkpointer - INFO - Checkpoint saved for thread_id: nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc, thread_ts: 1f042402-af09-616a-8004-c53262749c38\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:21 - src.graph.checkpointer - INFO - Persisted 3 writes to checkpoint version 1f042402-3247-64e1-8003-0486fdab15d8 for thread_id nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc, task_id 56f152a6-6e0a-4fe9-c434-90fa7d9b0efd.\u001b[0m\n",
      "\u001b[34m2025-06-05 21:06:21 - src.graph.main_workflow - INFO - Workflow completed successfully.\u001b[0m\n",
      "\n",
      "--- État Final Détaillé du Graphe ---\n",
      "  THREAD_ID: nb_workflow_run_f1fa2be5-f277-4b79-907c-455a73741edc\n",
      "  RESULT: {'messages': [HumanMessage(content='Analyze the latest advancements in reinforcement learning for robotic locomotion, focusing on how bipedal robots achieve stable gait. Include key challenges and future research directions based on recent ArXiv papers.', additional_kwargs={}, response_metadata={}), AIMessage(content='1. **Fundamental Questions**\\n    - What are the latest advancements in reinforcement learning (RL) for robotic locomotion?\\n    - How do bipedal robots achieve stable gait using R...\n",
      "  SYNTHESIS:  **Final Report**\n",
      "\n",
      "---\n",
      "\n",
      "1. **Executive Summary**\n",
      "\n",
      "In this analysis, we review recent advancements in reinforcement learning (RL), a rapidly evolving field that addresses core challenges through innovative breakthroughs and emerging trends. We highlight key developments such as counterexample-guided repair algorithms for RL systems, causal RL approaches, deep RL methodologies in computer vision, distributed RL techniques, and lifelong RL systems. Real-world applications range from robotics to aut...\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Générer un ID de thread unique pour cette exécution\n",
    "test_thread_id = \"nb_workflow_run_\" + str(uuid.uuid4())\n",
    "\n",
    "# LOG_LEVEL_NOTEBOOK est défini dans la section d'initialisation de ce script.\n",
    "print(f\"Lancement du workflow pour la requête avec thread_id: {test_thread_id}\")\n",
    "print(f\"Utilisation du LLM provider configuré: '{settings.DEFAULT_LLM_MODEL_PROVIDER}' et du provider d'embedding: '{settings.DEFAULT_EMBEDDING_PROVIDER}'.\")\n",
    "print(f\"Les logs du workflow (niveau '{LOG_LEVEL_NOTEBOOK}') et les sorties des agents/outils via astream_events apparaîtront ci-dessous.\")\n",
    "print(\"Le traitement peut prendre plusieurs minutes en fonction de la complexité de la requête et des modèles LLM utilisés.\")\n",
    "\n",
    "# MODIFICATION : Activer nest_asyncio pour permettre asyncio.run() dans Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "final_state_run1 = None\n",
    "\n",
    "if not settings.MONGODB_URI or (\"<user>\" in settings.MONGODB_URI and \"<password>\" in settings.MONGODB_URI) or \"<cluster_url>\" in settings.MONGODB_URI:\n",
    "    print(\"\\nERREUR CRITIQUE: MONGODB_URI n'est pas configuré correctement dans le fichier .env (il manque ou contient des placeholders).\")\n",
    "    print(\"L'exécution du workflow est annulée car le checkpointer MongoDB est requis.\")\n",
    "    logger.error(\"MONGODB_URI non configuré ou contient des placeholders. Workflow non exécuté.\")\n",
    "else:\n",
    "    try:\n",
    "        # asyncio.run() devrait maintenant fonctionner correctement grâce à nest_asyncio.apply()\n",
    "        final_state_run1 = asyncio.run(run_workflow(user_query, thread_id=test_thread_id))\n",
    "        \n",
    "    except ValueError as ve: \n",
    "        logger.error(f\"Erreur de configuration (ValueError) lors de l'exécution de run_workflow: {ve}\", exc_info=True)\n",
    "        print(f\"\\nERREUR DE CONFIGURATION PENDANT L'EXÉCUTION DU WORKFLOW : {ve}\")\n",
    "        print(\"Veuillez vérifier les configurations pour DEFAULT_LLM_MODEL_PROVIDER, DEFAULT_EMBEDDING_PROVIDER, \")\n",
    "        print(\"et leurs dépendances respectives (clés API, URLs de base, noms de modèles exacts) dans votre fichier .env et settings.py.\")\n",
    "        print(f\"Provider LLM actuel: {settings.DEFAULT_LLM_MODEL_PROVIDER}, Provider Embedding actuel: {settings.DEFAULT_EMBEDDING_PROVIDER}\")\n",
    "    except RuntimeError as re: # Attraper spécifiquement le RuntimeError si nest_asyncio n'a pas fonctionné\n",
    "        if \"cannot be called from a running event loop\" in str(re):\n",
    "            logger.error(f\"Erreur RuntimeError avec asyncio.run(): {re}. 'nest_asyncio.apply()' n'a peut-être pas fonctionné comme prévu.\", exc_info=True)\n",
    "            print(f\"\\nERREUR asyncio : {re}. Assurez-vous que 'nest_asyncio' est installé et que 'nest_asyncio.apply()' a été appelé.\")\n",
    "        else:\n",
    "            logger.error(f\"Erreur RuntimeError inattendue lors de l'exécution de asyncio.run(run_workflow): {re}\", exc_info=True)\n",
    "            print(f\"\\nERREUR RUNTIME INATTENDUE PENDANT L'EXÉCUTION DU WORKFLOW : {re}\")\n",
    "    except Exception as e: \n",
    "        logger.error(f\"Erreur inattendue lors de l'exécution de asyncio.run(run_workflow): {e}\", exc_info=True)\n",
    "        print(f\"\\nERREUR INATTENDUE PENDANT L'EXÉCUTION DU WORKFLOW : {e}\")\n",
    "\n",
    "if final_state_run1:\n",
    "    # pretty_print_final_state est défini plus haut dans ce script.\n",
    "    pretty_print_final_state(final_state_run1)\n",
    "else:\n",
    "    print(\"\\nL'exécution du workflow n'a pas retourné d'état final ou a échoué avant de pouvoir retourner un état.\")\n",
    "    if not settings.MONGODB_URI or (\"<user>\" in settings.MONGODB_URI and \"<password>\" in settings.MONGODB_URI) or \"<cluster_url>\" in settings.MONGODB_URI :\n",
    "        print(\"Rappel : MONGODB_URI n'était pas (ou mal) configuré, ce qui a pu empêcher l'exécution.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if final_state_run1 and 'synthesis_output' in final_state_run1:\n",
    "    print(final_state_run1['synthesis_output'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 3. Analyse des Sorties et du Comportement\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Après l'exécution :\n",
    "\n",
    "\n",
    "\n",
    "  * Examinez les logs produits dans la console du notebook (si le niveau de log est DEBUG pour `main_workflow` ou les agents, vous verrez beaucoup de détails).\n",
    "\n",
    "\n",
    "\n",
    "  * Observez la sortie finale (`synthesis_output`) dans l'état final.\n",
    "\n",
    "\n",
    "\n",
    "  * Si vous avez accès à MongoDB (par exemple, via MongoDB Compass ou un autre client), vous pouvez inspecter la collection des checkpoints (par défaut `langgraph_checkpoints` dans la base `makers_db`). Vous devriez y trouver des documents correspondant au `thread_id` utilisé. Chaque document représente un état sauvegardé du graphe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 4. (Optionnel) Exécution d'une Requête de Suivi sur le Même Thread\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Si le checkpointer a fonctionné, l'historique des messages et l'état du thread précédent sont sauvegardés. Envoyer une nouvelle requête avec le *même `thread_id`* permettra au système de potentiellement utiliser cet historique.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Notre workflow actuel est plutôt linéaire et ne gère pas explicitement les \"questions de suivi\" pour modifier un rapport existant. Une nouvelle invocation avec le même `thread_id` ajoutera à l'historique des messages et relancera le flux depuis le début, mais les agents verront l'historique complet.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Pour une vraie \"reprise\" d'un graphe interrompu, LangGraph le gère automatiquement si vous relancez avec la même configuration (thread_id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test d'une Requête de Suivi (Optionnel) ---\n",
    "# Décommentez les lignes ci-dessous pour tester une requête de suivi sur le même thread.\n",
    "# Note: Cela relancera le flux avec l'historique des messages accumulé. Le workflow actuel\n",
    "# est plutôt linéaire et une nouvelle invocation relancera le processus depuis le début,\n",
    "# mais les agents verront l'historique complet. La persistance via checkpointer est démontrée.\n",
    "\n",
    "# # S'assurer que test_thread_id est défini par la cellule d'exécution principale du workflow ci-dessus.\n",
    "# if 'test_thread_id' in locals() and test_thread_id:\n",
    "#     follow_up_query = \"Could you elaborate on the sim-to-real transfer challenges mentioned previously?\" # Exemple de requête de suivi\n",
    "#     logger.info(f\"Requête de suivi pour le thread {test_thread_id}: '{follow_up_query}'\")\n",
    "#     print(f\"\\nLancement d'une requête de suivi sur le même thread_id: {test_thread_id}\")\n",
    "#     print(f\"Utilisation du LLM provider configuré: '{settings.DEFAULT_LLM_MODEL_PROVIDER}' et du provider d'embedding: '{settings.DEFAULT_EMBEDDING_PROVIDER}'.\")\n",
    "#     print(\"Le traitement peut prendre plusieurs minutes...\")\n",
    "\n",
    "#     final_state_run2 = None\n",
    "#     # Vérification principale: MongoDB est essentiel.\n",
    "#     if not settings.MONGODB_URI or (\"<user>\" in settings.MONGODB_URI and \"<password>\" in settings.MONGODB_URI) or \"<cluster_url>\" in settings.MONGODB_URI:\n",
    "#         print(\"ERREUR CRITIQUE: MONGODB_URI n'est pas configuré correctement. Requête de suivi annulée.\")\n",
    "#         logger.error(\"MONGODB_URI non configuré ou contient des placeholders. Requête de suivi non exécutée.\")\n",
    "#     else:\n",
    "#         try:\n",
    "#             final_state_run2 = asyncio.run(run_workflow(follow_up_query, thread_id=test_thread_id))\n",
    "#         except ValueError as ve: \n",
    "#             logger.error(f\"Erreur de configuration (ValueError) lors de la requête de suivi: {ve}\", exc_info=True)\n",
    "#             print(f\"\\nERREUR DE CONFIGURATION PENDANT LA REQUÊTE DE SUIVI : {ve}\")\n",
    "#             print(\"Veuillez vérifier les configurations pour DEFAULT_LLM_MODEL_PROVIDER, DEFAULT_EMBEDDING_PROVIDER, et leurs dépendances.\")\n",
    "#         except Exception as e: \n",
    "#             logger.error(f\"Erreur inattendue lors de l'exécution de la requête de suivi : {e}\", exc_info=True)\n",
    "#             print(f\"\\nERREUR INATTENDUE PENDANT LA REQUÊTE DE SUIVI : {e}\")\n",
    "\n",
    "#     # pretty_print_final_state est défini plus haut dans ce script.\n",
    "#     if final_state_run2:\n",
    "#         pretty_print_final_state(final_state_run2)\n",
    "#     else:\n",
    "#         print(\"\\nL'exécution de la requête de suivi n'a pas retourné d'état final ou a échoué.\")\n",
    "# else:\n",
    "#     # Ce message s'affichera si cette cellule est exécutée avant que test_thread_id ne soit défini.\n",
    "#     print(\"\\nVariable 'test_thread_id' non trouvée ou non initialisée.\")\n",
    "#     print(\"Veuillez exécuter la cellule précédente (exécution du workflow principal) pour définir un 'test_thread_id' avant de décommenter et d'exécuter cette cellule.\")\n",
    "#     logger.warning(\"'test_thread_id' non défini. Saut de la cellule de requête de suivi optionnelle.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 5. Inspection des Checkpoints dans MongoDB (Conceptuel)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Si le `MongoDBSaver` est actif, vous pouvez vous connecter à votre instance MongoDB et examiner la collection `langgraph_checkpoints` (ou le nom que vous avez configuré dans `settings.py`). Vous y trouverez des documents JSON représentant les différents états sauvegardés pour chaque `thread_id`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Chaque document de checkpoint contient typiquement :\n",
    "\n",
    "\n",
    "\n",
    "  * `thread_id`\n",
    "\n",
    "\n",
    "\n",
    "  * `thread_ts` (un timestamp identifiant ce snapshot spécifique de l'état)\n",
    "\n",
    "\n",
    "\n",
    "  * `checkpoint` (l'état sérialisé du graphe, incluant les valeurs des canaux comme `messages`)\n",
    "\n",
    "\n",
    "\n",
    "  * `metadata` (métadonnées associées au checkpoint)\n",
    "\n",
    "\n",
    "\n",
    "  * `parent_ts` (s'il y a un checkpoint parent)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Cela démontre la persistance et la capacité de reprise du workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Conclusion de la Démonstration du Workflow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Ce notebook a permis de lancer le workflow LangGraph complet et d'observer son exécution.\n",
    "\n",
    "\n",
    "\n",
    "  Les prochaines étapes pourraient inclure :\n",
    "\n",
    "\n",
    "\n",
    "  * Des tests avec des requêtes plus variées.\n",
    "\n",
    "\n",
    "\n",
    "  * L'analyse détaillée des checkpoints dans MongoDB.\n",
    "\n",
    "\n",
    "\n",
    "  * L'utilisation du script `scripts/run_evaluation.py` pour évaluer quantitativement les résultats.\n",
    "\n",
    "\n",
    "\n",
    "  * L'amélioration itérative de la logique de routage et des prompts des agents dans `src/graph/main_workflow.py` et `src/agents/agent_architectures.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
