{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66f3b53",
   "metadata": {},
   "source": [
    "# Notebook 00: Configuration de l'Environnement\n",
    "\n",
    "Bienvenue dans le projet \"Cognitive Swarm: Multi-Agent Knowledge Discovery Engine\" !\n",
    "\n",
    "Ce notebook vous guidera à travers les étapes initiales de configuration de votre environnement de développement.\n",
    "\n",
    "## Étapes Préalables\n",
    "\n",
    "1.  **Installer Conda/Miniconda/Anaconda** : Si vous ne l'avez pas déjà, installez une distribution Conda adaptée à votre système d'exploitation depuis [Anaconda.com](https://www.anaconda.com/products/distribution) ou [Miniconda](https://docs.conda.io/en/latest/miniconda.html).\n",
    "\n",
    "2.  **Créer l'Environnement Conda** :\n",
    "    * Ouvrez un terminal ou une invite de commande Anaconda.\n",
    "    * Naviguez jusqu'à la racine de ce projet (`cognitive-swarm-agents/`).\n",
    "    * Exécutez la commande suivante pour créer l'environnement nommé `cognitive-swarm` à partir du fichier `environment.yml` fourni :\n",
    "        ```bash\n",
    "        conda env create -f environment.yml\n",
    "        ```\n",
    "    * Si l'environnement existe déjà et que vous souhaitez le mettre à jour :\n",
    "        ```bash\n",
    "        conda env update -f environment.yml --prune\n",
    "        ```\n",
    "\n",
    "3.  **Activer l'Environnement Conda** :\n",
    "    ```bash\n",
    "    conda activate cognitive-swarm\n",
    "    ```\n",
    "    Vous devriez voir `(cognitive-swarm)` au début de votre invite de commande.\n",
    "\n",
    "4.  **Créer le Fichier `.env`** :\n",
    "    * À la racine du projet (`cognitive-swarm-agents/`), créez un fichier nommé `.env`.\n",
    "    * Copiez le contenu de `.env.example` dans votre nouveau fichier `.env`.\n",
    "    * Remplissez les valeurs des variables d'environnement requises dans votre fichier `.env`, notamment :\n",
    "        * `OPENAI_API_KEY`\n",
    "        * `MONGO_URI` (votre chaîne de connexion MongoDB Atlas)\n",
    "        * `WANDB_API_KEY` (si vous utilisez Weights & Biases)\n",
    "        * Optionnellement, d'autres clés API (`ANTHROPIC_API_KEY`, `GROQ_API_KEY`, `TAVILY_API_KEY`) si vous prévoyez d'utiliser ces services.\n",
    "\n",
    "## Vérification de l'Environnement\n",
    "\n",
    "Les cellules de code ci-dessous vous aideront à vérifier que tout est correctement configuré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089164af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires pour ce notebook de configuration\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "# Tentative d'installation de python-dotenv si non présent (devrait être dans environment.yml)\n",
    "try:\n",
    "    importlib.import_module('dotenv')\n",
    "except ImportError:\n",
    "    print(\"Installation de python-dotenv...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-dotenv\"])\n",
    "    print(\"python-dotenv installé. Veuillez relancer ce kernel Jupyter.\")\n",
    "    # sys.exit() # Ou demander à l'utilisateur de relancer\n",
    "\n",
    "print(\"Imports de base réussis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ae6bd",
   "metadata": {},
   "source": [
    "### 1. Chargement des Variables d'Environnement\n",
    "\n",
    "Cette cellule charge les variables à partir de votre fichier `.env` et affiche certaines d'entre elles pour vérification (les clés API ne seront pas affichées intégralement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les variables du fichier .env situé à la racine du projet\n",
    "# Le notebook est dans notebooks/, donc ../.env\n",
    "dotenv_path = Path().resolve().parent / \".env\" # Path().resolve() donne le répertoire du notebook\n",
    "\n",
    "if dotenv_path.exists():\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "    print(f\"Variables d'environnement chargées depuis : {dotenv_path}\")\n",
    "else:\n",
    "    print(f\"Fichier .env non trouvé à l'emplacement attendu : {dotenv_path}\")\n",
    "    print(\"Veuillez vous assurer d'avoir créé et configuré votre fichier .env à la racine du projet.\")\n",
    "\n",
    "# Importer les settings de notre projet (qui utilisent aussi dotenv)\n",
    "# Pour que cela fonctionne, assurez-vous que le PYTHONPATH est correct\n",
    "# ou que vous exécutez Jupyter depuis la racine du projet.\n",
    "# Si exécuté depuis le dossier notebooks :\n",
    "import sys\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "try:\n",
    "    from config.settings import settings\n",
    "    print(\"Configuration du projet (settings.py) chargée avec succès.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Erreur lors de l'import de config.settings: {e}\")\n",
    "    print(\"Assurez-vous que vous exécutez ce notebook depuis le répertoire 'notebooks/' ou que la racine du projet est dans PYTHONPATH.\")\n",
    "    settings = None # Pour éviter des erreurs plus loin si l'import échoue\n",
    "\n",
    "if settings:\n",
    "    print(f\"\\n--- Vérification des Settings Chargés ---\")\n",
    "    print(f\"Nom du Projet: {settings.PROJECT_NAME}\")\n",
    "    print(f\"Mode Debug: {settings.DEBUG}\")\n",
    "    print(f\"Environnement Python (PYTHON_ENV): {settings.PYTHON_ENV}\")\n",
    "\n",
    "    print(f\"\\n--- Configuration des LLMs Génératifs ---\")\n",
    "    print(f\"Fournisseur LLM Génératif par Défaut: {settings.DEFAULT_LLM_MODEL_PROVIDER}\")\n",
    "    print(f\"  Si OpenAI: Modèle = {settings.DEFAULT_OPENAI_GENERATIVE_MODEL}\")\n",
    "    print(f\"  Si HuggingFace API: Repo ID = {settings.HUGGINGFACE_REPO_ID}\")\n",
    "    print(f\"  Si Ollama: Modèle Génératif = {settings.OLLAMA_GENERATIVE_MODEL_NAME}, Base URL = {settings.OLLAMA_BASE_URL}\")\n",
    "    \n",
    "    print(f\"\\n--- Configuration des Embeddings ---\")\n",
    "    print(f\"Fournisseur d'Embedding par Défaut: {settings.DEFAULT_EMBEDDING_PROVIDER}\")\n",
    "    print(f\"  Pour OpenAI: Modèle = {settings.OPENAI_EMBEDDING_MODEL_NAME}, Dimension = {settings.OPENAI_EMBEDDING_DIMENSION}\")\n",
    "    print(f\"  Pour HuggingFace: Modèle = {settings.HUGGINGFACE_EMBEDDING_MODEL_NAME}, Dimension = {settings.HUGGINGFACE_EMBEDDING_MODEL_DIMENSION}\")\n",
    "    print(f\"  Pour Ollama: Modèle = {settings.OLLAMA_EMBEDDING_MODEL_NAME}, Dimension = {settings.OLLAMA_EMBEDDING_MODEL_DIMENSION}, Base URL = {settings.OLLAMA_BASE_URL}\")\n",
    "\n",
    "    print(f\"\\n--- Clés API (vérification de présence) ---\")\n",
    "    print(f\"  OPENAI_API_KEY chargée: {bool(settings.OPENAI_API_KEY)}\")\n",
    "    if settings.OPENAI_API_KEY:\n",
    "        print(f\"    (début : {settings.OPENAI_API_KEY[:4]}...)\")\n",
    "    print(f\"  HUGGINGFACE_API_KEY chargée: {bool(settings.HUGGINGFACE_API_KEY)}\")\n",
    "    if settings.HUGGINGFACE_API_KEY:\n",
    "        print(f\"    (début : {settings.HUGGINGFACE_API_KEY[:6]}...)\")\n",
    "    print(f\"  WANDB_API_KEY chargée: {bool(settings.WANDB_API_KEY)}\")\n",
    "    if settings.WANDB_API_KEY:\n",
    "        print(f\"    (début : {settings.WANDB_API_KEY[:4]}...)\")\n",
    "    print(f\"  ANTHROPIC_API_KEY chargée: {bool(settings.ANTHROPIC_API_KEY)}\")\n",
    "    print(f\"  GROQ_API_KEY chargée: {bool(settings.GROQ_API_KEY)}\")\n",
    "    print(f\"  TAVILY_API_KEY chargée: {bool(settings.TAVILY_API_KEY)}\")\n",
    "\n",
    "    print(f\"\\n--- Configuration MongoDB ---\")\n",
    "    print(f\"  MONGO_URI: {settings.MONGO_URI[:20]}... (tronqué pour affichage)\")\n",
    "    print(f\"  MONGO_DATABASE_NAME: {settings.MONGO_DATABASE_NAME}\")\n",
    "    print(f\"  LANGGRAPH_CHECKPOINTS_COLLECTION: {settings.LANGGRAPH_CHECKPOINTS_COLLECTION}\")\n",
    "\n",
    "\n",
    "    print(f\"\\n--- Configuration des Données et Chemins ---\")\n",
    "    print(f\"  DATA_DIR: {settings.DATA_DIR}\")\n",
    "    print(f\"  Chemin du dataset d'évaluation RAG (par défaut): {settings.EVALUATION_DATASET_PATH}\")\n",
    "\n",
    "    if settings.DATA_DIR.exists():\n",
    "        print(f\"  Le répertoire DATA_DIR ({settings.DATA_DIR}) existe.\")\n",
    "    else:\n",
    "        print(f\"  ATTENTION : Le répertoire DATA_DIR ({settings.DATA_DIR}) n'existe pas. Certains scripts pourraient échouer.\")\n",
    "        print(f\"  Vous pourriez avoir besoin de le créer manuellement ou il sera créé par run_ingestion.py (pour ses sous-dossiers).\")\n",
    "    \n",
    "    # Vérifier le dataset d'évaluation si le chemin est défini\n",
    "    if settings.EVALUATION_DATASET_PATH:\n",
    "        eval_path = Path(settings.EVALUATION_DATASET_PATH)\n",
    "        if eval_path.is_file(): # Vérifier si c'est un fichier\n",
    "            print(f\"  Le fichier de dataset d'évaluation RAG ({eval_path}) existe.\")\n",
    "        else:\n",
    "            print(f\"  ATTENTION : Le fichier de dataset d'évaluation RAG ({eval_path}) n'existe PAS ou n'est pas un fichier.\")\n",
    "    else:\n",
    "        print(\"  Aucun chemin de dataset d'évaluation RAG n'est configuré dans settings.py (EVALUATION_DATASET_PATH est None).\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nLes settings du projet n'ont pas pu être chargés. Veuillez vérifier l'import et le fichier .env.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc96800",
   "metadata": {},
   "source": [
    "### 2. Test de Connexion à MongoDB\n",
    "\n",
    "Cette cellule tente de se connecter à votre instance MongoDB en utilisant l'URI fournie dans `.env` et chargée via `settings.py`.\n",
    "Assurez-vous que votre base de données MongoDB Atlas est accessible (IP autorisée, etc.) ou que votre instance locale est en cours d'exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfd98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_to_check = [\n",
    "    \"langchain\",\n",
    "    \"langchain_core\",\n",
    "    \"langchain_openai\",\n",
    "    \"langchain_community\", # Ajouté pour être explicite, car HuggingFaceEmbeddings et OllamaEmbeddings en viennent\n",
    "    \"langgraph\",\n",
    "    \"llama_index.core\",\n",
    "    \"llama_index.vector_stores.mongodb\",\n",
    "    \"llama_index.embeddings.openai\",\n",
    "    \"llama_index.embeddings.huggingface\", # <<< NOUVEAU CHECK\n",
    "    \"llama_index.embeddings.ollama\",      # <<< NOUVEAU CHECK\n",
    "    \"pymongo\",\n",
    "    \"motor\",\n",
    "    \"arxiv\",\n",
    "    \"fitz\", # PyMuPDF\n",
    "    \"tiktoken\",\n",
    "    \"pandas\",\n",
    "    \"wandb\",\n",
    "    \"crewai\", # Ajouté pour être explicite\n",
    "    \"pydantic\",\n",
    "    \"pydantic_settings\",\n",
    "    \"fastapi\", # Ajouté pour être explicite\n",
    "    \"uvicorn\"  # Ajouté pour être explicite\n",
    "]\n",
    "\n",
    "print(\"--- Vérification de l'import des bibliothèques principales ---\")\n",
    "all_libraries_found = True\n",
    "for lib_name in libraries_to_check:\n",
    "    try:\n",
    "        importlib.import_module(lib_name)\n",
    "        print(f\"✅ {lib_name} : Trouvé et importable.\")\n",
    "    except ImportError:\n",
    "        print(f\"❌ {lib_name} : NON TROUVÉ. Veuillez vérifier votre environnement Conda ('environment.yml') et vos requirements pip.\")\n",
    "        all_libraries_found = False\n",
    "\n",
    "if all_libraries_found:\n",
    "    print(\"\\n🎉 Toutes les bibliothèques principales listées semblent être correctement installées !\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Certaines bibliothèques principales listées sont manquantes. Veuillez vérifier l'installation de votre environnement Conda/pip.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a6666",
   "metadata": {},
   "source": [
    "### 3. Vérification des Bibliothèques Principales\n",
    "\n",
    "Cette cellule tente d'importer les bibliothèques majeures utilisées dans le projet pour s'assurer qu'elles sont bien installées dans l'environnement `cognitive-swarm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23253370",
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_to_check = [\n",
    "    \"langchain\",\n",
    "    \"langchain_core\",\n",
    "    \"langchain_openai\",\n",
    "    \"langgraph\",\n",
    "    \"llama_index.core\",\n",
    "    \"llama_index.vector_stores.mongodb\",\n",
    "    \"llama_index.embeddings.openai\",\n",
    "    \"pymongo\",\n",
    "    \"motor\",\n",
    "    \"arxiv\",\n",
    "    \"fitz\", # PyMuPDF\n",
    "    \"tiktoken\",\n",
    "    \"pandas\",\n",
    "    \"wandb\",\n",
    "    \"pydantic\",\n",
    "    \"pydantic_settings\"\n",
    "]\n",
    "\n",
    "print(\"--- Vérification de l'import des bibliothèques principales ---\")\n",
    "all_libraries_found = True\n",
    "for lib_name in libraries_to_check:\n",
    "    try:\n",
    "        importlib.import_module(lib_name)\n",
    "        print(f\"✅ {lib_name} : Trouvé et importable.\")\n",
    "    except ImportError:\n",
    "        print(f\"❌ {lib_name} : NON TROUVÉ. Veuillez vérifier votre environnement Conda ('environment.yml').\")\n",
    "        all_libraries_found = False\n",
    "\n",
    "if all_libraries_found:\n",
    "    print(\"\\n🎉 Toutes les bibliothèques principales semblent être correctement installées !\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Certaines bibliothèques principales sont manquantes. Veuillez vérifier l'installation de votre environnement Conda.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e5be5",
   "metadata": {},
   "source": [
    "## Configuration Terminée\n",
    "\n",
    "Si toutes les cellules ci-dessus se sont exécutées sans erreur majeure (en particulier les erreurs d'import ou de connexion), votre environnement est probablement prêt pour la suite du projet \"Cognitive Swarm\".\n",
    "\n",
    "Vous pouvez maintenant passer aux notebooks suivants pour explorer les différentes parties du système."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitive-swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
